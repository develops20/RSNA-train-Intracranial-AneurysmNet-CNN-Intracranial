{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":99552,"databundleVersionId":13190393,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/02-aneurysmnet-cnn-intracranial-training-nb153?scriptVersionId=254347897\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install monai\n\n# ====================================================\n# RSNA INTRACRANIAL ANEURYSM DETECTION - TRAINING PIPELINE\n# ====================================================\n\nimport os\nimport gc\nimport warnings\nimport json\nimport time\nimport numpy as np\nimport pandas as pd\nfrom typing import Tuple, Dict, List\nfrom collections import Counter\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import roc_auc_score\nimport albumentations as A\n\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.amp import autocast, GradScaler\n\nimport pydicom\nimport pydicom.errors\nfrom scipy import ndimage\nimport nibabel as nib\nfrom monai.transforms import (\n    Compose, RandRotate90d, RandFlipd, RandAffined,\n    RandGaussianNoised, RandAdjustContrastd, ToTensord\n)\nfrom monai.networks.nets import BasicUNet\nfrom monai.losses import DiceCELoss, FocalLoss\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:16:04.995278Z","iopub.execute_input":"2025-08-05T12:16:04.995854Z","iopub.status.idle":"2025-08-05T12:17:52.715271Z","shell.execute_reply.started":"2025-08-05T12:16:04.99583Z","shell.execute_reply":"2025-08-05T12:17:52.714322Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.5.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.5.0-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed monai-1.5.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"},{"name":"stderr","text":"2025-08-05 12:17:40.631931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754396260.854853      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754396260.921674      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ====================================================\n# CONFIGURATION\n# ====================================================\n\nclass Config:\n    # Paths\n    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n    LOCALIZER_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\n    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n    \n    # Model parameters\n    TARGET_SIZE = (32, 64, 64)  # Increased resolution\n    EPOCHS = 2\n    BATCH_SIZE = 16  # Reduced due to larger input size\n    LEARNING_RATE = 1e-3\n    WEIGHT_DECAY = 1e-4\n    N_FOLDS = 3\n    \n    # Training parameters\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    MIXED_PRECISION = True\n    GRADIENT_ACCUMULATION = 4\n    \n    # Competition constants\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n    \n    # Class weights for imbalanced data\n    ANEURYSM_PRESENT_WEIGHT = 13.0  # Match evaluation metric weighting\n\n# ====================================================\n# ENHANCED DATA PREPROCESSING\n# ====================================================\n\nclass AdvancedDICOMProcessor:\n    def __init__(self, target_size: Tuple[int, int, int] = Config.TARGET_SIZE):\n        self.target_size = target_size\n        self.stats = {\n            'total_loaded': 0,\n            'successful_loads': 0,\n            'shape_errors': 0,\n            'empty_volumes': 0,\n            'preprocessing_errors': 0,\n            'invalid_dicom_files': 0,\n            'empty_pixel_arrays': 0,\n            'corrupted_pixel_data': 0\n        }\n        \n        # Initialize detailed corruption log\n        self.corruption_log_file = 'detailed_corruption_log.txt'\n        self._init_corruption_log()\n    \n    def _init_corruption_log(self):\n        \"\"\"Initialize detailed corruption logging\"\"\"\n        try:\n            with open(self.corruption_log_file, 'w') as f:\n                f.write(\"# DETAILED DICOM CORRUPTION LOG\\n\")\n                f.write(\"# This file tracks specific reasons for DICOM corruption\\n\")\n                f.write(\"# Format: [TIMESTAMP] SeriesID | Error Type | Details\\n\")\n                f.write(\"# Error Types: NO_FILES, INVALID_DICOM, EMPTY_PIXELS, CORRUPTED_DATA, SHAPE_MISMATCH\\n\\n\")\n        except Exception as e:\n            print(f\"⚠️  Could not initialize corruption log: {e}\")\n    \n    def _log_corruption(self, series_id: str, error_type: str, details: str):\n        \"\"\"Log corruption details with timestamp\"\"\"\n        try:\n            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n            log_entry = f\"[{timestamp}] {series_id} | {error_type} | {details}\\n\"\n            with open(self.corruption_log_file, 'a') as f:\n                f.write(log_entry)\n                f.flush()\n        except Exception as e:\n            print(f\"⚠️  Could not log corruption: {e}\")\n\n    def _detect_localizer(self, ds, pixel_data, filename):\n        \"\"\"Detect if a DICOM is likely a localizer/scout image\"\"\"\n        try:\n            # Check various indicators that suggest this is a localizer\n            indicators = {\n                'small_slice_count': pixel_data.shape[0] < 50,  # Localizers usually have few slices\n                'filename_indicator': any(term in filename.lower() for term in ['scout', 'localizer', 'topo']),\n                'series_description': False,\n                'image_type': False\n            }\n            \n            # Check series description if available\n            if hasattr(ds, 'SeriesDescription'):\n                desc = str(ds.SeriesDescription).lower()\n                indicators['series_description'] = any(term in desc for term in \n                    ['scout', 'localizer', 'topo', 'survey', 'plan'])\n            \n            # Check image type if available\n            if hasattr(ds, 'ImageType'):\n                img_type = str(ds.ImageType).lower() if isinstance(ds.ImageType, str) else str(ds.ImageType)\n                indicators['image_type'] = any(term in img_type for term in ['localizer', 'scout'])\n            \n            # Consider it a localizer if any indicator is True\n            is_localizer = any(indicators.values())\n            \n            if is_localizer:\n                indicator_details = [k for k, v in indicators.items() if v]\n                print(f\"    🎯 Localizer indicators: {', '.join(indicator_details)}\")\n            \n            return is_localizer\n            \n        except Exception as e:\n            print(f\"    ⚠️  Error detecting localizer: {e}\")\n            return False  # Default to treating as regular volume\n        \n    def load_dicom_series(self, series_path: str) -> Tuple[np.ndarray, Dict]:\n        \"\"\"Load DICOM series with comprehensive error tracking and logging\"\"\"\n        self.stats['total_loaded'] += 1\n        series_id = os.path.basename(series_path)\n        \n        try:\n            # Check if directory exists\n            if not os.path.exists(series_path):\n                self._log_corruption(series_id, \"NO_PATH\", f\"Directory does not exist: {series_path}\")\n                self.stats['empty_volumes'] += 1\n                return self._get_fallback_volume(), {}\n            \n            # Get DICOM files\n            all_files = os.listdir(series_path)\n            dicom_files = [os.path.join(series_path, f) for f in all_files if f.endswith('.dcm')]\n            \n            if not dicom_files:\n                self._log_corruption(series_id, \"NO_FILES\", f\"No .dcm files found. Directory contains: {len(all_files)} files\")\n                print(f\"❌ No DICOM files found in {series_path}, using mean volume fallback\")\n                self.stats['empty_volumes'] += 1\n                return self._get_fallback_volume(), {}\n            \n            print(f\"🔍 Loading series {series_id}: Found {len(dicom_files)} DICOM files\")\n            \n            # Track detailed corruption stats for this series\n            series_stats = {\n                'total_files': len(dicom_files),\n                'invalid_dicom': 0,\n                'empty_pixels': 0,\n                'corrupted_pixels': 0,\n                'valid_dicoms': 0,\n                'pixel_read_errors': 0,\n                'localizer_converted': 0,\n                'slices_extracted': 0\n            }\n            \n            dicoms = []\n            detailed_errors = []\n            \n            for i, dicom_file in enumerate(dicom_files):\n                filename = os.path.basename(dicom_file)\n                try:\n                    # Try to read DICOM\n                    ds = pydicom.dcmread(dicom_file, force=True)\n                    \n                    # Check if pixel array exists\n                    if not hasattr(ds, 'pixel_array'):\n                        series_stats['empty_pixels'] += 1\n                        detailed_errors.append(f\"  {filename}: No pixel_array attribute\")\n                        continue\n                    \n                    # Try to access pixel array\n                    try:\n                        pixel_data = ds.pixel_array\n                        if pixel_data is None:\n                            series_stats['empty_pixels'] += 1\n                            detailed_errors.append(f\"  {filename}: pixel_array is None\")\n                            continue\n                        elif pixel_data.size == 0:\n                            series_stats['empty_pixels'] += 1\n                            detailed_errors.append(f\"  {filename}: pixel_array is empty (size=0)\")\n                            continue\n                        elif pixel_data.ndim == 2:\n                            # Standard 2D slice - this is what we want\n                            dicoms.append(ds)\n                            series_stats['valid_dicoms'] += 1\n                        elif pixel_data.ndim == 3:\n                            # 3D volume in single DICOM (localizer/reconstructed volume)\n                            # Check if this might be a localizer image\n                            is_localizer = self._detect_localizer(ds, pixel_data, filename)\n                            \n                            if is_localizer:\n                                print(f\"  🔍 Detected localizer image in {filename}, extracting representative slices\")\n                                # For localizers, extract fewer slices (e.g., every 4th slice)\n                                slice_step = max(1, pixel_data.shape[0] // 8)  # Get ~8 representative slices\n                                selected_indices = range(0, pixel_data.shape[0], slice_step)\n                            else:\n                                print(f\"  🔄 Converting 3D volume {pixel_data.shape} to 2D slices in {filename}\")\n                                # For regular 3D volumes, extract all slices\n                                selected_indices = range(pixel_data.shape[0])\n                            \n                            # Create pseudo-DICOM objects for selected slices\n                            slices_added = 0\n                            for slice_idx in selected_indices:\n                                slice_data = pixel_data[slice_idx]\n                                if slice_data.size > 0:\n                                    # Create a copy of the DICOM metadata for this slice\n                                    slice_ds = pydicom.Dataset()\n                                    slice_ds.pixel_array = slice_data\n                                    # Copy important metadata\n                                    for attr in ['Modality', 'PixelSpacing', 'SliceThickness', \n                                               'RescaleSlope', 'RescaleIntercept']:\n                                        if hasattr(ds, attr):\n                                            setattr(slice_ds, attr, getattr(ds, attr))\n                                    # Set unique instance number for each slice\n                                    slice_ds.InstanceNumber = slice_idx + 1\n                                    dicoms.append(slice_ds)\n                                    series_stats['valid_dicoms'] += 1\n                                    slices_added += 1\n                            \n                            series_stats['localizer_converted'] += 1 if is_localizer else 0\n                            series_stats['slices_extracted'] += slices_added\n                            \n                            if is_localizer:\n                                print(f\"  ✅ Extracted {slices_added} representative slices from localizer ({pixel_data.shape[0]} total)\")\n                            else:\n                                print(f\"  ✅ Extracted {slices_added} slices from 3D volume\")\n                        else:\n                            series_stats['corrupted_pixels'] += 1\n                            detailed_errors.append(f\"  {filename}: Unsupported dimensions {pixel_data.shape} (ndim={pixel_data.ndim})\")\n                            continue\n                            \n                    except Exception as pixel_error:\n                        series_stats['pixel_read_errors'] += 1\n                        detailed_errors.append(f\"  {filename}: Pixel read error - {str(pixel_error)}\")\n                        continue\n                        \n                except pydicom.errors.InvalidDicomError as dicom_error:\n                    series_stats['invalid_dicom'] += 1\n                    detailed_errors.append(f\"  {filename}: Invalid DICOM - {str(dicom_error)}\")\n                    continue\n                except Exception as e:\n                    series_stats['invalid_dicom'] += 1\n                    detailed_errors.append(f\"  {filename}: Read error - {str(e)}\")\n                    continue\n            \n            # Log detailed results\n            corruption_details = (f\"Files: {series_stats['total_files']}, \"\n                                f\"Valid: {series_stats['valid_dicoms']}, \"\n                                f\"Invalid: {series_stats['invalid_dicom']}, \"\n                                f\"Empty pixels: {series_stats['empty_pixels']}, \"\n                                f\"Corrupted pixels: {series_stats['corrupted_pixels']}, \"\n                                f\"Pixel errors: {series_stats['pixel_read_errors']}, \"\n                                f\"Localizers converted: {series_stats['localizer_converted']}, \"\n                                f\"Slices extracted: {series_stats['slices_extracted']}\")\n            \n            if series_stats['valid_dicoms'] == 0:\n                # Complete failure - log everything\n                error_summary = f\"TOTAL_FAILURE: {corruption_details}\"\n                self._log_corruption(series_id, \"TOTAL_FAILURE\", error_summary)\n                \n                print(f\"❌ Complete failure for series {series_id}:\")\n                print(f\"   📊 {corruption_details}\")\n                if detailed_errors:\n                    print(\"   🔍 First 5 errors:\")\n                    for error in detailed_errors[:5]:\n                        print(error)\n                    \n                self.stats['empty_volumes'] += 1\n                return self._get_fallback_volume(), {}\n            \n            elif series_stats['valid_dicoms'] < series_stats['total_files'] * 0.5:\n                # Partial failure - log but continue\n                self._log_corruption(series_id, \"PARTIAL_FAILURE\", corruption_details)\n                print(f\"⚠️  Partial corruption in series {series_id}: {corruption_details}\")\n            elif series_stats['localizer_converted'] > 0:\n                # Successfully converted localizer images\n                self._log_corruption(series_id, \"LOCALIZER_CONVERTED\", corruption_details)\n                print(f\"🎯 Successfully converted localizer series {series_id}: {corruption_details}\")\n                \n            # Continue with valid DICOMs\n            print(f\"✅ Successfully loaded {len(dicoms)} valid DICOMs from series {series_id}\")\n            \n            # Extract metadata from first valid DICOM\n            first_ds = dicoms[0]\n            metadata = {\n                'modality': getattr(first_ds, 'Modality', 'UNKNOWN'),\n                'spacing': getattr(first_ds, 'PixelSpacing', [1.0, 1.0]),\n                'slice_thickness': getattr(first_ds, 'SliceThickness', 1.0),\n                'rescale_slope': getattr(first_ds, 'RescaleSlope', 1.0),\n                'rescale_intercept': getattr(first_ds, 'RescaleIntercept', 0.0),\n            }\n            \n            # Sort by instance number \n            dicoms.sort(key=lambda x: int(getattr(x, 'InstanceNumber', 0)))\n            \n            # Process pixel arrays\n            pixel_arrays = []\n            shapes = []\n            pixel_processing_errors = 0\n            \n            for d in dicoms:\n                try:\n                    arr = d.pixel_array\n                    if arr.ndim == 2 and arr.size > 0:\n                        pixel_arrays.append(arr)\n                        shapes.append(arr.shape)\n                    else:\n                        pixel_processing_errors += 1\n                except Exception as e:\n                    pixel_processing_errors += 1\n                    continue\n            \n            if len(pixel_arrays) == 0:\n                self._log_corruption(series_id, \"PIXEL_PROCESSING_FAILURE\", \n                                   f\"All {len(dicoms)} DICOMs failed pixel processing\")\n                print(f\"❌ No valid pixel arrays in series (corrupted DICOM), using mean volume fallback\")\n                self.stats['shape_errors'] += 1\n                return self._get_fallback_volume(), metadata\n            \n            if pixel_processing_errors > 0:\n                self._log_corruption(series_id, \"PIXEL_PROCESSING_PARTIAL\", \n                                   f\"{pixel_processing_errors} DICOMs failed pixel processing out of {len(dicoms)}\")\n            \n            # Handle shape consistency\n            unique_shapes = list(set(shapes))\n            if len(unique_shapes) == 1:\n                # All same shape - direct stacking\n                volume = np.stack(pixel_arrays, axis=0).astype(np.float32)\n                print(f\"✅ Consistent shapes: {unique_shapes[0]} across {len(pixel_arrays)} slices\")\n            else:\n                # Multiple shapes - resize to most common\n                most_common_shape = Counter(shapes).most_common(1)[0][0]\n                shape_counter = Counter(shapes)\n                shape_breakdown = \", \".join([f\"{shape}: {count}\" for shape, count in shape_counter.most_common(3)])\n                shape_details = f\"Found {len(unique_shapes)} different shapes. Breakdown: {shape_breakdown}\"\n                self._log_corruption(series_id, \"SHAPE_MISMATCH\", shape_details)\n                print(f\"⚠️  Shape inconsistency in {series_id}: {shape_details}\")\n                print(f\"   📐 Resizing all slices to most common shape: {most_common_shape}\")\n                \n                resized_arrays = []\n                for arr in pixel_arrays:\n                    if arr.shape == most_common_shape:\n                        resized_arrays.append(arr.astype(np.float32))\n                    else:\n                        zoom_factors = (most_common_shape[0] / arr.shape[0], \n                                      most_common_shape[1] / arr.shape[1])\n                        resized_arr = ndimage.zoom(arr, zoom_factors, order=1, prefilter=False)\n                        resized_arrays.append(resized_arr.astype(np.float32))\n                volume = np.stack(resized_arrays, axis=0).astype(np.float32)\n            \n            # Log successful loads with details\n            if self.stats['total_loaded'] <= 10:\n                print(f\"✅ Final volume: {volume.shape} from {len(pixel_arrays)} slices\")\n            \n            # Apply rescale if available\n            if metadata['rescale_slope'] != 1.0 or metadata['rescale_intercept'] != 0.0:\n                volume = volume * metadata['rescale_slope'] + metadata['rescale_intercept']\n\n            self.stats['successful_loads'] += 1\n            return volume, metadata\n            \n        except Exception as e:\n            # Log unexpected errors\n            error_details = f\"Unexpected error: {str(e)}\"\n            self._log_corruption(series_id, \"UNEXPECTED_ERROR\", error_details)\n            print(f\"❌ Unexpected error loading {series_path}: {e}, using mean volume fallback\")\n            self.stats['shape_errors'] += 1\n            return self._get_fallback_volume(), {}\n\n    def _get_fallback_volume(self):\n        \"\"\"Get mean volume fallback or zeros if no dataset reference\"\"\"\n        if hasattr(self, 'dataset') and hasattr(self.dataset, 'mean_volume'):\n            return self.dataset.mean_volume.copy()\n        return np.zeros(self.target_size, dtype=np.float32)\n\n    def print_stats(self):\n        \"\"\"Print comprehensive loading statistics\"\"\"\n        total = self.stats['total_loaded']\n        successful = self.stats['successful_loads']\n        empty = self.stats['empty_volumes']\n        shape_errors = self.stats['shape_errors']\n        invalid_dicom = self.stats['invalid_dicom_files']\n        empty_pixels = self.stats['empty_pixel_arrays']\n        corrupted_pixels = self.stats['corrupted_pixel_data']\n        \n        if total > 0:\n            success_rate = (successful / total) * 100\n            print(f\"\\n📊 === COMPREHENSIVE DICOM LOADING STATS ===\")\n            print(f\"📈 Total attempts: {total}\")\n            print(f\"✅ Successful loads: {successful}/{total} ({success_rate:.1f}%)\")\n            print(f\"❌ Failed loads breakdown:\")\n            print(f\"   🚫 Empty volumes: {empty} ({empty/total*100:.1f}%)\")\n            print(f\"   📄 Invalid DICOM files: {invalid_dicom} ({invalid_dicom/total*100:.1f}%)\")\n            print(f\"   🗂️  Empty pixel arrays: {empty_pixels} ({empty_pixels/total*100:.1f}%)\")\n            print(f\"   💥 Corrupted pixel data: {corrupted_pixels} ({corrupted_pixels/total*100:.1f}%)\")\n            print(f\"   📐 Shape errors: {shape_errors} ({shape_errors/total*100:.1f}%)\")\n            \n            # Overall assessment\n            total_failed = empty + invalid_dicom + empty_pixels + corrupted_pixels + shape_errors\n            print(f\"📊 Total corruption rate: {total_failed/total*100:.1f}%\")\n            \n            if success_rate < 70:\n                print(f\"🚨 SUCCESS RATE TOO LOW ({success_rate:.1f}%)!\")\n                print(f\"   🔍 Check detailed_corruption_log.txt for specific issues\")\n                print(f\"   📋 Most common issues likely in the corruption log\")\n            elif success_rate < 85:\n                print(f\"⚠️  Moderate success rate ({success_rate:.1f}%) - some data quality issues\")\n                print(f\"   💡 Review detailed_corruption_log.txt for improvement opportunities\")\n            else:\n                print(f\"✅ Good success rate ({success_rate:.1f}%)\")\n            \n            print(f\"📄 Detailed analysis available in: {self.corruption_log_file}\")\n            print(f\"===============================\")\n    \n    def analyze_corruption_patterns(self):\n        \"\"\"Analyze and summarize corruption patterns from the log\"\"\"\n        try:\n            if not os.path.exists(self.corruption_log_file):\n                print(\"📄 No corruption log file found\")\n                return\n            \n            error_types = {}\n            series_with_errors = set()\n            \n            with open(self.corruption_log_file, 'r') as f:\n                for line in f:\n                    if line.startswith('#') or not line.strip():\n                        continue\n                    \n                    try:\n                        # Parse: [TIMESTAMP] SeriesID | Error Type | Details\n                        parts = line.strip().split(' | ')\n                        if len(parts) >= 2:\n                            series_id = parts[0].split('] ')[1] if '] ' in parts[0] else parts[0]\n                            error_type = parts[1]\n                            \n                            series_with_errors.add(series_id)\n                            error_types[error_type] = error_types.get(error_type, 0) + 1\n                    except:\n                        continue\n            \n            if error_types:\n                print(f\"\\n🔍 === CORRUPTION PATTERN ANALYSIS ===\")\n                print(f\"📊 Unique series with errors: {len(series_with_errors)}\")\n                print(f\"🏷️  Error type breakdown:\")\n                \n                sorted_errors = sorted(error_types.items(), key=lambda x: x[1], reverse=True)\n                for error_type, count in sorted_errors:\n                    print(f\"   {error_type}: {count} occurrences\")\n                \n                print(f\"💡 Most common issue: {sorted_errors[0][0]} ({sorted_errors[0][1]} cases)\")\n                print(f\"===============================\")\n        \n        except Exception as e:\n            print(f\"⚠️  Could not analyze corruption patterns: {e}\")\n\n    def preprocess_volume(self, volume: np.ndarray, metadata: Dict) -> np.ndarray:\n        \"\"\"Enhanced preprocessing with modality-specific handling\"\"\"\n        if volume.ndim != 3 or volume.size == 0:\n            print(f\"Warning: Received a non-3D volume. Returning empty target volume.\")\n            return np.zeros(self.target_size, dtype=np.float32)\n        \n        # Default windowing\n        p1, p99 = np.percentile(volume, [5, 95])\n        volume = np.clip(volume, p1, p99)\n        \n        # Normalization\n        vol_min, vol_max = volume.min(), volume.max()\n        if vol_max > vol_min:\n            volume = (volume - vol_min) / (vol_max - vol_min)\n        \n        # Resize to target size\n        if volume.shape != self.target_size:\n            zoom_factors = [self.target_size[i] / volume.shape[i] for i in range(3)]\n            volume = ndimage.zoom(volume, zoom_factors, order=1, prefilter=False)\n        \n        return volume.astype(np.float32)\n\n    def load_localization_mask(self, series_id: str, localizer_df: pd.DataFrame) -> np.ndarray:\n        return np.zeros(self.target_size, dtype=np.float32)\n\n\n# ====================================================\n# ENHANCED DATASET\n# ====================================================\n\nclass EnhancedAneurysmDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, localizer_df: pd.DataFrame, \n                 series_dir: str, processor: AdvancedDICOMProcessor, \n                 mode: str = 'train', fold: int = None, shared_mean_volume: np.ndarray = None):\n        self.df = df\n        self.localizer_df = localizer_df\n        self.series_dir = series_dir\n        self.processor = processor\n        self.mode = mode\n        self.fold = fold\n        \n        # Data augmentation for training\n        if mode == 'train':\n            self.transform = Compose([\n                # Lightweight augmentations to improve generalization\n                RandRotate90d(keys=['volume'], prob=0.2, spatial_axes=(0, 1)),  # 90-degree rotations only\n                RandFlipd(keys=['volume'], prob=0.5, spatial_axis=0),           # Axial flip\n                RandFlipd(keys=['volume'], prob=0.5, spatial_axis=1),           # Sagittal flip\n                RandGaussianNoised(keys=['volume'], prob=0.2, std=0.03),        # Very low noise level\n                ToTensord(keys=['volume'])\n            ])\n        else:\n            self.transform = Compose([ToTensord(keys=['volume'])])\n\n        # Set dataset reference in processor for mean volume access\n        self.processor.dataset = self\n\n         # Use shared mean volume or compute new one\n        if shared_mean_volume is not None:\n            self.mean_volume = shared_mean_volume.copy()\n            print(f\"🔄 Using shared mean volume fallback (shape: {self.mean_volume.shape})\")\n        else:\n            # Precompute mean volume for fallback on corrupted DICOM files\n            print(\"🔄 Computing mean volume fallback from valid series...\")\n            valid_volumes = []\n            sample_size = min(10, len(df))  # Sample 10 series for speed\n            \n            for i, series_id in enumerate(df[Config.ID_COL][:sample_size]):\n                series_path = os.path.join(series_dir, series_id)\n                try:\n                    volume, _ = processor.load_dicom_series(series_path)\n                    if not np.all(volume == 0) and volume.size > 0:\n                        volume = processor.preprocess_volume(volume, {})\n                        valid_volumes.append(volume)\n                        print(f\"  ✅ Valid volume {i+1}/{sample_size}: {volume.shape}\")\n                except Exception as e:\n                    print(f\"  ❌ Skipped corrupted volume {i+1}/{sample_size}: {e}\")\n                    continue\n            \n            if valid_volumes:\n                self.mean_volume = np.mean(valid_volumes, axis=0).astype(np.float32)\n                print(f\"📊 Mean volume computed from {len(valid_volumes)} valid series: {self.mean_volume.shape}\")\n            else:\n                self.mean_volume = np.zeros(processor.target_size, dtype=np.float32)\n                print(\"⚠️  No valid volumes found, using zero fallback\")\n            \n            print(f\"🎯 Mean volume fallback ready (shape: {self.mean_volume.shape})\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        load_start = time.time()\n        row = self.df.iloc[idx]\n        series_id = row[Config.ID_COL]\n        series_path = os.path.join(self.series_dir, series_id)\n        \n        # Load and process volume\n        volume, metadata = self.processor.load_dicom_series(series_path)\n        dicom_time = time.time() - load_start\n        preprocess_start = time.time()\n        volume = self.processor.preprocess_volume(volume, metadata)\n        \n        # Create localization mask (for auxiliary loss)\n        loc_mask = self.processor.load_localization_mask(series_id, self.localizer_df)\n        \n        # Get labels\n        labels = row[Config.LABEL_COLS].values.astype(np.float32)\n        \n        # Apply transforms\n        data_dict = {'volume': volume}\n        if self.transform:\n            data_dict = self.transform(data_dict)\n        \n        volume_tensor = data_dict['volume'].unsqueeze(0)  # Add channel dimension\n        loc_mask_tensor = torch.from_numpy(loc_mask).unsqueeze(0)\n        labels_tensor = torch.from_numpy(labels)\n        \n        # Add metadata features\n        modality_encoding = self._encode_modality(metadata.get('modality', 'UNKNOWN'))\n        metadata_tensor = torch.tensor(modality_encoding, dtype=torch.float32)\n        \n        preprocess_time = time.time() - preprocess_start\n        # Print timing for first few samples to debug\n        if idx < 5:\n            print(f\"Sample {idx}: DICOM load: {dicom_time:.2f}s, Preprocess: {preprocess_time:.2f}s\")\n        \n        return {\n            'volume': volume_tensor,\n            'localization_mask': loc_mask_tensor,\n            'labels': labels_tensor,\n            'metadata': metadata_tensor,\n            'series_id': series_id\n        }\n    \n    def _encode_modality(self, modality: str) -> List[float]:\n        \"\"\"One-hot encode modality\"\"\"\n        modalities = ['CTA', 'MRA', 'MRI', 'MR', 'UNKNOWN']\n        encoding = [0.0] * len(modalities)\n        if modality in modalities:\n            encoding[modalities.index(modality)] = 1.0\n        else:\n            encoding[-1] = 1.0  # UNKNOWN\n        return encoding\n\n\n# ====================================================\n# ADVANCED MODEL ARCHITECTURE\n# ====================================================\n\n#class MultiModalAneurysmNet(nn.Module):\nclass SimplifiedAneurysmNet(nn.Module):\n    def __init__(self, num_classes: int = len(Config.LABEL_COLS), \n                 spatial_dims: int = 3, in_channels: int = 1, \n        #          features: Tuple = (32, 64, 128, 256, 512, 1024)):\n        # super(MultiModalAneurysmNet, self).__init__()\n                 features: Tuple = (16, 32, 64, 128, 256, 51)):\n        super(SimplifiedAneurysmNet, self).__init__()\n        \n        # Main 3D U-Net backbone\n        self.backbone = BasicUNet(\n            spatial_dims=spatial_dims,\n            in_channels=in_channels,\n            out_channels=features[0],\n            features=features,\n            dropout=0.1 #Reduced dropout \n        )\n        \n        # Global average pooling\n        self.global_pool = nn.AdaptiveAvgPool3d(1)\n        \n        # # Metadata processing\n        # self.metadata_mlp = nn.Sequential(\n        #     nn.Linear(5, 32),  # 5 modality categories\n        #     nn.ReLU(),\n        #     nn.Dropout(0.3),\n        #     nn.Linear(32, 64),\n        #     nn.ReLU()\n        # )\n        \n        # Classification head\n        #feature_size = features[0] + 64  # backbone features + metadata features\n        self.classifier = nn.Sequential(\n            # nn.Linear(feature_size, 512),\n            # nn.ReLU(),\n            # nn.Dropout(0.5),\n            # nn.Linear(512, 256),\n            nn.Linear(features[0], 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, volume, metadata=None):\n        # Extract features from 3D volume\n        features = self.backbone(volume)\n        # Global features for classification\n        global_features = self.global_pool(features).flatten(1)\n        classification_logits = self.classifier(global_features)\n        return classification_logits, None\n\n# ====================================================\n# WEIGHTED LOSS FUNCTION\n# ====================================================\n\nclass WeightedMultiLabelLoss(nn.Module):\n    def __init__(self, pos_weights=None, aneurysm_weight=13.0):\n        super().__init__()\n        self.pos_weights = pos_weights\n        self.aneurysm_weight = aneurysm_weight\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n        \n    def forward(self, logits, targets):\n        bce_loss = self.bce(logits, targets)\n        \n        # Apply position weights if provided\n        if self.pos_weights is not None:\n            bce_loss = bce_loss * self.pos_weights.to(logits.device)\n        \n        # Weight the \"Aneurysm Present\" class higher (last column)\n        weights = torch.ones_like(bce_loss)\n        weights[:, -1] = self.aneurysm_weight\n        \n        weighted_loss = bce_loss * weights\n        return weighted_loss.mean()\n\n\n# ====================================================\n# TRAINING FUNCTIONS\n# ====================================================\n\ndef compute_weighted_auc(y_true, y_pred):\n    \"\"\"Compute weighted AUC matching competition metric\"\"\"\n    aucs = []\n    weights = []\n    \n    for i in range(len(Config.LABEL_COLS)):\n        try:\n            auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n            aucs.append(auc)\n            # Weight \"Aneurysm Present\" (last column) higher\n            weights.append(13.0 if i == len(Config.LABEL_COLS) - 1 else 1.0)\n        except ValueError:\n            aucs.append(0.5)  # Default for no positive cases\n            weights.append(13.0 if i == len(Config.LABEL_COLS) - 1 else 1.0)\n    \n    weighted_auc = sum(a * w for a, w in zip(aucs, weights)) / sum(weights)\n    return weighted_auc, aucs\n\ndef train_epoch(model, train_loader, optimizer, criterion, scaler, device):\n    model.train()\n    total_loss = 0\n    num_batches = 0\n    skipped_batches = 0\n    \n    # Device verification for debugging\n    print(f\"🔧 Training on device: {device}\")\n    if hasattr(model, 'module'):  # DataParallel wrapped\n        print(f\"🔧 Model device (DataParallel): {next(model.module.parameters()).device}\")\n    else:\n        print(f\"🔧 Model device: {next(model.parameters()).device}\")\n    print(f\"🔧 Criterion on GPU: {hasattr(criterion, 'pos_weights') and criterion.pos_weights.device if hasattr(criterion, 'pos_weights') else 'N/A'}\")\n    \n    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Training Epoch\")):\n        start_time = time.time()\n        # Transfer data to GPU with non-blocking for better performance\n        volume = batch['volume'].to(device, non_blocking=True)\n        metadata = batch['metadata'].to(device, non_blocking=True)\n        labels = batch['labels'].to(device, non_blocking=True)\n        loc_mask = batch['localization_mask'].to(device, non_blocking=True)\n        \n        # Add GPU monitoring for first few batches\n        if batch_idx < 3:\n            gpu_mem_before = torch.cuda.memory_allocated(0) / 1e9\n            print(f\"  🔍 Batch {batch_idx}: GPU memory before forward: {gpu_mem_before:.2f}GB\")\n\n        # CRITICAL FIX: Skip batches with zero-filled volumes\n        if torch.all(volume == 0) or torch.var(volume) < 1e-6:\n            skipped_batches += 1\n            if batch_idx < 5:  # Log first few skips\n                print(f\"⚠️  Skipping batch {batch_idx}: zero-filled or low-variance volume\")\n            continue\n            \n        # Forward pass timing\n        forward_start = time.time()\n        with autocast(device_type=device.type, enabled=Config.MIXED_PRECISION):\n            class_logits, _ = model(volume, metadata)\n            total_loss_batch = criterion(class_logits, labels)\n        forward_time = time.time() - forward_start\n        \n        # Add detailed timing for first few batches\n        if batch_idx < 3:\n            gpu_mem_after = torch.cuda.memory_allocated(0) / 1e9\n            print(f\"  ⚡ Batch {batch_idx}: Forward pass: {forward_time:.3f}s, GPU memory after: {gpu_mem_after:.2f}GB\")\n            \n        # DEBUG: Check for extreme loss values\n        if total_loss_batch.item() > 1e7:\n            print(f\"🚨 Warning: Extreme loss in training batch {batch_idx}: {total_loss_batch.item():.2e}\")\n            print(f\"   Labels: {labels[0].cpu().numpy()}\")  # Print first sample's labels \n        \n        # Gradient accumulation and backward pass timing\n        backward_start = time.time()\n        scaled_loss = total_loss_batch / Config.GRADIENT_ACCUMULATION\n        scaler.scale(scaled_loss).backward()\n        backward_time = time.time() - backward_start\n        \n        if batch_idx < 3:\n            print(f\"  🔄 Batch {batch_idx}: Backward pass: {backward_time:.3f}s\")\n        \n        if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        \n        total_loss += total_loss_batch.item()\n        num_batches += 1\n\n        # Print timing for first few batches to identify bottlenecks\n        if batch_idx < 5:\n            batch_time = time.time() - start_time\n            print(f\"Batch {batch_idx}: {batch_time:.2f}s\")\n    \n    if skipped_batches > 0:\n        print(f\"⚠️  Skipped {skipped_batches} batches with corrupted/zero volumes\")\n    \n    return total_loss / max(num_batches, 1) if num_batches > 0 else float('inf')\n\ndef validate_epoch(model, val_loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    num_batches = 0\n    skipped_batches = 0\n    \n    with torch.no_grad():\n        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"Validating\")):\n            volume = batch['volume'].to(device)\n            metadata = batch['metadata'].to(device)\n            labels = batch['labels'].to(device)\n            \n            # CRITICAL FIX: Skip batches with zero-filled volumes\n            if torch.all(volume == 0) or torch.var(volume) < 1e-6:\n                skipped_batches += 1\n                if batch_idx < 3:  # Log first few skips\n                    print(f\"⚠️  Skipping validation batch {batch_idx}: zero-filled or low-variance volume\")\n                continue\n            \n            with autocast(device_type=device.type, enabled=Config.MIXED_PRECISION):\n                class_logits, _ = model(volume, metadata)\n                loss = criterion(class_logits, labels)\n\n                # DEBUG: Check for extreme loss values\n                if loss.item() > 1e7:\n                    print(f\"🚨 Warning: Extreme loss in validation batch {batch_idx}: {loss.item():.2e}\")\n                    print(f\"   Labels: {labels[0].cpu().numpy()}\")  # Print first sample's labels\n            \n            total_loss += loss.item()\n            num_batches += 1\n            \n            # Collect predictions for AUC calculation\n            probs = torch.sigmoid(class_logits).cpu().numpy()\n            all_preds.append(probs)\n            all_labels.append(labels.cpu().numpy())\n\n    if skipped_batches > 0:\n        print(f\"⚠️  Skipped {skipped_batches} validation batches with corrupted/zero volumes\")\n    \n    if len(all_preds) == 0:\n        print(\"🚨 WARNING: No valid validation batches - all were corrupted!\")\n        return float('inf'), 0.5, [0.5] * len(Config.LABEL_COLS)\n    \n    all_preds = np.vstack(all_preds)\n    all_labels = np.vstack(all_labels)\n    \n    weighted_auc, individual_aucs = compute_weighted_auc(all_labels, all_preds)\n    \n    return total_loss / max(num_batches, 1), weighted_auc, individual_aucs\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:18:20.492949Z","iopub.execute_input":"2025-08-05T12:18:20.493681Z","iopub.status.idle":"2025-08-05T12:18:20.554121Z","shell.execute_reply.started":"2025-08-05T12:18:20.493652Z","shell.execute_reply":"2025-08-05T12:18:20.553493Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ====================================================\n# MAIN TRAINING EXECUTION\n# ====================================================\n\ndef main():\n    print(f\"Using device: {Config.DEVICE}\")\n    print(f\"Mixed precision: {Config.MIXED_PRECISION}\")\n    if torch.cuda.is_available():\n        print(f\"GPU devices available: {torch.cuda.device_count()}\")\n        for i in range(torch.cuda.device_count()):\n            gpu_mem = torch.cuda.get_device_properties(i).total_memory / 1e9\n            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)} ({gpu_mem:.1f}GB)\")\n    print(f\"Optimized settings - Batch size: {Config.BATCH_SIZE}, Workers: 6/4 (Conservative)\")\n    \n    # Load data\n    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n    localizer_df = pd.read_csv(Config.LOCALIZER_CSV_PATH)\n\n    print(\"---!!! RUNNING IN DEBUG MODE ON A SMALL SUBSET !!!---\")\n    #print(f\"Training samples: {len(train_df)}\")\n    train_df = train_df.head(100)  # Limit to 100 samples for speed testing\n    print(f\"Training samples: {len(train_df)} (limited for speed testing)\")\n    print(f\"Positive aneurysm cases: {train_df['Aneurysm Present'].sum()}\")\n\n    # Calculate class weights for imbalanced data\n    pos_counts = train_df[Config.LABEL_COLS].sum()\n    neg_counts = len(train_df) - pos_counts\n    pos_weights = neg_counts / (pos_counts + 1e-8)  # Add small epsilon\n    pos_weights = np.minimum(pos_weights, 100.0)  # Cap weights at 100\n    pos_weights = torch.tensor(pos_weights, dtype=torch.float32)  # Convert to tensor\n    print(\"Class weights (capped at 100):\", pos_weights)\n\n    # DATASET INTEGRITY CHECK\n    print(\"\\n🔍 Checking dataset integrity...\")\n    valid_series = 0\n    invalid_series = []\n    \n    for series_id in train_df[Config.ID_COL]:\n        series_path = os.path.join(Config.SERIES_DIR, series_id)\n        if os.path.exists(series_path):\n            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n            if dicom_files:\n                valid_series += 1\n            else:\n                invalid_series.append(f\"No DICOMs: {series_id}\")\n        else:\n            invalid_series.append(f\"Missing path: {series_id}\")\n    \n    success_rate = valid_series / len(train_df)\n    print(f\"📊 Dataset check: {valid_series}/{len(train_df)} series valid ({success_rate:.1%})\")\n    \n    if success_rate < 0.7:\n        print(f\"🚨 WARNING: Only {success_rate:.1%} of series are accessible!\")\n        print(\"First few issues:\")\n        for issue in invalid_series[:5]:\n            print(f\"  - {issue}\")\n        print(f\"⚠️  Training will proceed, but expect many corrupted DICOM errors\")\n    else:\n        print(f\"✅ Good dataset integrity ({success_rate:.1%} valid)\")\n        \n    print()\n\n    # Initialize corrupted series log (legacy compatibility)\n    with open('corrupted_series.txt', 'w') as f:\n        f.write(\"# Corrupted series log - check this file to identify problematic DICOM series\\n\")\n    print(\"📝 Initialized 'corrupted_series.txt' for logging corrupted series\")\n    print(\"🔍 Enhanced corruption tracking enabled with detailed analysis\")\n    \n    # Create stratified group k-fold split\n    # Use patient-level grouping to prevent data leakage\n    train_df['patient_group'] = train_df['PatientID'] if 'PatientID' in train_df.columns else range(len(train_df))\n    \n    skf = StratifiedGroupKFold(n_splits=Config.N_FOLDS, shuffle=True, random_state=42)\n    train_df['fold'] = -1\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(\n        train_df, train_df['Aneurysm Present'], groups=train_df['patient_group']\n    )):\n        train_df.loc[val_idx, 'fold'] = fold\n    \n    # Initialize processor\n    processor = AdvancedDICOMProcessor()\n    \n    # Train models for each fold\n    fold_scores = []\n    \n    for fold in range(Config.N_FOLDS):\n        print(f\"\\n{'='*50}\")\n        print(f\"FOLD {fold + 1}/{Config.N_FOLDS}\")\n        print(f\"{'='*50}\")\n        \n        # Split data\n        train_fold_df = train_df[train_df['fold'] != fold].reset_index(drop=True)\n        val_fold_df = train_df[train_df['fold'] == fold].reset_index(drop=True)\n        \n        print(f\"Train: {len(train_fold_df)}, Validation: {len(val_fold_df)}\")\n        \n        # Create datasets\n        train_dataset = EnhancedAneurysmDataset(\n            train_fold_df, localizer_df, Config.SERIES_DIR, processor, mode='train', fold=fold\n        )\n        val_dataset = EnhancedAneurysmDataset(\n            val_fold_df, localizer_df, Config.SERIES_DIR, processor, mode='val', fold=fold,\n            shared_mean_volume=train_dataset.mean_volume\n        )\n        \n        # Create data loaders with conservative settings for stability\n        train_loader = DataLoader(\n            train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, \n            num_workers=6, pin_memory=True, drop_last=True, \n            prefetch_factor=2, persistent_workers=True\n        )\n        val_loader = DataLoader(\n            val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, \n            num_workers=4, pin_memory=True, prefetch_factor=2, persistent_workers=True\n        )\n        \n        # Initialize model\n        model = SimplifiedAneurysmNet().to(Config.DEVICE)\n        # Enable multi-GPU training if available\n        if torch.cuda.device_count() > 1:\n            print(f\"🚀 Using {torch.cuda.device_count()} GPUs for training\")\n            model = nn.DataParallel(model)\n        else:\n            print(f\"📱 Using single GPU: {Config.DEVICE}\")\n        criterion = WeightedMultiLabelLoss(pos_weights=pos_weights).to(Config.DEVICE)\n        \n        # Optimizer with different learning rates for different parts\n        # optimizer = optim.AdamW([\n        #     {'params': model.backbone.parameters(), 'lr': Config.LEARNING_RATE},\n        #     {'params': model.classifier.parameters(), 'lr': Config.LEARNING_RATE * 2},\n        #     {'params': model.metadata_mlp.parameters(), 'lr': Config.LEARNING_RATE * 2}\n        # ], weight_decay=Config.WEIGHT_DECAY)\n        optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n        \n        # Learning rate scheduler\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            optimizer, T_0=10, T_mult=2, eta_min=1e-6\n        )\n        \n        scaler = GradScaler(enabled=Config.MIXED_PRECISION)\n        \n        # Training loop\n        best_auc = 0\n        patience = 10\n        patience_counter = 0\n        \n        for epoch in range(Config.EPOCHS):\n            # Train\n            train_loss = train_epoch(model, train_loader, optimizer, criterion, scaler, Config.DEVICE)\n            \n            # Validate\n            val_loss, val_auc, individual_aucs = validate_epoch(model, val_loader, criterion, Config.DEVICE)\n            \n            # Step scheduler\n            scheduler.step()\n            \n            print(f\"Epoch {epoch+1:3d} | \"\n                  f\"Train Loss: {train_loss:.4f} | \"\n                  f\"Val Loss: {val_loss:.4f} | \"\n                  f\"Val AUC: {val_auc:.4f}\")\n\n            # Print comprehensive DICOM stats and analyze corruption patterns\n            processor.print_stats()\n            \n            # Analyze corruption patterns (every 2 epochs to avoid spam)\n            if epoch % 2 == 0:\n                processor.analyze_corruption_patterns()\n\n            # Check legacy corrupted series log (for compatibility)\n            try:\n                with open('corrupted_series.txt', 'r') as f:\n                    lines = f.readlines()\n                    corrupted_count = len([l for l in lines if not l.startswith('#')])\n                    if corrupted_count > 0:\n                        print(f\"📄 Legacy corruption log: {corrupted_count} entries in 'corrupted_series.txt'\")\n            except FileNotFoundError:\n                pass  # Expected if no legacy logging occurred\n\n            # SANITY CHECK: Stop if data loading is fundamentally broken\n            if processor.stats['total_loaded'] > 20:  # Only check after some attempts\n                success_rate = processor.stats['successful_loads'] / processor.stats['total_loaded']\n                if success_rate < 0.5:  # Less than 50% success rate\n                    print(f\"\\n🚨 STOPPING TRAINING: Data loading success rate is {success_rate:.1%}\")\n                    print(\"Fix the DICOM loading issues before continuing training!\")\n                    print(\"Most volumes are returning empty - this is a waste of time!\")\n                    break\n            \n            # Save best model\n            if val_auc > best_auc:\n                best_auc = val_auc\n                patience_counter = 0\n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'scheduler_state_dict': scheduler.state_dict(),\n                    'val_auc': val_auc,\n                    'epoch': epoch,\n                    'fold': fold,\n                    'individual_aucs': individual_aucs\n                }, f'best_model_fold_{fold}.pth')\n            else:\n                patience_counter += 1\n                \n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n                \n            # Memory cleanup\n            if epoch % 5 == 0:\n                gc.collect()\n                torch.cuda.empty_cache()\n        \n        fold_scores.append(best_auc)\n        print(f\"Fold {fold + 1} best AUC: {best_auc:.4f}\")\n    \n    # Final results\n    mean_cv_score = np.mean(fold_scores)\n    std_cv_score = np.std(fold_scores)\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"CROSS-VALIDATION RESULTS\")\n    print(f\"{'='*50}\")\n    print(f\"Mean CV AUC: {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n    print(f\"Individual fold scores: {fold_scores}\")\n    \n    # Save training summary\n    results = {\n        'cv_scores': fold_scores,\n        'mean_cv_score': mean_cv_score,\n        'std_cv_score': std_cv_score,\n        'config': vars(Config())\n    }\n    \n    with open('training_results.json', 'w') as f:\n        json.dump(results, f, indent=2, default=str)\n    \n    print(\"Training complete! Models saved as 'best_model_fold_X.pth'\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:18:28.889695Z","iopub.execute_input":"2025-08-05T12:18:28.88994Z","execution_failed":"2025-08-05T12:26:25.225Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nMixed precision: True\nGPU devices available: 2\n  GPU 0: Tesla T4 (15.8GB)\n  GPU 1: Tesla T4 (15.8GB)\nOptimized settings - Batch size: 16, Workers: 6/4 (Conservative)\n---!!! RUNNING IN DEBUG MODE ON A SMALL SUBSET !!!---\nTraining samples: 100 (limited for speed testing)\nPositive aneurysm cases: 48\nClass weights (capped at 100): tensor([ 32.3333,  49.0000,  13.2857,   9.0000,  49.0000,  11.5000,  10.1111,\n         99.0000,  49.0000,  49.0000, 100.0000,  32.3333,  49.0000,   1.0833])\n\n🔍 Checking dataset integrity...\n📊 Dataset check: 100/100 series valid (100.0%)\n✅ Good dataset integrity (100.0% valid)\n\n📝 Initialized 'corrupted_series.txt' for logging corrupted series\n🔍 Enhanced corruption tracking enabled with detailed analysis\n\n==================================================\nFOLD 1/3\n==================================================\nTrain: 66, Validation: 34\n🔄 Computing mean volume fallback from valid series...\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10004684224894397679901841656954650085: Found 147 DICOM files\n✅ Successfully loaded 147 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10004684224894397679901841656954650085\n✅ Consistent shapes: (512, 512) across 147 slices\n✅ Final volume: (147, 512, 512) from 147 slices\n  ✅ Valid volume 1/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317: Found 276 DICOM files\n✅ Successfully loaded 276 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317\n✅ Consistent shapes: (512, 512) across 276 slices\n✅ Final volume: (276, 512, 512) from 276 slices\n  ✅ Valid volume 2/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.75206494637570575939256404615022232157.dcm: Invalid dimensions (150, 528, 528)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10014757658335054766479957992112625961: Found 856 DICOM files\n✅ Successfully loaded 856 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10014757658335054766479957992112625961\n✅ Consistent shapes: (512, 512) across 856 slices\n✅ Final volume: (856, 512, 512) from 856 slices\n  ✅ Valid volume 4/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105: Found 178 DICOM files\n✅ Successfully loaded 178 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105\n✅ Consistent shapes: (768, 696) across 178 slices\n✅ Final volume: (178, 768, 696) from 178 slices\n  ✅ Valid volume 5/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831: Found 671 DICOM files\n✅ Successfully loaded 671 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831\n✅ Consistent shapes: (512, 512) across 671 slices\n✅ Final volume: (671, 512, 512) from 671 slices\n  ✅ Valid volume 6/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636: Found 205 DICOM files\n✅ Successfully loaded 205 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636\n✅ Consistent shapes: (512, 512) across 205 slices\n✅ Final volume: (205, 512, 512) from 205 slices\n  ✅ Valid volume 7/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10030804647049037739144303822498146901: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10030804647049037739144303822498146901:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.12788534311541061134282993296707574954.dcm: Invalid dimensions (25, 512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557: Found 83 DICOM files\n✅ Successfully loaded 83 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557\n✅ Consistent shapes: (512, 512) across 83 slices\n✅ Final volume: (83, 512, 512) from 83 slices\n  ✅ Valid volume 9/10: (32, 64, 64)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10035782880104673269567641444954004745: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10035782880104673269567641444954004745:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.12512789258062887712849260043950985853.dcm: Invalid dimensions (150, 480, 480)\n📊 Mean volume computed from 7 valid series: (32, 64, 64)\n🎯 Mean volume fallback ready (shape: (32, 64, 64))\n🔄 Using shared mean volume fallback (shape: (32, 64, 64))\nBasicUNet features: (16, 32, 64, 128, 256, 51).\n🚀 Using 2 GPUs for training\n🔧 Training on device: cuda\n🔧 Model device (DataParallel): cuda:0\n🔧 Criterion on GPU: cpu\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"🔍 Loading series 1.2.826.0.1.3680043.8.498.10058383541003792190302541266378919328: Found 88 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10221223003274066645389576091413528073: Found 191 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10168980078157176521154364692096920137: Found 52 DICOM files\n\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831: Found 671 DICOM files\n\n✅ Successfully loaded 52 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10168980078157176521154364692096920137\n✅ Consistent shapes: (320, 256) across 52 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105: Found 178 DICOM files\n✅ Successfully loaded 88 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10058383541003792190302541266378919328\n✅ Consistent shapes: (512, 512) across 88 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10232731436838657115800303234983509594: Found 30 DICOM files\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10232731436838657115800303234983509594\n✅ Consistent shapes: (640, 640) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10046318991957083423208748012349179640: Found 136 DICOM files\n✅ Successfully loaded 136 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10046318991957083423208748012349179640\n✅ Consistent shapes: (512, 512) across 136 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10048925006598672000564912882060003872: Found 594 DICOM files\n✅ Successfully loaded 178 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105\n✅ Consistent shapes: (768, 696) across 178 slices\nSample 4: DICOM load: 9.09s, Preprocess: 2.33s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10095912539619532839962135126795591815: Found 240 DICOM files\n✅ Successfully loaded 671 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831\n✅ Consistent shapes: (512, 512) across 671 slices\n✅ Successfully loaded 240 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10095912539619532839962135126795591815\n✅ Consistent shapes: (512, 512) across 240 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10232762689430514958235799084476946744: Found 231 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242908234090194014051186313014188903: Found 108 DICOM files\n✅ Successfully loaded 191 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10221223003274066645389576091413528073\n✅ Consistent shapes: (1024, 1024) across 191 slices\n✅ Successfully loaded 108 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242908234090194014051186313014188903\n✅ Consistent shapes: (512, 512) across 108 slices\n✅ Successfully loaded 231 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10232762689430514958235799084476946744\n✅ Consistent shapes: (256, 256) across 231 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10149517800497200117971642051961114300: Found 40 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10252642992827581995791460041128469049: Found 148 DICOM files\n✅ Successfully loaded 40 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10149517800497200117971642051961114300\n✅ Consistent shapes: (288, 288) across 40 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10229915682372012073055285556885310225: Found 204 DICOM files\n✅ Successfully loaded 594 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10048925006598672000564912882060003872\n✅ Consistent shapes: (512, 512) across 594 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10240701911188793595728082556212433173: Found 140 DICOM files\n✅ Successfully loaded 148 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10252642992827581995791460041128469049\n✅ Consistent shapes: (512, 512) across 148 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10093305095697542087736136017987424145: Found 96 DICOM files\n✅ Successfully loaded 204 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10229915682372012073055285556885310225\n✅ Consistent shapes: (512, 512) across 204 slices\n✅ Successfully loaded 140 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10240701911188793595728082556212433173\n✅ Consistent shapes: (352, 352) across 140 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636: Found 205 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10220365367013559992095908932821694373: Found 191 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10257249310194962131618310444401032418: Found 843 DICOM files\n✅ Successfully loaded 96 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10093305095697542087736136017987424145\n✅ Consistent shapes: (512, 512) across 96 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10192011262895867728128531292507199782: Found 737 DICOM files\n✅ Successfully loaded 191 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10220365367013559992095908932821694373\n✅ Consistent shapes: (384, 348) across 191 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10118104902601294641571465174067732646: Found 321 DICOM files\n✅ Successfully loaded 205 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636\n✅ Consistent shapes: (512, 512) across 205 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10076056930521523789588901704956188485: Found 136 DICOM files\n✅ Successfully loaded 321 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10118104902601294641571465174067732646\n✅ Consistent shapes: (512, 512) across 321 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10195070873338721244150818495996796822: Found 289 DICOM files\n✅ Successfully loaded 136 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10076056930521523789588901704956188485\n✅ Consistent shapes: (1024, 1024) across 136 slices\n✅ Successfully loaded 289 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10195070873338721244150818495996796822\n✅ Consistent shapes: (512, 512) across 289 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10042423585566957032411171949972906248: Found 116 DICOM files\n✅ Successfully loaded 737 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10192011262895867728128531292507199782\n⚠️  Shape inconsistency in 1.2.826.0.1.3680043.8.498.10192011262895867728128531292507199782: Found 2 different shapes. Most common: (512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10183727561065274266314159653049375993: Found 35 DICOM files\n✅ Successfully loaded 35 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10183727561065274266314159653049375993\n✅ Consistent shapes: (320, 280) across 35 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317: Found 276 DICOM files\n✅ Successfully loaded 116 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10042423585566957032411171949972906248\n✅ Consistent shapes: (512, 452) across 116 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10083588592953106038022099657923782077: Found 24 DICOM files\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10083588592953106038022099657923782077\n✅ Consistent shapes: (512, 512) across 24 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10063454172499468887877935052136698373: Found 2 DICOM files\n✅ Successfully loaded 2 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10063454172499468887877935052136698373\n✅ Consistent shapes: (464, 704) across 2 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10245631466184909766661730547792670102: Found 21 DICOM files\n✅ Successfully loaded 843 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10257249310194962131618310444401032418\n✅ Successfully loaded 21 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10245631466184909766661730547792670102\n✅ Consistent shapes: (512, 512) across 843 slices\n✅ Consistent shapes: (512, 512) across 21 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10212302880573111557869412819411272803: Found 200 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10100852389239445465234081623205886374: Found 1 DICOM files\n✅ Successfully loaded 276 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317\n✅ Consistent shapes: (512, 512) across 276 slices\nSample 1: DICOM load: 6.13s, Preprocess: 1.38s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10140895167100232412095668871893964095: Found 188 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10100852389239445465234081623205886374:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.31251320957940292666601357417618570765.dcm: Invalid dimensions (150, 480, 480)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10098743283291956051221530305664415374: Found 44 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10177991619943313403139905685327320608: Found 27 DICOM files\n✅ Successfully loaded 27 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10177991619943313403139905685327320608\n✅ Consistent shapes: (320, 320) across 27 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10040419508532196461125208817600495772: Found 188 DICOM files\n✅ Successfully loaded 44 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10098743283291956051221530305664415374\n✅ Consistent shapes: (512, 512) across 44 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10133777372284957640897520050991895887: Found 45 DICOM files\n✅ Successfully loaded 200 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10212302880573111557869412819411272803\n✅ Consistent shapes: (512, 512) across 200 slices\n✅ Successfully loaded 45 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10133777372284957640897520050991895887\n✅ Consistent shapes: (448, 392) across 45 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10073947840865129766563613260212070964: Found 120 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10116626135148932224643146695383345963: Found 24 DICOM files\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10116626135148932224643146695383345963\n✅ Consistent shapes: (512, 512) across 24 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10184847787867063803105367841107558567: Found 164 DICOM files\n✅ Successfully loaded 188 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10040419508532196461125208817600495772\n✅ Successfully loaded 120 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10073947840865129766563613260212070964\n✅ Consistent shapes: (512, 512) across 120 slices\n✅ Consistent shapes: (512, 512) across 188 slices\n✅ Successfully loaded 188 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10140895167100232412095668871893964095\n✅ Consistent shapes: (512, 512) across 188 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10158065843180867652384529862983576761: Found 116 DICOM files\n✅ Successfully loaded 164 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10184847787867063803105367841107558567\n✅ Consistent shapes: (384, 300) across 164 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10068453918327434625947056516458124159: Found 242 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557: Found 83 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10052893794239333131781802642788307307: Found 74 DICOM files\n✅ Successfully loaded 83 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557\n✅ Consistent shapes: (512, 512) across 83 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10122841756457641138155875644216826804: Found 1 DICOM files\n✅ Successfully loaded 74 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10052893794239333131781802642788307307\n✅ Consistent shapes: (512, 512) across 74 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10126487256624050201543415947047895825: Found 898 DICOM files\n✅ Successfully loaded 116 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10158065843180867652384529862983576761\n✅ Consistent shapes: (512, 456) across 116 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10159052987439329819869659161075958798: Found 24 DICOM files\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10159052987439329819869659161075958798\n✅ Consistent shapes: (512, 512) across 24 slices\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10122841756457641138155875644216826804:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.18155697113448637526398174722597847630.dcm: Invalid dimensions (150, 560, 560)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10152316071300066886893512484432664805: Found 120 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657: Found 1 DICOM files\n✅ Successfully loaded 120 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10152316071300066886893512484432664805\n✅ Consistent shapes: (512, 512) across 120 slices\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.75206494637570575939256404615022232157.dcm: Invalid dimensions (150, 528, 528)\nSample 2: DICOM load: 2.71s, Preprocess: 0.01s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10247439373520422169955747183361551750: Found 26 DICOM files\n✅ Successfully loaded 242 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10068453918327434625947056516458124159\n✅ Consistent shapes: (640, 580) across 242 slices\n✅ Successfully loaded 26 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10247439373520422169955747183361551750\n✅ Consistent shapes: (512, 512) across 26 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10126204714343951399034097831014403155: Found 150 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242234264937443187831558438826464608: Found 56 DICOM files\n✅ Successfully loaded 56 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242234264937443187831558438826464608\n✅ Consistent shapes: (512, 512) across 56 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10144083517869641752799954597390552857: Found 194 DICOM files\n✅ Successfully loaded 150 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10126204714343951399034097831014403155\n✅ Consistent shapes: (512, 512) across 150 slices\n✅ Successfully loaded 194 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10144083517869641752799954597390552857\n✅ Consistent shapes: (512, 512) across 194 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10101061475536996465167813138158739213: Found 175 DICOM files\n✅ Successfully loaded 175 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10101061475536996465167813138158739213\n✅ Consistent shapes: (576, 522) across 175 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10134365079002163886508836892471866754: Found 1 DICOM files\n✅ Successfully loaded 898 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10126487256624050201543415947047895825\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10134365079002163886508836892471866754:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.12524552726742591936607820382077304797.dcm: Invalid dimensions (150, 512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10030804647049037739144303822498146901: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10030804647049037739144303822498146901:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:✅ Consistent shapes: (512, 512) across 898 slices\n\n  1.2.826.0.1.3680043.8.498.12788534311541061134282993296707574954.dcm: Invalid dimensions (25, 512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10177117050965285724806213067235546942: Found 47 DICOM files\n✅ Successfully loaded 47 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10177117050965285724806213067235546942\n✅ Consistent shapes: (512, 512) across 47 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10035782880104673269567641444954004745: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10035782880104673269567641444954004745:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.12512789258062887712849260043950985853.dcm: Invalid dimensions (150, 480, 480)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10161806953566875622930260306554507426: Found 124 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10215833141558976135001043369327881438: Found 24 DICOM files\n✅ Successfully loaded 124 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10161806953566875622930260306554507426\n✅ Consistent shapes: (512, 512) across 124 slices\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10215833141558976135001043369327881438\n✅ Consistent shapes: (896, 896) across 24 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10145340168188681268595785827168799711: Found 23 DICOM files\n✅ Successfully loaded 23 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10145340168188681268595785827168799711\n✅ Consistent shapes: (1024, 1024) across 23 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10170698207397181808858428764907250482: Found 307 DICOM files\n✅ Successfully loaded 307 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10170698207397181808858428764907250482\n✅ Consistent shapes: (512, 512) across 307 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10086325220791440678552106812785190149: Found 82 DICOM files\n✅ Successfully loaded 82 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10086325220791440678552106812785190149\n✅ Consistent shapes: (512, 512) across 82 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10163482612339017493097015030860956863: Found 302 DICOM files\n✅ Successfully loaded 302 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10163482612339017493097015030860956863\n✅ Consistent shapes: (512, 512) across 302 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10129540112106776730428126836684374398: Found 80 DICOM files\n✅ Successfully loaded 80 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10129540112106776730428126836684374398\n✅ Consistent shapes: (768, 768) across 80 slices\n  🔍 Batch 0: GPU memory before forward: 0.04GB\n  ⚡ Batch 0: Forward pass: 1.336s, GPU memory after: 1.11GB\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:  25%|██▌       | 1/4 [02:03<06:10, 123.50s/it]","output_type":"stream"},{"name":"stdout","text":"  🔄 Batch 0: Backward pass: 0.286s\nBatch 0: 1.74s\n  🔍 Batch 1: GPU memory before forward: 0.07GB\n  ⚡ Batch 1: Forward pass: 0.091s, GPU memory after: 1.14GB\n  🔄 Batch 1: Backward pass: 0.013s\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:  50%|█████     | 2/4 [02:03<01:41, 50.98s/it] ","output_type":"stream"},{"name":"stdout","text":"Batch 1: 0.21s\n  🔍 Batch 2: GPU memory before forward: 0.08GB\n  ⚡ Batch 2: Forward pass: 0.085s, GPU memory after: 1.14GB\n  🔄 Batch 2: Backward pass: 0.012s\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:  75%|███████▌  | 3/4 [02:03<00:27, 27.79s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 2: 0.20s\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch: 100%|██████████| 4/4 [02:04<00:00, 31.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Batch 3: 0.33s\n","output_type":"stream"},{"name":"stderr","text":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"🔍 Loading series 1.2.826.0.1.3680043.8.498.10129580404994628606227497184499173213: Found 313 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10256018119694768427929632156620347034: Found 180 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647: Found 188 DICOM files\n\n\n✅ Successfully loaded 188 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647\n✅ Consistent shapes: (512, 512) across 188 slices\nSample 0: DICOM load: 5.77s, Preprocess: 0.79s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10009383108068795488741533244914370182: Found 224 DICOM files\n✅ Successfully loaded 313 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10129580404994628606227497184499173213\n✅ Consistent shapes: (512, 512) across 313 slices\n✅ Successfully loaded 180 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10256018119694768427929632156620347034\n✅ Consistent shapes: (1008, 1008) across 180 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10133805409448598100180344093077653742: Found 554 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10264784704607431871981917026977073042: Found 168 DICOM files\n✅ Successfully loaded 224 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10009383108068795488741533244914370182\n✅ Consistent shapes: (768, 696) across 224 slices\n✅ Successfully loaded 168 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10264784704607431871981917026977073042\n✅ Consistent shapes: (512, 512) across 168 slices\nSample 1: DICOM load: 11.44s, Preprocess: 2.00s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10021411248005513321236647460239137906: Found 239 DICOM files\n✅ Successfully loaded 239 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10021411248005513321236647460239137906\n✅ Consistent shapes: (512, 512) across 239 slices\n✅ Successfully loaded 554 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10133805409448598100180344093077653742\n✅ Consistent shapes: (512, 512) across 554 slices\nSample 2: DICOM load: 6.97s, Preprocess: 1.31s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10030095840917973694487307992374923817: Found 451 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10143240284902513794767720489625125957: Found 240 DICOM files\n✅ Successfully loaded 240 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10143240284902513794767720489625125957\n✅ Consistent shapes: (512, 512) across 240 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10148992367063193735584459523736151066: Found 139 DICOM files\n✅ Successfully loaded 139 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10148992367063193735584459523736151066\n✅ Consistent shapes: (256, 254) across 139 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10157259652665015386051954194840128811: Found 359 DICOM files\n✅ Successfully loaded 451 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10030095840917973694487307992374923817\n✅ Consistent shapes: (512, 512) across 451 slices\nSample 3: DICOM load: 10.48s, Preprocess: 1.97s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10035643165968342618460849823699311381: Found 228 DICOM files\n✅ Successfully loaded 359 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10157259652665015386051954194840128811\n✅ Consistent shapes: (512, 512) across 359 slices\n✅ Successfully loaded 228 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10035643165968342618460849823699311381\n✅ Consistent shapes: (512, 512) across 228 slices\nSample 4: DICOM load: 5.33s, Preprocess: 1.17s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10037266473301611864455091971206084528: Found 201 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10161092109954976473450555831085144960: Found 284 DICOM files\n✅ Successfully loaded 284 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10161092109954976473450555831085144960\n✅ Successfully loaded 201 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10037266473301611864455091971206084528\n✅ Consistent shapes: (512, 512) across 284 slices\n✅ Consistent shapes: (768, 696) across 201 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10163827504601437014258638041508575801: Found 75 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10042474696169267476037627878420766468: Found 587 DICOM files\n✅ Successfully loaded 75 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10163827504601437014258638041508575801\n✅ Consistent shapes: (584, 512) across 75 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10172626607552095496094268567506878754: Found 561 DICOM files\n✅ Successfully loaded 587 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10042474696169267476037627878420766468\n✅ Consistent shapes: (512, 512) across 587 slices\n✅ Successfully loaded 561 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10172626607552095496094268567506878754\n✅ Consistent shapes: (512, 512) across 561 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10057981374227560278263065500472865434: Found 723 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10186041198879318410917325125181341286: Found 30 DICOM files\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10186041198879318410917325125181341286\n✅ Consistent shapes: (512, 512) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10188636688783982623025997809119805350: Found 136 DICOM files\n✅ Successfully loaded 136 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10188636688783982623025997809119805350\n✅ Consistent shapes: (384, 314) across 136 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10207110118916220264491289532161991004: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10207110118916220264491289532161991004:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.35987680962070754560160756829496799559.dcm: Invalid dimensions (24, 528, 528)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10218616184968326770042507305824538520: Found 359 DICOM files\n✅ Successfully loaded 359 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10218616184968326770042507305824538520\n✅ Consistent shapes: (240, 320) across 359 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10230011967368070546203100023298616413: Found 144 DICOM files\n✅ Successfully loaded 144 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10230011967368070546203100023298616413\n✅ Consistent shapes: (512, 512) across 144 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10237346404947508483392228545497384153: Found 205 DICOM files\n✅ Successfully loaded 723 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10057981374227560278263065500472865434\n✅ Successfully loaded 205 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10237346404947508483392228545497384153\n✅ Consistent shapes: (512, 512) across 723 slices\n✅ Consistent shapes: (512, 512) across 205 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242740813399049394757933972926370746: Found 158 DICOM files\n✅ Successfully loaded 158 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242740813399049394757933972926370746\n✅ Consistent shapes: (512, 512) across 158 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10058588444796585220635465116646088095: Found 30 DICOM files\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10058588444796585220635465116646088095\n✅ Consistent shapes: (256, 208) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10070371997983281654193426002305027111: Found 30 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242915350197711554605463577659482013: Found 19 DICOM files\n✅ Successfully loaded 19 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242915350197711554605463577659482013\n✅ Consistent shapes: (512, 512) across 19 slices\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10070371997983281654193426002305027111\n✅ Consistent shapes: (512, 512) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10077108087009955586144859725246456654: Found 31 DICOM files\n✅ Successfully loaded 31 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10077108087009955586144859725246456654\n⚠️  Shape inconsistency in 1.2.826.0.1.3680043.8.498.10077108087009955586144859725246456654: Found 2 different shapes. Most common: (584, 584)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10092666779602341135460882241562348436: Found 281 DICOM files\n✅ Successfully loaded 281 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10092666779602341135460882241562348436\n✅ Consistent shapes: (512, 512) across 281 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10097649530131165889513682791963111629: Found 175 DICOM files\n✅ Successfully loaded 175 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10097649530131165889513682791963111629\n✅ Consistent shapes: (768, 696) across 175 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10102361048562788202568222767625052953: Found 164 DICOM files\n✅ Successfully loaded 164 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10102361048562788202568222767625052953\n✅ Consistent shapes: (384, 300) across 164 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10118061831005170945889563029918713432: Found 169 DICOM files\n✅ Successfully loaded 169 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10118061831005170945889563029918713432\n✅ Consistent shapes: (512, 512) across 169 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10125437190727527270716129219120957188: Found 20 DICOM files\n✅ Successfully loaded 20 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10125437190727527270716129219120957188\n✅ Consistent shapes: (512, 512) across 20 slices\n","output_type":"stream"},{"name":"stderr","text":"Validating: 100%|██████████| 3/3 [01:54<00:00, 38.13s/it] \n","output_type":"stream"},{"name":"stdout","text":"Epoch   1 | Train Loss: 27.8750 | Val Loss: 27.3719 | Val AUC: 0.4746\n\n📊 === COMPREHENSIVE DICOM LOADING STATS ===\n📈 Total attempts: 10\n✅ Successful loads: 7/10 (70.0%)\n❌ Failed loads breakdown:\n   🚫 Empty volumes: 3 (30.0%)\n   📄 Invalid DICOM files: 0 (0.0%)\n   🗂️  Empty pixel arrays: 0 (0.0%)\n   💥 Corrupted pixel data: 0 (0.0%)\n   📐 Shape errors: 0 (0.0%)\n📊 Total corruption rate: 30.0%\n⚠️  Moderate success rate (70.0%) - some data quality issues\n   💡 Review detailed_corruption_log.txt for improvement opportunities\n📄 Detailed analysis available in: detailed_corruption_log.txt\n===============================\n\n🔍 === CORRUPTION PATTERN ANALYSIS ===\n📊 Unique series with errors: 9\n🏷️  Error type breakdown:\n   TOTAL_FAILURE: 10 occurrences\n   SHAPE_MISMATCH: 2 occurrences\n💡 Most common issue: TOTAL_FAILURE (10 cases)\n===============================\n🔧 Training on device: cuda\n🔧 Model device (DataParallel): cuda:0\n🔧 Criterion on GPU: cpu\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:   0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"🔍 Loading series 1.2.826.0.1.3680043.8.498.10145340168188681268595785827168799711: Found 23 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10240701911188793595728082556212433173: Found 140 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10048925006598672000564912882060003872: Found 594 DICOM files\n\n\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10126487256624050201543415947047895825: Found 898 DICOM files\n✅ Successfully loaded 140 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10240701911188793595728082556212433173\n✅ Consistent shapes: (352, 352) across 140 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10116626135148932224643146695383345963: Found 24 DICOM files\n✅ Successfully loaded 23 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10145340168188681268595785827168799711\n✅ Consistent shapes: (1024, 1024) across 23 slices\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10116626135148932224643146695383345963\n✅ Consistent shapes: (512, 512) across 24 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10133777372284957640897520050991895887: Found 45 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10257249310194962131618310444401032418: Found 843 DICOM files\n✅ Successfully loaded 45 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10133777372284957640897520050991895887\n✅ Consistent shapes: (448, 392) across 45 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831: Found 671 DICOM files\n✅ Successfully loaded 594 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10048925006598672000564912882060003872\n✅ Consistent shapes: (512, 512) across 594 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10073947840865129766563613260212070964: Found 120 DICOM files\n✅ Successfully loaded 120 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10073947840865129766563613260212070964\n✅ Consistent shapes: (512, 512) across 120 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10195070873338721244150818495996796822: Found 289 DICOM files\n✅ Successfully loaded 898 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10126487256624050201543415947047895825\n✅ Consistent shapes: (512, 512) across 898 slices\n✅ Successfully loaded 671 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831\n✅ Consistent shapes: (512, 512) across 671 slices\n✅ Successfully loaded 843 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10257249310194962131618310444401032418\n✅ Successfully loaded 289 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10195070873338721244150818495996796822\n✅ Consistent shapes: (512, 512) across 289 slices\n✅ Consistent shapes: (512, 512) across 843 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10076056930521523789588901704956188485: Found 136 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657: Found 1 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10014757658335054766479957992112625961: Found 856 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.75206494637570575939256404615022232157.dcm: Invalid dimensions (150, 528, 528)\nSample 2: DICOM load: 3.31s, Preprocess: 0.01s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10100852389239445465234081623205886374: Found 1 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10163482612339017493097015030860956863: Found 302 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10100852389239445465234081623205886374:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.31251320957940292666601357417618570765.dcm: Invalid dimensions (150, 480, 480)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10083588592953106038022099657923782077: Found 24 DICOM files\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10083588592953106038022099657923782077\n✅ Consistent shapes: (512, 512) across 24 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10004684224894397679901841656954650085: Found 147 DICOM files\n✅ Successfully loaded 147 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10004684224894397679901841656954650085\n✅ Consistent shapes: (512, 512) across 147 slices\nSample 0: DICOM load: 2.28s, Preprocess: 0.95s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10161806953566875622930260306554507426: Found 124 DICOM files\n✅ Successfully loaded 302 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10163482612339017493097015030860956863\n✅ Consistent shapes: (512, 512) across 302 slices\n✅ Successfully loaded 124 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10161806953566875622930260306554507426\n✅ Consistent shapes: (512, 512) across 124 slices\n✅ Successfully loaded 136 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10076056930521523789588901704956188485\n✅ Consistent shapes: (1024, 1024) across 136 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10030804647049037739144303822498146901: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10030804647049037739144303822498146901:🔍 Loading series 1.2.826.0.1.3680043.8.498.10158065843180867652384529862983576761: Found 116 DICOM files\n\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.12788534311541061134282993296707574954.dcm: Invalid dimensions (25, 512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10159052987439329819869659161075958798: Found 24 DICOM files\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10159052987439329819869659161075958798\n✅ Consistent shapes: (512, 512) across 24 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10184847787867063803105367841107558567: Found 164 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242234264937443187831558438826464608: Found 56 DICOM files\n✅ Successfully loaded 164 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10184847787867063803105367841107558567\n✅ Consistent shapes: (384, 300) across 164 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10168980078157176521154364692096920137: Found 52 DICOM files\n✅ Successfully loaded 56 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242234264937443187831558438826464608\n✅ Consistent shapes: (512, 512) across 56 slices\n✅ Successfully loaded 52 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10168980078157176521154364692096920137\n✅ Consistent shapes: (320, 256) across 52 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10192011262895867728128531292507199782: Found 737 DICOM files\n✅ Successfully loaded 116 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10158065843180867652384529862983576761\n✅ Consistent shapes: (512, 456) across 116 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10177991619943313403139905685327320608: Found 27 DICOM files\n✅ Successfully loaded 27 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10177991619943313403139905685327320608\n✅ Consistent shapes: (320, 320) across 27 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10140895167100232412095668871893964095: Found 188 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10134365079002163886508836892471866754: Found 1 DICOM files\n✅ Successfully loaded 856 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10014757658335054766479957992112625961\n✅ Consistent shapes: (512, 512) across 856 slices\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10134365079002163886508836892471866754:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.12524552726742591936607820382077304797.dcm: Invalid dimensions (150, 512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10093305095697542087736136017987424145: Found 96 DICOM files\n✅ Successfully loaded 96 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10093305095697542087736136017987424145\n✅ Consistent shapes: (512, 512) across 96 slices\n✅ Successfully loaded 188 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10140895167100232412095668871893964095\n✅ Consistent shapes: (512, 512) across 188 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10221223003274066645389576091413528073: Found 191 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10101061475536996465167813138158739213: Found 175 DICOM files\nSample 3: DICOM load: 19.10s, Preprocess: 5.03s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557: Found 83 DICOM files\n✅ Successfully loaded 83 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557\n✅ Consistent shapes: (512, 512) across 83 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10149517800497200117971642051961114300: Found 40 DICOM files\n✅ Successfully loaded 40 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10149517800497200117971642051961114300\n✅ Consistent shapes: (288, 288) across 40 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10232762689430514958235799084476946744: Found 231 DICOM files\n✅ Successfully loaded 175 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10101061475536996465167813138158739213\n✅ Consistent shapes: (576, 522) across 175 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10170698207397181808858428764907250482: Found 307 DICOM files\n✅ Successfully loaded 231 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10232762689430514958235799084476946744\n✅ Consistent shapes: (256, 256) across 231 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10220365367013559992095908932821694373: Found 191 DICOM files\n✅ Successfully loaded 191 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10220365367013559992095908932821694373\n✅ Consistent shapes: (384, 348) across 191 slices\n✅ Successfully loaded 737 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10192011262895867728128531292507199782\n⚠️  Shape inconsistency in 1.2.826.0.1.3680043.8.498.10192011262895867728128531292507199782: Found 2 different shapes. Most common: (512, 512)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105: Found 178 DICOM files\n✅ Successfully loaded 307 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10170698207397181808858428764907250482\n✅ Consistent shapes: (512, 512) across 307 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10245631466184909766661730547792670102: Found 21 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10215833141558976135001043369327881438: Found 24 DICOM files\n✅ Successfully loaded 21 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10245631466184909766661730547792670102\n✅ Consistent shapes: (512, 512) across 21 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10086325220791440678552106812785190149: Found 82 DICOM files\n✅ Successfully loaded 191 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10221223003274066645389576091413528073\n✅ Successfully loaded 24 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10215833141558976135001043369327881438\n✅ Consistent shapes: (896, 896) across 24 slices\n✅ Consistent shapes: (1024, 1024) across 191 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10126204714343951399034097831014403155: Found 150 DICOM files\n✅ Successfully loaded 82 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10086325220791440678552106812785190149\n✅ Consistent shapes: (512, 512) across 82 slices\n✅ Successfully loaded 178 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105\n✅ Consistent shapes: (768, 696) across 178 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10252642992827581995791460041128469049: Found 148 DICOM files\nSample 4: DICOM load: 9.50s, Preprocess: 2.56s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10095912539619532839962135126795591815: Found 240 DICOM files\n✅ Successfully loaded 148 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10252642992827581995791460041128469049\n✅ Consistent shapes: (512, 512) across 148 slices\n✅ Successfully loaded 150 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10126204714343951399034097831014403155\n✅ Consistent shapes: (512, 512) across 150 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10052893794239333131781802642788307307: Found 74 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10046318991957083423208748012349179640: Found 136 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10183727561065274266314159653049375993: Found 35 DICOM files\n✅ Successfully loaded 35 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10183727561065274266314159653049375993\n✅ Consistent shapes: (320, 280) across 35 slices\n  🔍 Batch 0: GPU memory before forward: 0.11GB\n  ⚡ Batch 0: Forward pass: 0.150s, GPU memory after: 1.16GB\n  🔄 Batch 0: Backward pass: 0.028s\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:  25%|██▌       | 1/4 [01:14<03:42, 74.04s/it]","output_type":"stream"},{"name":"stdout","text":"✅ Successfully loaded 74 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10052893794239333131781802642788307307\n✅ Consistent shapes: (512, 512) across 74 slices\nBatch 0: 0.32s\n✅ Successfully loaded 240 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10095912539619532839962135126795591815\n✅ Consistent shapes: (512, 512) across 240 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10177117050965285724806213067235546942: Found 47 DICOM files\n✅ Successfully loaded 47 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10177117050965285724806213067235546942\n✅ Consistent shapes: (512, 512) across 47 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10058383541003792190302541266378919328: Found 88 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10144083517869641752799954597390552857: Found 194 DICOM files\n✅ Successfully loaded 136 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10046318991957083423208748012349179640\n✅ Consistent shapes: (512, 512) across 136 slices\n✅ Successfully loaded 88 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10058383541003792190302541266378919328\n✅ Consistent shapes: (512, 512) across 88 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317: Found 276 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10232731436838657115800303234983509594: Found 30 DICOM files\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10232731436838657115800303234983509594\n✅ Consistent shapes: (640, 640) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10042423585566957032411171949972906248: Found 116 DICOM files\n✅ Successfully loaded 116 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10042423585566957032411171949972906248\n✅ Successfully loaded 194 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10144083517869641752799954597390552857\n✅ Consistent shapes: (512, 452) across 116 slices\n✅ Consistent shapes: (512, 512) across 194 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10122841756457641138155875644216826804: Found 1 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242908234090194014051186313014188903: Found 108 DICOM files\n✅ Successfully loaded 276 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317\n✅ Consistent shapes: (512, 512) across 276 slices\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10122841756457641138155875644216826804:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.18155697113448637526398174722597847630.dcm: Invalid dimensions (150, 560, 560)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10118104902601294641571465174067732646: Found 321 DICOM files\n✅ Successfully loaded 108 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242908234090194014051186313014188903\n✅ Consistent shapes: (512, 512) across 108 slices\nSample 1: DICOM load: 4.95s, Preprocess: 1.18s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636: Found 205 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10040419508532196461125208817600495772: Found 188 DICOM files\n✅ Successfully loaded 188 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10040419508532196461125208817600495772\n✅ Consistent shapes: (512, 512) across 188 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10152316071300066886893512484432664805: Found 120 DICOM files\n✅ Successfully loaded 205 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636\n✅ Consistent shapes: (512, 512) across 205 slices\n✅ Successfully loaded 321 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10118104902601294641571465174067732646\n✅ Consistent shapes: (512, 512) across 321 slices\n✅ Successfully loaded 120 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10152316071300066886893512484432664805\n✅ Consistent shapes: (512, 512) across 120 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10212302880573111557869412819411272803: Found 200 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10068453918327434625947056516458124159: Found 242 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10063454172499468887877935052136698373: Found 2 DICOM files\n✅ Successfully loaded 2 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10063454172499468887877935052136698373\n✅ Consistent shapes: (464, 704) across 2 slices\n✅ Successfully loaded 200 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10212302880573111557869412819411272803\n✅ Consistent shapes: (512, 512) across 200 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10247439373520422169955747183361551750: Found 26 DICOM files\n✅ Successfully loaded 26 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10247439373520422169955747183361551750\n✅ Consistent shapes: (512, 512) across 26 slices\n✅ Successfully loaded 242 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10068453918327434625947056516458124159\n  🔍 Batch 1: GPU memory before forward: 0.13GB\n  ⚡ Batch 1: Forward pass: 0.124s, GPU memory after: 1.19GB\n  🔄 Batch 1: Backward pass: 0.020s\n✅ Consistent shapes: (640, 580) across 242 slices\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:  50%|█████     | 2/4 [01:32<01:22, 41.23s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 1: 0.28s\n  🔍 Batch 2: GPU memory before forward: 0.13GB\n  ⚡ Batch 2: Forward pass: 0.110s, GPU memory after: 1.19GB\n  🔄 Batch 2: Backward pass: 0.019s\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch:  75%|███████▌  | 3/4 [01:32<00:22, 22.52s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 2: 0.24s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10098743283291956051221530305664415374: Found 44 DICOM files\n✅ Successfully loaded 44 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10098743283291956051221530305664415374\n✅ Consistent shapes: (512, 512) across 44 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10229915682372012073055285556885310225: Found 204 DICOM files\n✅ Successfully loaded 204 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10229915682372012073055285556885310225\n✅ Consistent shapes: (512, 512) across 204 slices\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch: 100%|██████████| 4/4 [01:37<00:00, 24.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"Batch 3: 0.27s\n","output_type":"stream"},{"name":"stderr","text":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"🔍 Loading series 1.2.826.0.1.3680043.8.498.10256018119694768427929632156620347034: Found 180 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647: Found 188 DICOM files🔍 Loading series 1.2.826.0.1.3680043.8.498.10129580404994628606227497184499173213: Found 313 DICOM files\n\n\n✅ Successfully loaded 188 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647\n✅ Consistent shapes: (512, 512) across 188 slices\nSample 0: DICOM load: 4.10s, Preprocess: 0.75s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10009383108068795488741533244914370182: Found 224 DICOM files\n✅ Successfully loaded 313 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10129580404994628606227497184499173213\n✅ Consistent shapes: (512, 512) across 313 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10133805409448598100180344093077653742: Found 554 DICOM files\n✅ Successfully loaded 180 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10256018119694768427929632156620347034\n✅ Consistent shapes: (1008, 1008) across 180 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10264784704607431871981917026977073042: Found 168 DICOM files\n✅ Successfully loaded 224 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10009383108068795488741533244914370182\n✅ Consistent shapes: (768, 696) across 224 slices\nSample 1: DICOM load: 8.14s, Preprocess: 2.45s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10021411248005513321236647460239137906: Found 239 DICOM files\n✅ Successfully loaded 168 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10264784704607431871981917026977073042\n✅ Consistent shapes: (512, 512) across 168 slices\n✅ Successfully loaded 554 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10133805409448598100180344093077653742\n✅ Consistent shapes: (512, 512) across 554 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10143240284902513794767720489625125957: Found 240 DICOM files\n✅ Successfully loaded 239 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10021411248005513321236647460239137906\n✅ Consistent shapes: (512, 512) across 239 slices\nSample 2: DICOM load: 3.47s, Preprocess: 1.15s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10030095840917973694487307992374923817: Found 451 DICOM files\n✅ Successfully loaded 240 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10143240284902513794767720489625125957\n✅ Consistent shapes: (512, 512) across 240 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10148992367063193735584459523736151066: Found 139 DICOM files\n✅ Successfully loaded 139 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10148992367063193735584459523736151066\n✅ Consistent shapes: (256, 254) across 139 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10157259652665015386051954194840128811: Found 359 DICOM files\n✅ Successfully loaded 451 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10030095840917973694487307992374923817\n✅ Consistent shapes: (512, 512) across 451 slices\n✅ Successfully loaded 359 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10157259652665015386051954194840128811\n✅ Consistent shapes: (512, 512) across 359 slices\nSample 3: DICOM load: 6.57s, Preprocess: 1.95s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10035643165968342618460849823699311381: Found 228 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10161092109954976473450555831085144960: Found 284 DICOM files\n✅ Successfully loaded 228 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10035643165968342618460849823699311381\n✅ Consistent shapes: (512, 512) across 228 slices\nSample 4: DICOM load: 2.91s, Preprocess: 1.14s\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10037266473301611864455091971206084528: Found 201 DICOM files\n✅ Successfully loaded 284 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10161092109954976473450555831085144960\n✅ Consistent shapes: (512, 512) across 284 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10163827504601437014258638041508575801: Found 75 DICOM files\n✅ Successfully loaded 75 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10163827504601437014258638041508575801\n✅ Consistent shapes: (584, 512) across 75 slices\n✅ Successfully loaded 201 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10037266473301611864455091971206084528\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10172626607552095496094268567506878754: Found 561 DICOM files\n✅ Consistent shapes: (768, 696) across 201 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10042474696169267476037627878420766468: Found 587 DICOM files\n✅ Successfully loaded 561 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10172626607552095496094268567506878754\n✅ Consistent shapes: (512, 512) across 561 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10186041198879318410917325125181341286: Found 30 DICOM files\n✅ Successfully loaded 587 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10042474696169267476037627878420766468\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10186041198879318410917325125181341286\n✅ Consistent shapes: (512, 512) across 30 slices\n✅ Consistent shapes: (512, 512) across 587 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10188636688783982623025997809119805350: Found 136 DICOM files\n✅ Successfully loaded 136 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10188636688783982623025997809119805350\n✅ Consistent shapes: (384, 314) across 136 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10207110118916220264491289532161991004: Found 1 DICOM files\n❌ Complete failure for series 1.2.826.0.1.3680043.8.498.10207110118916220264491289532161991004:\n   📊 Files: 1, Valid: 0, Invalid: 0, Empty pixels: 0, Corrupted pixels: 1, Pixel errors: 0\n   🔍 First 5 errors:\n  1.2.826.0.1.3680043.8.498.35987680962070754560160756829496799559.dcm: Invalid dimensions (24, 528, 528)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10218616184968326770042507305824538520: Found 359 DICOM files\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10057981374227560278263065500472865434: Found 723 DICOM files\n✅ Successfully loaded 359 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10218616184968326770042507305824538520\n✅ Consistent shapes: (240, 320) across 359 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10230011967368070546203100023298616413: Found 144 DICOM files\n✅ Successfully loaded 144 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10230011967368070546203100023298616413\n✅ Consistent shapes: (512, 512) across 144 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10237346404947508483392228545497384153: Found 205 DICOM files\n✅ Successfully loaded 205 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10237346404947508483392228545497384153\n✅ Consistent shapes: (512, 512) across 205 slices\n✅ Successfully loaded 723 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10057981374227560278263065500472865434\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242740813399049394757933972926370746: Found 158 DICOM files\n✅ Consistent shapes: (512, 512) across 723 slices\n✅ Successfully loaded 158 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242740813399049394757933972926370746\n✅ Consistent shapes: (512, 512) across 158 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10242915350197711554605463577659482013: Found 19 DICOM files\n✅ Successfully loaded 19 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10242915350197711554605463577659482013\n✅ Consistent shapes: (512, 512) across 19 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10058588444796585220635465116646088095: Found 30 DICOM files\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10058588444796585220635465116646088095\n✅ Consistent shapes: (256, 208) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10070371997983281654193426002305027111: Found 30 DICOM files\n✅ Successfully loaded 30 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10070371997983281654193426002305027111\n✅ Consistent shapes: (512, 512) across 30 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10077108087009955586144859725246456654: Found 31 DICOM files\n✅ Successfully loaded 31 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10077108087009955586144859725246456654\n⚠️  Shape inconsistency in 1.2.826.0.1.3680043.8.498.10077108087009955586144859725246456654: Found 2 different shapes. Most common: (584, 584)\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10092666779602341135460882241562348436: Found 281 DICOM files\n✅ Successfully loaded 281 valid DICOMs from series 1.2.826.0.1.3680043.8.498.10092666779602341135460882241562348436\n✅ Consistent shapes: (512, 512) across 281 slices\n🔍 Loading series 1.2.826.0.1.3680043.8.498.10097649530131165889513682791963111629: Found 175 DICOM files\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}