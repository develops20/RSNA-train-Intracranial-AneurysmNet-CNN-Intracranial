{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":99552,"databundleVersionId":13190393,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/02-aneurysmnet-cnn-intracranial-training-nb153?scriptVersionId=254951991\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# ====================================================\n# RSNA INTRACRANIAL ANEURYSM DETECTION - TRAINING PIPELINE\n# ====================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pydicom\nimport nibabel as nib\nimport cv2\nfrom scipy import ndimage\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:05:29.369422Z","iopub.execute_input":"2025-08-05T19:05:29.370288Z","iopub.status.idle":"2025-08-05T19:05:34.845416Z","shell.execute_reply.started":"2025-08-05T19:05:29.37026Z","shell.execute_reply":"2025-08-05T19:05:34.844776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================================\n# CELL 2: CONFIGURATION\n# ====================================================\n\nclass Config:\n    # Paths\n    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n    LOCALIZER_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\n    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n    \n    # Stage 1: 3D Segmentation\n    STAGE1_TARGET_SIZE = (64, 128, 128)  # Smaller for speed\n    STAGE1_BATCH_SIZE = 4\n    STAGE1_EPOCHS = 15\n    STAGE1_LR = 3e-4\n    \n    # General\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    MIXED_PRECISION = True\n    N_FOLDS = 3\n    \n    # Competition constants\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n    TARGET_COL = 'Aneurysm Present'\n    \n    # Debug settings\n    DEBUG_MODE = False\n    DEBUG_SAMPLES = 200  # Use small subset for testing\n\nprint(f\"âœ… Configuration loaded - Device: {Config.DEVICE}\")\n\n# ====================================================\n# CELL 2.5: CUSTOM 3D UNET (REPLACES MONAI BASICUNET)\n# ====================================================\n\nclass Custom3DUNet(nn.Module):\n    \"\"\"Pure PyTorch 3D UNet implementation to replace MONAI BasicUNet\"\"\"\n    \n    def __init__(self, spatial_dims=3, in_channels=1, out_channels=32, \n                 features=(32, 64, 128, 256, 512, 32), dropout=0.1):\n        super().__init__()\n        \n        self.features = features\n        self.dropout = dropout\n        \n        # Encoder (downsampling path)\n        self.encoder_blocks = nn.ModuleList()\n        prev_channels = in_channels\n        \n        for i, feature_count in enumerate(features[:-1]):  # Exclude last feature (decoder output)\n            # Each encoder block: Conv3D -> BatchNorm -> ReLU -> Conv3D -> BatchNorm -> ReLU\n            block = nn.Sequential(\n                nn.Conv3d(prev_channels, feature_count, kernel_size=3, padding=1),\n                nn.BatchNorm3d(feature_count),\n                nn.ReLU(inplace=True),\n                nn.Conv3d(feature_count, feature_count, kernel_size=3, padding=1),\n                nn.BatchNorm3d(feature_count),\n                nn.ReLU(inplace=True),\n                nn.Dropout3d(dropout) if dropout > 0 else nn.Identity()\n            )\n            self.encoder_blocks.append(block)\n            prev_channels = feature_count\n        \n        # Downsampling layers (MaxPool)\n        self.downsample_layers = nn.ModuleList([\n            nn.MaxPool3d(kernel_size=2, stride=2) \n            for _ in range(len(features) - 2)  # No downsampling after last encoder block\n        ])\n        \n        # Decoder (upsampling path)\n        self.decoder_blocks = nn.ModuleList()\n        self.upsample_layers = nn.ModuleList()\n        \n        # Reverse the features for decoder (skip the input feature count)\n        decoder_features = list(reversed(features[:-1]))  # [512, 256, 128, 64, 32]\n        \n        for i in range(len(decoder_features) - 1):\n            current_features = decoder_features[i]\n            next_features = decoder_features[i + 1]\n            \n            # Upsampling layer\n            upsample = nn.ConvTranspose3d(\n                current_features, next_features, \n                kernel_size=2, stride=2\n            )\n            self.upsample_layers.append(upsample)\n            \n            # Decoder block (concatenation + convolutions)\n            # Input: upsampled features + skip connection = next_features * 2\n            decoder_block = nn.Sequential(\n                nn.Conv3d(next_features * 2, next_features, kernel_size=3, padding=1),\n                nn.BatchNorm3d(next_features),\n                nn.ReLU(inplace=True),\n                nn.Conv3d(next_features, next_features, kernel_size=3, padding=1),\n                nn.BatchNorm3d(next_features),\n                nn.ReLU(inplace=True),\n                nn.Dropout3d(dropout) if dropout > 0 else nn.Identity()\n            )\n            self.decoder_blocks.append(decoder_block)\n        \n        # Final output convolution\n        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        # Store skip connections\n        skip_connections = []\n        \n        # Encoder path\n        for i, encoder_block in enumerate(self.encoder_blocks):\n            x = encoder_block(x)\n            skip_connections.append(x)\n            \n            # Downsample (except for the last encoder block)\n            if i < len(self.downsample_layers):\n                x = self.downsample_layers[i](x)\n        \n        # Decoder path\n        skip_connections = skip_connections[:-1]  # Remove the deepest layer (no skip for bottleneck)\n        skip_connections.reverse()  # Reverse to match decoder order\n        \n        for i, (upsample_layer, decoder_block) in enumerate(zip(self.upsample_layers, self.decoder_blocks)):\n            # Upsample\n            x = upsample_layer(x)\n            \n            # Get corresponding skip connection\n            skip = skip_connections[i]\n            \n            # Ensure spatial dimensions match (handle odd-sized inputs)\n            if x.shape[2:] != skip.shape[2:]:\n                x = nn.functional.interpolate(x, size=skip.shape[2:], mode='trilinear', align_corners=False)\n            \n            # Concatenate skip connection\n            x = torch.cat([x, skip], dim=1)\n            \n            # Apply decoder block\n            x = decoder_block(x)\n        \n        # Final output\n        x = self.final_conv(x)\n        \n        return x\n\nclass Enhanced3DAugmentation:\n    \"\"\"Intensive 3D augmentations for medical imaging using scipy/numpy\"\"\"\n    \n    def __init__(self, mode='train'):\n        self.mode = mode\n        self.apply_augmentation = (mode == 'train')\n        \n    def random_rotation_3d(self, volume, max_angle=15):\n        \"\"\"Random 3D rotation\"\"\"\n        if not self.apply_augmentation or np.random.random() > 0.5:\n            return volume\n            \n        angle = np.random.uniform(-max_angle, max_angle)\n        # Rotate around z-axis (axial plane)\n        rotated = ndimage.rotate(volume, angle, axes=(1, 2), reshape=False, order=1)\n        return rotated\n    \n    def random_elastic_deformation(self, volume, sigma=4, points=3):\n        \"\"\"Random elastic deformation for vessel-like structures\"\"\"\n        if not self.apply_augmentation or np.random.random() > 0.3:\n            return volume\n            \n        shape = volume.shape\n        dx = ndimage.gaussian_filter((np.random.random(shape) - 0.5), sigma) * points\n        dy = ndimage.gaussian_filter((np.random.random(shape) - 0.5), sigma) * points\n        dz = ndimage.gaussian_filter((np.random.random(shape) - 0.5), sigma) * points\n        \n        x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n        indices = np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1)), np.reshape(z + dz, (-1, 1))\n        \n        deformed = ndimage.map_coordinates(volume, indices, order=1, mode='reflect')\n        return deformed.reshape(shape)\n    \n    def random_brightness_contrast(self, volume, brightness=0.2, contrast=0.2):\n        \"\"\"Random brightness and contrast for aneurysm visibility\"\"\"\n        if not self.apply_augmentation or np.random.random() > 0.7:\n            return volume\n            \n        # Brightness adjustment\n        brightness_factor = 1 + np.random.uniform(-brightness, brightness)\n        volume = volume * brightness_factor\n        \n        # Contrast adjustment\n        contrast_factor = 1 + np.random.uniform(-contrast, contrast)\n        mean = volume.mean()\n        volume = (volume - mean) * contrast_factor + mean\n        \n        return np.clip(volume, 0, 1)\n    \n    def random_gaussian_noise(self, volume, std_range=(0, 0.05)):\n        \"\"\"Add Gaussian noise to improve robustness\"\"\"\n        if not self.apply_augmentation or np.random.random() > 0.4:\n            return volume\n            \n        std = np.random.uniform(std_range[0], std_range[1])\n        noise = np.random.normal(0, std, volume.shape)\n        return np.clip(volume + noise, 0, 1)\n    \n    def random_gamma_correction(self, volume, gamma_range=(0.8, 1.2)):\n        \"\"\"Gamma correction for intensity variations\"\"\"\n        if not self.apply_augmentation or np.random.random() > 0.5:\n            return volume\n            \n        gamma = np.random.uniform(gamma_range[0], gamma_range[1])\n        return np.power(volume, gamma)\n    \n    def __call__(self, data_dict):\n        \"\"\"Apply all augmentations\"\"\"\n        result = {}\n        \n        for key in data_dict:\n            if key == 'volume' and isinstance(data_dict[key], np.ndarray):\n                volume = data_dict[key].copy()\n                \n                # Apply augmentations sequentially\n                volume = self.random_rotation_3d(volume)\n                volume = self.random_elastic_deformation(volume)\n                volume = self.random_brightness_contrast(volume)\n                volume = self.random_gaussian_noise(volume)\n                volume = self.random_gamma_correction(volume)\n                \n                # Convert to tensor\n                result[key] = torch.from_numpy(volume).float()\n            elif isinstance(data_dict[key], np.ndarray):\n                result[key] = torch.from_numpy(data_dict[key]).float()\n            else:\n                result[key] = data_dict[key]\n        \n        return result\n\nclass CustomTransforms:\n    \"\"\"Simple transforms for validation (no augmentation)\"\"\"\n    \n    def __init__(self, keys=['volume']):\n        self.keys = keys\n        \n    def __call__(self, data_dict):\n        \"\"\"Apply transforms to data dictionary\"\"\"\n        result = {}\n        \n        for key in data_dict:\n            if key in self.keys:\n                # Convert numpy array to tensor if needed\n                if isinstance(data_dict[key], np.ndarray):\n                    result[key] = torch.from_numpy(data_dict[key]).float()\n                else:\n                    result[key] = data_dict[key]\n            else:\n                result[key] = data_dict[key]\n        \n        return result\n\nprint(\"âœ… Enhanced 3D UNet with medical augmentations loaded (MONAI-free!)\")\n\n# ====================================================\n# CELL 3: SIMPLE DICOM PROCESSOR\n# ====================================================\n\nclass SimpleDICOMProcessor:\n    def __init__(self, target_size=None):\n        self.target_size = target_size or Config.STAGE1_TARGET_SIZE\n        \n    def load_dicom_series(self, series_path):\n        \"\"\"Simple DICOM loading - no complex error handling\"\"\"\n        try:\n            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n            if not dicom_files:\n                return np.zeros(self.target_size, dtype=np.float32)\n            \n            # Load all DICOMs\n            pixel_arrays = []\n            for f in dicom_files[:50]:  # Limit to 50 files max for speed\n                try:\n                    ds = pydicom.dcmread(os.path.join(series_path, f), force=True)\n                    if hasattr(ds, 'pixel_array'):\n                        arr = ds.pixel_array\n                        if arr.ndim == 2:  # Standard 2D slice\n                            pixel_arrays.append(arr)\n                        elif arr.ndim == 3:  # 3D volume - take middle slices\n                            mid_start = arr.shape[0] // 4\n                            mid_end = 3 * arr.shape[0] // 4\n                            for slice_idx in range(mid_start, mid_end, 2):  # Every 2nd slice\n                                pixel_arrays.append(arr[slice_idx])\n                except:\n                    continue\n            \n            if not pixel_arrays:\n                return np.zeros(self.target_size, dtype=np.float32)\n            \n            # Resize all slices to same shape before stacking\n            if len(pixel_arrays) > 0:\n                # Use first slice shape as reference, or use a standard size\n                target_slice_shape = (256, 256)  # Standard size for all slices\n                \n                resized_arrays = []\n                for arr in pixel_arrays:\n                    if arr.shape != target_slice_shape:\n                        # Resize slice to target shape\n                        resized_arr = ndimage.zoom(arr, \n                                                 (target_slice_shape[0] / arr.shape[0], \n                                                  target_slice_shape[1] / arr.shape[1]), \n                                                 order=1)\n                        resized_arrays.append(resized_arr)\n                    else:\n                        resized_arrays.append(arr)\n                \n                # Now stack - all arrays have same shape\n                volume = np.stack(resized_arrays, axis=0).astype(np.float32)\n            else:\n                return np.zeros(self.target_size, dtype=np.float32)\n            \n            # Simple preprocessing\n            volume = self.preprocess_volume(volume)\n            return volume\n            \n        except Exception as e:\n            print(f\"Failed to load {series_path}: {e}\")\n            return np.zeros(self.target_size, dtype=np.float32)\n    \n    def preprocess_volume(self, volume):\n        \"\"\"Simple preprocessing\"\"\"\n        # Normalize\n        p1, p99 = np.percentile(volume, [1, 99])\n        volume = np.clip(volume, p1, p99)\n        volume = (volume - p1) / (p99 - p1 + 1e-8)\n        \n        # Resize to target\n        if volume.shape != self.target_size:\n            zoom_factors = [self.target_size[i] / volume.shape[i] for i in range(3)]\n            volume = ndimage.zoom(volume, zoom_factors, order=1)\n        \n        return volume.astype(np.float32)\n\nprint(\"âœ… DICOM Processor loaded\")\n\n# ====================================================\n# CELL 4: DATASET CLASS\n# ====================================================\n\nclass SimpleSegmentationDataset(Dataset):\n    def __init__(self, df, series_dir, processor, mode='train'):\n        self.df = df\n        self.series_dir = series_dir\n        self.processor = processor\n        self.mode = mode\n        \n        # Enhanced augmentation for training, simple transforms for validation\n        if mode == 'train':\n            self.transform = Enhanced3DAugmentation(mode='train')\n        else:\n            self.transform = CustomTransforms(keys=['volume'])\n        \n    def __len__(self):\n        return len(self.df)\n\n    def validate_segmentation_mask(self, series_id, mask):\n        \"\"\"Validate segmentation mask quality\"\"\"\n        # Check if mask is empty\n        if mask.max() == 0:\n            return False\n            \n        # Check mask connectivity and size\n        mask_binary = (mask > 0.5).astype(np.uint8)\n        labeled_mask, num_components = ndimage.label(mask_binary)\n        \n        if num_components == 0:\n            return False\n            \n        # Check component sizes (aneurysms should be small but not tiny)\n        component_sizes = []\n        for i in range(1, num_components + 1):\n            component_size = np.sum(labeled_mask == i)\n            component_sizes.append(component_size)\n        \n        # Valid if has reasonably sized components\n        valid_components = [size for size in component_sizes if 10 < size < 10000]\n        return len(valid_components) > 0\n    \n    \n    def load_segmentation_mask(self, series_id, volume_shape):\n        \"\"\"Load real segmentation mask from competition data with validation\"\"\"\n        seg_path = os.path.join(Config.SEGMENTATION_DIR, f\"{series_id}.nii\")\n        \n        try:\n            if os.path.exists(seg_path):\n                # Load NIfTI segmentation mask\n                import nibabel as nib\n                nii_img = nib.load(seg_path)\n                mask = nii_img.get_fdata().astype(np.float32)\n                \n                # Resize mask to match volume shape\n                if mask.shape != volume_shape:\n                    zoom_factors = [volume_shape[i] / mask.shape[i] for i in range(3)]\n                    mask = ndimage.zoom(mask, zoom_factors, order=0)  # Nearest neighbor for masks\n                \n                # Normalize mask values to 0-1\n                mask = (mask > 0).astype(np.float32)\n                \n                # Validate mask quality\n                if self.validate_segmentation_mask(series_id, mask):\n                    return mask\n                else:\n                    # Mask failed validation - use fallback for aneurysm cases\n                    has_aneurysm = int(self.df[self.df[Config.ID_COL] == series_id][Config.TARGET_COL].iloc[0])\n                    if has_aneurysm:\n                        # Create enhanced central region mask for aneurysm cases\n                        mask = np.zeros(volume_shape, dtype=np.float32)\n                        h, w, d = volume_shape\n                        # Multiple small regions to simulate potential aneurysm locations\n                        mask[h//3:2*h//3, w//3:2*w//3, d//3:2*d//3] = 0.7\n                        mask[h//4:3*h//4, w//4:3*w//4, d//2:d//2+d//8] = 1.0  # Central strong region\n                        return mask\n                    else:\n                        return np.zeros(volume_shape, dtype=np.float32)\n            else:\n                # No segmentation available - create empty mask\n                return np.zeros(volume_shape, dtype=np.float32)\n                \n        except Exception as e:\n            print(f\"Error loading segmentation for {series_id}: {e}\")\n            # Fallback: create simple mask if aneurysm present\n            has_aneurysm = int(self.df[self.df[Config.ID_COL] == series_id][Config.TARGET_COL].iloc[0])\n            if has_aneurysm:\n                # Create a rough central region mask as fallback\n                mask = np.zeros(volume_shape, dtype=np.float32)\n                h, w, d = volume_shape\n                mask[h//4:3*h//4, w//4:3*w//4, d//4:3*d//4] = 1.0\n                return mask\n            else:\n                return np.zeros(volume_shape, dtype=np.float32)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        series_id = row[Config.ID_COL]\n        series_path = os.path.join(self.series_dir, series_id)\n        \n        # Load volume\n        volume = self.processor.load_dicom_series(series_path)\n        \n        # Load REAL segmentation mask from competition data\n        mask = self.load_segmentation_mask(series_id, volume.shape)\n        \n        # Get aneurysm presence label\n        has_aneurysm = int(row[Config.TARGET_COL])\n        \n        # Transform\n        data_dict = {'volume': volume}\n        if self.transform:\n            data_dict = self.transform(data_dict)\n        \n        volume_tensor = data_dict['volume'].unsqueeze(0)  # Add channel dim\n        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n        \n        return {\n            'volume': volume_tensor,\n            'mask': mask_tensor,\n            'has_aneurysm': torch.tensor(has_aneurysm, dtype=torch.float32),\n            'series_id': series_id\n        }\n\nprint(\"âœ… Dataset class loaded\")\n\n# ====================================================\n# CELL 5: 3D U-NET MODEL\n# ====================================================\n\nclass Simple3DSegmentationNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super().__init__()\n        \n        # Use our Custom3DUNet - pure PyTorch implementation!\n        self.backbone = Custom3DUNet(\n            spatial_dims=3,\n            in_channels=in_channels,\n            out_channels=32,\n            features=(32, 64, 128, 256, 512, 32),\n            dropout=0.1\n        )\n        \n        # Segmentation head\n        self.seg_head = nn.Conv3d(32, out_channels, kernel_size=1)\n        \n        # Classification head (aneurysm presence)\n        self.global_pool = nn.AdaptiveAvgPool3d(1)\n        self.classifier = nn.Sequential(\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, x):\n        # Extract features\n        features = self.backbone(x)\n        \n        # Segmentation output\n        seg_logits = self.seg_head(features)\n        \n        # Classification output\n        pooled_features = self.global_pool(features).flatten(1)\n        cls_logits = self.classifier(pooled_features)\n        \n        return seg_logits, cls_logits\n\nprint(\"âœ… Model architecture loaded\")\n\n# ====================================================\n# CELL 6: ENHANCED LOSS FUNCTIONS\n# ====================================================\n\nclass DiceLoss(nn.Module):\n    \"\"\"Dice Loss for better segmentation of small objects\"\"\"\n    def __init__(self, smooth=1e-6):\n        super().__init__()\n        self.smooth = smooth\n        \n    def forward(self, predictions, targets):\n        # Apply sigmoid to logits\n        predictions = torch.sigmoid(predictions)\n        \n        # Flatten tensors\n        predictions = predictions.view(-1)\n        targets = targets.view(-1)\n        \n        # Calculate intersection and union\n        intersection = (predictions * targets).sum()\n        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n        \n        return 1 - dice\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss for handling class imbalance\"\"\"\n    def __init__(self, alpha=0.25, gamma=2.0, smooth=1e-6):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.smooth = smooth\n        \n    def forward(self, predictions, targets):\n        # Apply sigmoid to get probabilities\n        probs = torch.sigmoid(predictions)\n        \n        # Calculate focal loss components\n        pt = torch.where(targets == 1, probs, 1 - probs)\n        ce_loss = nn.functional.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        \n        return focal_loss.mean()\n        \nclass EnhancedCombinedLoss(nn.Module):\n    \"\"\"Enhanced loss combining Dice + BCE + Focal for medical segmentation\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.dice_loss = DiceLoss()\n        self.bce_loss = nn.BCEWithLogitsLoss()\n        self.focal_loss = FocalLoss(alpha=0.25, gamma=2)\n        \n    def forward(self, seg_logits, cls_logits, seg_targets, cls_targets):\n        # Multi-component segmentation loss\n        dice_loss = self.dice_loss(seg_logits, seg_targets)\n        bce_seg_loss = self.bce_loss(seg_logits, seg_targets)\n        focal_seg_loss = self.focal_loss(seg_logits, seg_targets)\n        \n        # Weighted combination for class imbalance\n        seg_loss = 0.5 * dice_loss + 0.3 * bce_seg_loss + 0.2 * focal_seg_loss\n        \n        # Classification loss\n        cls_loss = self.bce_loss(cls_logits.squeeze(), cls_targets)\n        \n        # Higher weight on segmentation for Stage 1\n        total_loss = 2.0 * seg_loss + 0.5 * cls_loss\n        return total_loss, seg_loss, cls_loss\n\nprint(\"âœ… Enhanced loss functions loaded (Dice + BCE + Focal)\")\n\n# ====================================================\n# CELL 7: TRAINING FUNCTIONS\n# ====================================================\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    total_seg_loss = 0\n    total_cls_loss = 0\n    num_batches = 0\n    \n    for batch in tqdm(loader, desc=\"Training\"):\n        volume = batch['volume'].to(device)\n        mask = batch['mask'].to(device)\n        has_aneurysm = batch['has_aneurysm'].to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        seg_logits, cls_logits = model(volume)\n        \n        # Calculate loss\n        loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm)\n        \n        # Backward pass with gradient clipping\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_seg_loss += seg_loss.item()\n        total_cls_loss += cls_loss.item()\n        num_batches += 1\n    \n    return (total_loss / num_batches, \n            total_seg_loss / num_batches, \n            total_cls_loss / num_batches)\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_seg_loss = 0\n    total_cls_loss = 0\n    num_batches = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Validating\"):\n            volume = batch['volume'].to(device)\n            mask = batch['mask'].to(device)\n            has_aneurysm = batch['has_aneurysm'].to(device)\n            \n            # Forward pass\n            seg_logits, cls_logits = model(volume)\n            \n            # Calculate loss\n            loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm)\n            \n            total_loss += loss.item()\n            total_seg_loss += seg_loss.item()\n            total_cls_loss += cls_loss.item()\n            num_batches += 1\n    \n    return (total_loss / num_batches, \n            total_seg_loss / num_batches, \n            total_cls_loss / num_batches)\n\nprint(\"âœ… Training functions loaded\")\n\n# ====================================================\n# CELL 8: MAIN TRAINING LOOP\n# ====================================================\n\ndef main():\n    print(f\"ðŸš€ STAGE 1: 3D SEGMENTATION FOR REGION LOCALIZATION\")\n    print(f\"Using device: {Config.DEVICE}\")\n    print(f\"Target size: {Config.STAGE1_TARGET_SIZE}\")\n    \n    # Load data\n    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n    \n    # Load localizer data (for future use)\n    try:\n        localizer_df = pd.read_csv(Config.LOCALIZER_CSV_PATH)\n        print(f\"Loaded localizer data: {len(localizer_df)} entries\")\n    except:\n        localizer_df = None\n        print(\"No localizer data found - continuing without it\")\n    \n    # Debug mode - small subset\n    if Config.DEBUG_MODE:\n        train_df = train_df.head(Config.DEBUG_SAMPLES)\n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Aneurysm cases: {train_df[Config.TARGET_COL].sum()}\")\n    \n    # Simple train/val split\n    val_size = len(train_df) // 5\n    val_df = train_df[:val_size].reset_index(drop=True)\n    train_df = train_df[val_size:].reset_index(drop=True)\n    \n    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n    \n    # Create datasets\n    processor = SimpleDICOMProcessor()\n    train_dataset = SimpleSegmentationDataset(train_df, Config.SERIES_DIR, processor, 'train')\n    val_dataset = SimpleSegmentationDataset(val_df, Config.SERIES_DIR, processor, 'val')\n    \n    # Create loaders\n    train_loader = DataLoader(train_dataset, batch_size=Config.STAGE1_BATCH_SIZE, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=Config.STAGE1_BATCH_SIZE, shuffle=False, num_workers=2)\n    \n    # Create model\n    model = Simple3DSegmentationNet().to(Config.DEVICE)\n    \n    # Multi-GPU if available\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs\")\n        model = nn.DataParallel(model)\n    \n    # Enhanced optimizer and loss - proven optimization from winning solutions\n    optimizer = optim.AdamW(model.parameters(), lr=Config.STAGE1_LR, weight_decay=1e-4)\n    criterion = EnhancedCombinedLoss()  # Use enhanced loss function\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.STAGE1_EPOCHS, eta_min=1e-6)\n    \n    # Training loop\n    best_loss = float('inf')\n    \n    for epoch in range(Config.STAGE1_EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{Config.STAGE1_EPOCHS}\")\n        \n        # Train\n        train_loss, train_seg_loss, train_cls_loss = train_epoch(\n            model, train_loader, optimizer, criterion, Config.DEVICE\n        )\n        \n        # Validate\n        val_loss, val_seg_loss, val_cls_loss = validate_epoch(\n            model, val_loader, criterion, Config.DEVICE\n        )\n        \n        # Step scheduler\n        scheduler.step()\n        \n        print(f\"Train - Total: {train_loss:.4f}, Seg: {train_seg_loss:.4f}, Cls: {train_cls_loss:.4f}\")\n        print(f\"Val   - Total: {val_loss:.4f}, Seg: {val_seg_loss:.4f}, Cls: {val_cls_loss:.4f}\")\n        \n        # Save best model\n        if val_loss < best_loss:\n            best_loss = val_loss\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'epoch': epoch,\n                'val_loss': val_loss\n            }, 'stage1_segmentation_best.pth')\n            print(f\"ðŸ’¾ Saved best model (val_loss: {val_loss:.4f})\")\n    \n    print(f\"\\nâœ… Stage 1 complete! Best val loss: {best_loss:.4f}\")\n    print(\"ðŸ“ Model saved as 'stage1_segmentation_best.pth'\")\n    \n    return model\n\n# ====================================================\n# CELL 9: ROI EXTRACTOR FOR STAGE 2 (FUTURE USE)\n# ====================================================\n\nclass ROIExtractor:\n    def __init__(self, roi_size=(224, 224), confidence_threshold=0.5):\n        self.roi_size = roi_size\n        self.confidence_threshold = confidence_threshold\n    \n    def extract_rois(self, volume, segmentation_mask):\n        \"\"\"Extract 2D ROI slices from 3D volume using segmentation mask\"\"\"\n        rois = []\n        \n        # Find slices with high confidence regions\n        for slice_idx in range(volume.shape[0]):\n            slice_volume = volume[slice_idx]\n            slice_mask = segmentation_mask[slice_idx]\n            \n            # Check if this slice has potential aneurysm regions\n            if np.max(slice_mask) > self.confidence_threshold:\n                # Find connected components\n                binary_mask = (slice_mask > self.confidence_threshold).astype(np.uint8)\n                \n                # Find contours\n                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n                \n                for contour in contours:\n                    # Get bounding box\n                    x, y, w, h = cv2.boundingRect(contour)\n                    \n                    # Expand bounding box\n                    margin = max(w, h) // 4\n                    x = max(0, x - margin)\n                    y = max(0, y - margin)\n                    w = min(slice_volume.shape[1] - x, w + 2*margin)\n                    h = min(slice_volume.shape[0] - y, h + 2*margin)\n                    \n                    # Extract ROI\n                    roi = slice_volume[y:y+h, x:x+w]\n                    \n                    # Resize to standard size\n                    roi_resized = cv2.resize(roi, self.roi_size)\n                    \n                    rois.append({\n                        'roi': roi_resized,\n                        'slice_idx': slice_idx,\n                        'bbox': (x, y, w, h),\n                        'confidence': np.max(slice_mask[y:y+h, x:x+w])\n                    })\n        \n        return rois\n\nprint(\"âœ… ROI Extractor loaded (for Stage 2)\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:05:40.585225Z","iopub.execute_input":"2025-08-05T19:05:40.58606Z","iopub.status.idle":"2025-08-05T19:05:40.716064Z","shell.execute_reply.started":"2025-08-05T19:05:40.586035Z","shell.execute_reply":"2025-08-05T19:05:40.715361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================================\n# CELL 10: RUN TRAINING\n# ====================================================\n\n# Start Training\nmodel = main()\n\nprint(\"Expected training time: ??? hours\")\nprint(\"Output: stage1_segmentation_best.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:06:29.349478Z","iopub.execute_input":"2025-08-05T19:06:29.349758Z","iopub.status.idle":"2025-08-05T19:09:06.126401Z","shell.execute_reply.started":"2025-08-05T19:06:29.349736Z","shell.execute_reply":"2025-08-05T19:09:06.125184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}