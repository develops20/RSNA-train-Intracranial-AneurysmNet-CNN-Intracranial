{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/02-aneurysmnet-cnn-intracranial-training-nb153?scriptVersionId=256272756\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"11a0af56","metadata":{"execution":{"iopub.execute_input":"2025-08-16T08:55:48.166137Z","iopub.status.busy":"2025-08-16T08:55:48.165942Z","iopub.status.idle":"2025-08-16T08:55:55.012161Z","shell.execute_reply":"2025-08-16T08:55:55.011566Z"},"papermill":{"duration":6.851508,"end_time":"2025-08-16T08:55:55.013529","exception":false,"start_time":"2025-08-16T08:55:48.162021","status":"completed"},"tags":[]},"outputs":[],"source":["# ====================================================\n","# RSNA INTRACRANIAL ANEURYSM DETECTION - TRAINING PIPELINE\n","# ====================================================\n","\n","import os\n","import gc\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pydicom\n","import nibabel as nib\n","import cv2\n","from scipy import ndimage\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Seeding for reproducibility\n","def set_global_seed(seed: int):\n","    import random\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","    try:\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","    except Exception:\n","        pass\n","\n","set_global_seed(42)"]},{"cell_type":"code","execution_count":2,"id":"d86e4a77","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-08-16T08:55:55.021956Z","iopub.status.busy":"2025-08-16T08:55:55.021605Z","iopub.status.idle":"2025-08-16T08:55:55.119672Z","shell.execute_reply":"2025-08-16T08:55:55.11889Z"},"papermill":{"duration":0.104199,"end_time":"2025-08-16T08:55:55.120694","exception":false,"start_time":"2025-08-16T08:55:55.016495","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Configuration loaded - Device: cuda\n","✅ Enhanced 3D UNet with medical augmentations loaded (MONAI-free!)\n","✅ DICOM Processor loaded\n","✅ Dataset class loaded\n","✅ Model architecture loaded\n","✅ Enhanced loss functions loaded (Dice + BCE + Focal)\n","✅ Training functions loaded\n","✅ ROI Extractor loaded (for Stage 2)\n"]}],"source":["# ====================================================\n","# CELL 2: CONFIGURATION\n","# ====================================================\n","\n","class Config:\n","    # Paths\n","    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n","    LOCALIZER_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\n","    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n","    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n","    \n","    # Stage 1: 3D Segmentation\n","    STAGE1_TARGET_SIZE = (48, 112, 112) \n","    STAGE1_BATCH_SIZE = 36\n","    STAGE1_EPOCHS = 15\n","    STAGE1_LR = 1e-4\n","    \n","    # General\n","    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    MIXED_PRECISION = True\n","    CUDNN_BENCHMARK = True\n","    N_FOLDS = 3\n","    \n","    # Competition constants\n","    ID_COL = 'SeriesInstanceUID'\n","    LABEL_COLS = [\n","        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n","        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n","        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n","        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n","        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n","        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n","    ]\n","    TARGET_COL = 'Aneurysm Present'\n","    \n","    # Debug settings\n","    DEBUG_MODE = False\n","    DEBUG_SAMPLES = 200  # Use small subset for testing\n","\n","    # Optional: require GT masks for training\n","    # If True, will filter to only series with non-empty .nii masks in SEGMENTATION_DIR.\n","    # Leave False on Kaggle since GT masks are typically unavailable.\n","    FILTER_TO_MASKED_SERIES = False\n","\n","    # Synthetic mask behavior\n","    SYN_MASK_RANDOM_CENTER = True\n","    SYN_MASK_SIZE_FRAC = (0.1, 0.3)  # edge as fraction of min(D,H,W)\n","\n","    # Augmentations\n","    USE_ELASTIC_DEFORMATION = False  # disable heavy CPU elastic deformation for speed\n","    \n","    # Loss weighting\n","    SEG_LOSS_WEIGHT = 0.1  # down-weight segmentation loss when masks may be synthetic\n","    \n","    # Reproducibility\n","    SEED = 42\n","\n","    # Validation control (legacy; using Config.VAL_SUBSAMPLE_FRACTION below)\n","    VAL_SUBSAMPLE_FRACTION = 1.0\n","    VAL_FULL_EVERY_N_EPOCHS = 1\n","\n","    # DICOM loading performance\n","    MAX_SLICES_PER_SERIES = 64\n","    USE_DICOM_THREADPOOL = False\n","    DICOM_WORKERS = 4\n","\n","    # Caching\n","    USE_DISK_CACHE = True\n","    CACHE_DIR = '/kaggle/working/stage1_cache'\n","    MASK_CACHE_DIR = '/kaggle/working/mask_cache'\n","    PRE_BUILD_CACHE = True\n","    MASK_CACHE_DTYPE = np.uint8\n","\n","    # Training\n","    GRAD_ACCUM_STEPS = 1\n","\n","    # GPU augmentations (lightweight; applied during training only)\n","    AUG_ENABLE_GPU = False\n","    AUG_BRIGHTNESS = 0.2    # multiplicative ±range\n","    AUG_CONTRAST = 0.2      # contrast around mean ±range\n","    AUG_NOISE_STD = 0.03    # max Gaussian noise std\n","    AUG_GAMMA_MINMAX = (0.9, 1.1)\n","\n","    # UNet feature width scaling\n","    UNET_FEATURES = (24, 48, 96, 192, 384, 24)\n","    UNET_OUT_CHANNELS = 24\n","\n","    # Validation\n","    VAL_SUBSAMPLE_FRACTION = 1.0\n","    EARLY_STOPPING_PATIENCE = 3\n","    \n","    # Loss composition\n","    FOCAL_LOSS_WEIGHT = 0.0\n","\n","print(f\"✅ Configuration loaded - Device: {Config.DEVICE}\")\n","\n","# ====================================================\n","# CELL 2.5: CUSTOM 3D UNET (REPLACES MONAI BASICUNET)\n","# ====================================================\n","\n","class Custom3DUNet(nn.Module):\n","    \"\"\"Pure PyTorch 3D UNet implementation to replace MONAI BasicUNet\"\"\"\n","    \n","    def __init__(self, spatial_dims=3, in_channels=1, out_channels=None, \n","                 features=None, dropout=0.1):\n","        super().__init__()\n","        \n","        # Use configurable features\n","        features = features or Config.UNET_FEATURES\n","        out_channels = out_channels or Config.UNET_OUT_CHANNELS\n","        self.features = features\n","        self.dropout = dropout\n","        \n","        # Encoder (downsampling path)\n","        self.encoder_blocks = nn.ModuleList()\n","        prev_channels = in_channels\n","        \n","        for i, feature_count in enumerate(features[:-1]):  # Exclude last feature (decoder output)\n","            # Each encoder block: Conv3D -> BatchNorm -> ReLU -> Conv3D -> BatchNorm -> ReLU\n","            block = nn.Sequential(\n","                nn.Conv3d(prev_channels, feature_count, kernel_size=3, padding=1),\n","                nn.BatchNorm3d(feature_count),\n","                nn.ReLU(inplace=True),\n","                nn.Conv3d(feature_count, feature_count, kernel_size=3, padding=1),\n","                nn.BatchNorm3d(feature_count),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout3d(dropout) if dropout > 0 else nn.Identity()\n","            )\n","            self.encoder_blocks.append(block)\n","            prev_channels = feature_count\n","        \n","        # Downsampling layers (MaxPool)\n","        self.downsample_layers = nn.ModuleList([\n","            nn.MaxPool3d(kernel_size=2, stride=2) \n","            for _ in range(len(features) - 2)  # No downsampling after last encoder block\n","        ])\n","        \n","        # Decoder (upsampling path)\n","        self.decoder_blocks = nn.ModuleList()\n","        self.upsample_layers = nn.ModuleList()\n","        \n","        # Reverse the features for decoder (skip the input feature count)\n","        decoder_features = list(reversed(features[:-1]))  # [512, 256, 128, 64, 32]\n","        \n","        for i in range(len(decoder_features) - 1):\n","            current_features = decoder_features[i]\n","            next_features = decoder_features[i + 1]\n","            \n","            # Upsampling layer\n","            upsample = nn.ConvTranspose3d(\n","                current_features, next_features, \n","                kernel_size=2, stride=2\n","            )\n","            self.upsample_layers.append(upsample)\n","            \n","            # Decoder block (concatenation + convolutions)\n","            # Input: upsampled features + skip connection = next_features * 2\n","            decoder_block = nn.Sequential(\n","                nn.Conv3d(next_features * 2, next_features, kernel_size=3, padding=1),\n","                nn.BatchNorm3d(next_features),\n","                nn.ReLU(inplace=True),\n","                nn.Conv3d(next_features, next_features, kernel_size=3, padding=1),\n","                nn.BatchNorm3d(next_features),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout3d(dropout) if dropout > 0 else nn.Identity()\n","            )\n","            self.decoder_blocks.append(decoder_block)\n","        \n","        # Final output convolution\n","        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n","        \n","    def forward(self, x):\n","        # Store skip connections\n","        skip_connections = []\n","        \n","        # Encoder path\n","        for i, encoder_block in enumerate(self.encoder_blocks):\n","            x = encoder_block(x)\n","            skip_connections.append(x)\n","            \n","            # Downsample (except for the last encoder block)\n","            if i < len(self.downsample_layers):\n","                x = self.downsample_layers[i](x)\n","        \n","        # Decoder path\n","        skip_connections = skip_connections[:-1]  # Remove the deepest layer (no skip for bottleneck)\n","        skip_connections.reverse()  # Reverse to match decoder order\n","        \n","        for i, (upsample_layer, decoder_block) in enumerate(zip(self.upsample_layers, self.decoder_blocks)):\n","            # Upsample\n","            x = upsample_layer(x)\n","            \n","            # Get corresponding skip connection\n","            skip = skip_connections[i]\n","            \n","            # Ensure spatial dimensions match (handle odd-sized inputs)\n","            if x.shape[2:] != skip.shape[2:]:\n","                x = nn.functional.interpolate(x, size=skip.shape[2:], mode='trilinear', align_corners=False)\n","            \n","            # Concatenate skip connection\n","            x = torch.cat([x, skip], dim=1)\n","            \n","            # Apply decoder block\n","            x = decoder_block(x)\n","        \n","        # Final output\n","        x = self.final_conv(x)\n","        \n","        return x\n","\n","class Enhanced3DAugmentation:\n","    \"\"\"Intensive 3D augmentations for medical imaging using scipy/numpy\"\"\"\n","    \n","    def __init__(self, mode='train'):\n","        self.mode = mode\n","        self.apply_augmentation = (mode == 'train')\n","        \n","    def random_rotation_3d(self, volume, max_angle=15):\n","        \"\"\"Random 3D rotation\"\"\"\n","        if not self.apply_augmentation or np.random.random() > 0.5:\n","            return volume\n","            \n","        angle = np.random.uniform(-max_angle, max_angle)\n","        # Rotate around z-axis (axial plane)\n","        rotated = ndimage.rotate(volume, angle, axes=(1, 2), reshape=False, order=1)\n","        return rotated\n","    \n","    def random_elastic_deformation(self, volume, sigma=4, points=3):\n","        \"\"\"Heavy CPU op disabled by default for performance\"\"\"\n","        if not Config.USE_ELASTIC_DEFORMATION:\n","            return volume\n","        if not self.apply_augmentation or np.random.random() > 0.3:\n","            return volume\n","        shape = volume.shape\n","        dx = ndimage.gaussian_filter((np.random.random(shape) - 0.5), sigma) * points\n","        dy = ndimage.gaussian_filter((np.random.random(shape) - 0.5), sigma) * points\n","        dz = ndimage.gaussian_filter((np.random.random(shape) - 0.5), sigma) * points\n","        x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n","        indices = np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1)), np.reshape(z + dz, (-1, 1))\n","        deformed = ndimage.map_coordinates(volume, indices, order=1, mode='reflect')\n","        return deformed.reshape(shape)\n","    \n","    def random_brightness_contrast(self, volume, brightness=0.2, contrast=0.2):\n","        \"\"\"Random brightness and contrast for aneurysm visibility\"\"\"\n","        if not self.apply_augmentation or np.random.random() > 0.7:\n","            return volume\n","            \n","        # Brightness adjustment\n","        brightness_factor = 1 + np.random.uniform(-brightness, brightness)\n","        volume = volume * brightness_factor\n","        \n","        # Contrast adjustment\n","        contrast_factor = 1 + np.random.uniform(-contrast, contrast)\n","        mean = volume.mean()\n","        volume = (volume - mean) * contrast_factor + mean\n","        \n","        return np.clip(volume, 0, 1)\n","    \n","    def random_gaussian_noise(self, volume, std_range=(0, 0.05)):\n","        \"\"\"Add Gaussian noise to improve robustness\"\"\"\n","        if not self.apply_augmentation or np.random.random() > 0.4:\n","            return volume\n","            \n","        std = np.random.uniform(std_range[0], std_range[1])\n","        noise = np.random.normal(0, std, volume.shape)\n","        return np.clip(volume + noise, 0, 1)\n","    \n","    def random_gamma_correction(self, volume, gamma_range=(0.8, 1.2)):\n","        \"\"\"Gamma correction for intensity variations\"\"\"\n","        if not self.apply_augmentation or np.random.random() > 0.5:\n","            return volume\n","            \n","        gamma = np.random.uniform(gamma_range[0], gamma_range[1])\n","        return np.power(volume, gamma)\n","    \n","    def __call__(self, data_dict):\n","        \"\"\"Apply all augmentations\"\"\"\n","        result = {}\n","        \n","        for key in data_dict:\n","            if key == 'volume' and isinstance(data_dict[key], np.ndarray):\n","                volume = data_dict[key].copy()\n","                \n","                # Apply augmentations sequentially\n","                # volume = self.random_rotation_3d(volume)\n","                # volume = self.random_elastic_deformation(volume)\n","                volume = self.random_brightness_contrast(volume)\n","                volume = self.random_gaussian_noise(volume)\n","                volume = self.random_gamma_correction(volume)\n","                \n","                # Convert to tensor\n","                result[key] = torch.from_numpy(volume).float()\n","            elif isinstance(data_dict[key], np.ndarray):\n","                result[key] = torch.from_numpy(data_dict[key]).float()\n","            else:\n","                result[key] = data_dict[key]\n","        \n","        return result\n","\n","class CustomTransforms:\n","    \"\"\"Simple transforms for validation (no augmentation)\"\"\"\n","    \n","    def __init__(self, keys=['volume']):\n","        self.keys = keys\n","        \n","    def __call__(self, data_dict):\n","        \"\"\"Apply transforms to data dictionary\"\"\"\n","        result = {}\n","        \n","        for key in data_dict:\n","            if key in self.keys:\n","                # Convert numpy array to tensor if needed\n","                if isinstance(data_dict[key], np.ndarray):\n","                    result[key] = torch.from_numpy(data_dict[key]).float()\n","                else:\n","                    result[key] = data_dict[key]\n","            else:\n","                result[key] = data_dict[key]\n","        \n","        return result\n","\n","print(\"✅ Enhanced 3D UNet with medical augmentations loaded (MONAI-free!)\")\n","\n","# ====================================================\n","# CELL 3: SIMPLE DICOM PROCESSOR\n","# ====================================================\n","\n","class SimpleDICOMProcessor:\n","    def __init__(self, target_size=None):\n","        self.target_size = target_size or Config.STAGE1_TARGET_SIZE\n","        if Config.USE_DISK_CACHE:\n","            os.makedirs(Config.CACHE_DIR, exist_ok=True)\n","            os.makedirs(Config.MASK_CACHE_DIR, exist_ok=True)\n","        \n","    def load_dicom_series(self, series_path):\n","        \"\"\"Simple DICOM loading with reduced slice cap for performance\"\"\"\n","        try:\n","            series_id = os.path.basename(series_path.rstrip('/'))\n","            cache_key = f\"{series_id}_D{self.target_size[0]}H{self.target_size[1]}W{self.target_size[2]}_S{Config.MAX_SLICES_PER_SERIES}.npy\"\n","            cache_path = os.path.join(Config.CACHE_DIR, cache_key)\n","            if Config.USE_DISK_CACHE and os.path.exists(cache_path):\n","                try:\n","                    vol = np.load(cache_path, allow_pickle=False)\n","                    # Ensure cached volume matches target size\n","                    if vol.shape != self.target_size:\n","                        vol = self._resize_volume_to_target(vol)\n","                        try:\n","                            tmp_path = cache_path + '.tmp'\n","                            np.save(tmp_path, vol.astype(np.float16), allow_pickle=False)\n","                            os.replace(tmp_path, cache_path)\n","                        except Exception:\n","                            pass\n","                    return vol.astype(np.float32)\n","                except Exception:\n","                    pass\n","\n","            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n","            if not dicom_files:\n","                return np.zeros(self.target_size, dtype=np.float32)\n","\n","            # Skip header sorting for speed\n","            \n","            # Load DICOM pixels\n","            pixel_arrays = []\n","            def read_one(fname):\n","                try:\n","                    ds = pydicom.dcmread(os.path.join(series_path, fname), force=True)\n","                    if hasattr(ds, 'pixel_array'):\n","                        arr = ds.pixel_array\n","                        if arr.ndim == 2:\n","                            return arr\n","                        elif arr.ndim == 3:\n","                            mid_start = arr.shape[0] // 4\n","                            mid_end = 3 * arr.shape[0] // 4\n","                            return [arr[slice_idx] for slice_idx in range(mid_start, mid_end, 2)]\n","                except Exception:\n","                    return None\n","\n","            selected_files = dicom_files[: Config.MAX_SLICES_PER_SERIES]\n","            if Config.USE_DICOM_THREADPOOL and len(selected_files) > 1:\n","                from concurrent.futures import ThreadPoolExecutor\n","                with ThreadPoolExecutor(max_workers=Config.DICOM_WORKERS) as ex:\n","                    for res in ex.map(read_one, selected_files):\n","                        if res is None:\n","                            continue\n","                        if isinstance(res, list):\n","                            pixel_arrays.extend(res)\n","                        else:\n","                            pixel_arrays.append(res)\n","            else:\n","                for f in selected_files:\n","                    res = read_one(f)\n","                    if res is None:\n","                        continue\n","                    if isinstance(res, list):\n","                        pixel_arrays.extend(res)\n","                    else:\n","                        pixel_arrays.append(res)\n","            \n","            if not pixel_arrays:\n","                return np.zeros(self.target_size, dtype=np.float32)\n","            \n","            # Resize all slices to same shape before stacking\n","            if len(pixel_arrays) > 0:\n","                # Use first slice shape as reference, or use a standard size\n","                target_slice_shape = (256, 256)  # Standard size for all slices\n","                \n","                resized_arrays = []\n","                for arr in pixel_arrays:\n","                    if arr.shape != target_slice_shape:\n","                        # Resize slice to target shape\n","                        resized_arr = cv2.resize(arr.astype(np.float32), (target_slice_shape[1], target_slice_shape[0]))\n","                        resized_arrays.append(resized_arr)\n","                    else:\n","                        resized_arrays.append(arr)\n","                \n","                # Now stack and resize to exact target size (D,H,W)\n","                volume = np.stack(resized_arrays, axis=0).astype(np.float32)\n","                volume = self._resize_volume_to_target(volume)\n","            else:\n","                return np.zeros(self.target_size, dtype=np.float32)\n","\n","            # Normalize to [0,1] once here (cache pre-normalized) for speed\n","            flat = volume.reshape(-1)\n","            if flat.size > 1000:\n","                sample_idx = np.random.choice(flat.size, 1000, replace=False)\n","                sample = flat[sample_idx]\n","                p1, p99 = np.percentile(sample, [1, 99])\n","            else:\n","                p1, p99 = np.percentile(flat, [1, 99])\n","            volume = np.clip(volume, p1, p99)\n","            denom = (p99 - p1) if (p99 - p1) > 1e-6 else 1e-6\n","            volume = (volume - p1) / denom\n","            \n","            # Save preprocessed volume (target size) to cache (float16)\n","            if Config.USE_DISK_CACHE:\n","                try:\n","                    tmp_path = cache_path + '.tmp'\n","                    np.save(tmp_path, volume.astype(np.float16), allow_pickle=False)\n","                    os.replace(tmp_path, cache_path)\n","                except Exception:\n","                    pass\n","            return volume\n","\n","        except Exception as e:\n","            print(f\"Failed to load {series_path}: {e}\")\n","            return np.zeros(self.target_size, dtype=np.float32)\n","\n","    def get_mask_cache_path(self, series_id: str) -> str:\n","        return os.path.join(Config.MASK_CACHE_DIR, f\"{series_id}_mask.npy\")\n","\n","    def _resize_mask_fast(self, mask: np.ndarray) -> np.ndarray:\n","        target_d, target_h, target_w = self.target_size\n","        D, H, W = mask.shape\n","        # Depth resample by index selection\n","        if D != target_d:\n","            idx = np.linspace(0, max(D - 1, 0), num=target_d).astype(int) if D > 0 else np.zeros(target_d, dtype=int)\n","            mask = mask[idx]\n","        # Per-slice nearest resize\n","        if (H, W) != (target_h, target_w):\n","            resized = np.empty((target_d, target_h, target_w), dtype=np.float32)\n","            for i in range(target_d):\n","                resized[i] = cv2.resize(mask[i].astype(np.float32), (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n","            mask = resized\n","        return mask\n","\n","    def load_and_cache_mask(self, series_id: str, has_aneurysm: bool) -> np.ndarray:\n","        cache_path = self.get_mask_cache_path(series_id)\n","        # Load from cache if present and correct shape\n","        if os.path.exists(cache_path):\n","            try:\n","                m = np.load(cache_path, allow_pickle=False)\n","                if m.shape == self.target_size:\n","                    return m.astype(np.float32)\n","            except Exception:\n","                pass  # fall through to rebuild\n","\n","        seg_path = os.path.join(Config.SEGMENTATION_DIR, f\"{series_id}.nii\")\n","        try:\n","            if os.path.exists(seg_path):\n","                nii_img = nib.load(seg_path)\n","                mask = nii_img.get_fdata().astype(np.float32)\n","                mask = self._resize_mask_fast(mask)\n","                mask = (mask > 0).astype(Config.MASK_CACHE_DTYPE)\n","                # quick validation\n","                if mask.max() == 0 and has_aneurysm:\n","                    mask = self._create_synthetic_mask(series_id)\n","            else:\n","                mask = self._create_synthetic_mask(series_id) if has_aneurysm else np.zeros(self.target_size, dtype=Config.MASK_CACHE_DTYPE)\n","        except Exception as e:\n","            print(f\"Error processing mask for {series_id}: {e}\")\n","            mask = np.zeros(self.target_size, dtype=Config.MASK_CACHE_DTYPE)\n","\n","        # Save to cache atomically\n","        try:\n","            tmp = cache_path + '.tmp'\n","            np.save(tmp, mask, allow_pickle=False)\n","            os.replace(tmp, cache_path)\n","        except Exception:\n","            pass\n","        return mask.astype(np.float32)\n","\n","    def _create_synthetic_mask(self, series_id: str) -> np.ndarray:\n","        np.random.seed(hash(series_id) % (2**32))\n","        D, H, W = self.target_size\n","        min_dim = min(D, H, W)\n","        edge = int(np.random.uniform(0.1, 0.3) * min_dim)\n","        edge = max(4, min(edge, min_dim))\n","        cz = np.random.randint(edge//2, D - edge//2) if D > edge else D // 2\n","        cy = np.random.randint(edge//2, H - edge//2) if H > edge else H // 2\n","        cx = np.random.randint(edge//2, W - edge//2) if W > edge else W // 2\n","        z1, z2 = max(0, cz - edge//2), min(D, cz + edge//2)\n","        y1, y2 = max(0, cy - edge//2), min(H, cy + edge//2)\n","        x1, x2 = max(0, cx - edge//2), min(W, cx + edge//2)\n","        m = np.zeros(self.target_size, dtype=Config.MASK_CACHE_DTYPE)\n","        m[z1:z2, y1:y2, x1:x2] = 1\n","        return m\n","\n","    def _resize_volume_to_target(self, volume: np.ndarray) -> np.ndarray:\n","        \"\"\"Resize a 3D volume to self.target_size (D,H,W).\"\"\"\n","        target_d, target_h, target_w = self.target_size\n","        D, H, W = volume.shape\n","        # Depth resample by index selection\n","        if D != target_d:\n","            idx = np.linspace(0, max(D - 1, 0), num=target_d).astype(int) if D > 0 else np.zeros(target_d, dtype=int)\n","            volume = volume[idx]\n","        # Per-slice resize to (target_h, target_w)\n","        if (H, W) != (target_h, target_w):\n","            resized = np.empty((target_d, target_h, target_w), dtype=np.float32)\n","            for i in range(target_d):\n","                resized[i] = cv2.resize(volume[i].astype(np.float32), (target_w, target_h))\n","            volume = resized\n","        return volume.astype(np.float32)\n","    \n","    def preprocess_volume(self, volume):\n","        \"\"\"Deprecated: kept for compatibility; not used in fast path.\"\"\"\n","        # Fallback CPU preprocessing if needed\n","        p1, p99 = np.percentile(volume, [1, 99])\n","        volume = np.clip(volume, p1, p99)\n","        volume = (volume - p1) / (p99 - p1 + 1e-8)\n","        if volume.shape != self.target_size:\n","            zoom_factors = [self.target_size[i] / volume.shape[i] for i in range(3)]\n","            volume = ndimage.zoom(volume, zoom_factors, order=1)\n","        return volume.astype(np.float32)\n","\n","print(\"✅ DICOM Processor loaded\")\n","\n","# ====================================================\n","# CELL 4: DATASET CLASS\n","# ====================================================\n","\n","class SimpleSegmentationDataset(Dataset):\n","    def __init__(self, df, series_dir, processor, mode='train'):\n","        self.df = df\n","        self.series_dir = series_dir\n","        self.processor = processor\n","        self.mode = mode\n","        \n","        # Enhanced augmentation for training, simple transforms for validation\n","        if mode == 'train':\n","            self.transform = Enhanced3DAugmentation(mode='train')\n","        else:\n","            self.transform = CustomTransforms(keys=['volume'])\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def validate_segmentation_mask(self, series_id, mask):\n","        \"\"\"Validate segmentation mask quality\"\"\"\n","        # Check if mask is empty\n","        if mask.max() == 0:\n","            return False\n","            \n","        # Check mask connectivity and size\n","        mask_binary = (mask > 0.5).astype(np.uint8)\n","        labeled_mask, num_components = ndimage.label(mask_binary)\n","        \n","        if num_components == 0:\n","            return False\n","            \n","        # Check component sizes (aneurysms should be small but not tiny)\n","        component_sizes = []\n","        for i in range(1, num_components + 1):\n","            component_size = np.sum(labeled_mask == i)\n","            component_sizes.append(component_size)\n","        \n","        # Valid if has reasonably sized components\n","        valid_components = [size for size in component_sizes if 10 < size < 10000]\n","        return len(valid_components) > 0\n","    \n","    \n","    def load_segmentation_mask(self, series_id, volume_shape):\n","        \"\"\"Load real segmentation mask from competition data with validation\"\"\"\n","        seg_path = os.path.join(Config.SEGMENTATION_DIR, f\"{series_id}.nii\")\n","        \n","        try:\n","            if os.path.exists(seg_path):\n","                # Load NIfTI segmentation mask\n","                import nibabel as nib\n","                nii_img = nib.load(seg_path)\n","                mask = nii_img.get_fdata().astype(np.float32)\n","                \n","                # Resize mask to match volume shape\n","                if mask.shape != volume_shape:\n","                    zoom_factors = [volume_shape[i] / mask.shape[i] for i in range(3)]\n","                    mask = ndimage.zoom(mask, zoom_factors, order=0)  # Nearest neighbor for masks\n","                \n","                # Normalize mask values to 0-1\n","                mask = (mask > 0).astype(np.float32)\n","                \n","                # Validate mask quality\n","                if self.validate_segmentation_mask(series_id, mask):\n","                    return mask\n","                else:\n","                    # Mask failed validation - use fallback for aneurysm cases\n","                    has_aneurysm = int(self.df[self.df[Config.ID_COL] == series_id][Config.TARGET_COL].iloc[0])\n","                    if has_aneurysm:\n","                        # Create enhanced central region mask for aneurysm cases\n","                        mask = np.zeros(volume_shape, dtype=np.float32)\n","                        h, w, d = volume_shape\n","                        # Multiple small regions to simulate potential aneurysm locations\n","                        mask[h//3:2*h//3, w//3:2*w//3, d//3:2*d//3] = 0.7\n","                        mask[h//4:3*h//4, w//4:3*w//4, d//2:d//2+d//8] = 1.0  # Central strong region\n","                        return mask\n","                    else:\n","                        return np.zeros(volume_shape, dtype=np.float32)\n","            else:\n","                # No segmentation available - fallback based on aneurysm label\n","                has_aneurysm = int(self.df[self.df[Config.ID_COL] == series_id][Config.TARGET_COL].iloc[0])\n","                if has_aneurysm:\n","                    # Randomized synthetic cube\n","                    D, H, W = volume_shape\n","                    min_dim = min(D, H, W)\n","                    frac_low, frac_high = Config.SYN_MASK_SIZE_FRAC\n","                    edge = int(np.random.uniform(frac_low, frac_high) * min_dim)\n","                    edge = max(4, min(edge, min_dim))\n","                    if Config.SYN_MASK_RANDOM_CENTER:\n","                        cz = np.random.randint(edge//2, D - edge//2) if D > edge else D // 2\n","                        cy = np.random.randint(edge//2, H - edge//2) if H > edge else H // 2\n","                        cx = np.random.randint(edge//2, W - edge//2) if W > edge else W // 2\n","                    else:\n","                        cz, cy, cx = D//2, H//2, W//2\n","                    z1, z2 = max(0, cz - edge//2), min(D, cz + edge//2)\n","                    y1, y2 = max(0, cy - edge//2), min(H, cy + edge//2)\n","                    x1, x2 = max(0, cx - edge//2), min(W, cx + edge//2)\n","                    mask = np.zeros(volume_shape, dtype=np.float32)\n","                    mask[z1:z2, y1:y2, x1:x2] = 1.0\n","                    return mask\n","                else:\n","                    return np.zeros(volume_shape, dtype=np.float32)\n","                \n","        except Exception as e:\n","            print(f\"Error loading segmentation for {series_id} (corrupt nii?): {e}\")\n","            # For corrupt files, avoid giving synthetic positives blindly; use zeros\n","            return np.zeros(volume_shape, dtype=np.float32)\n","    \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        series_id = row[Config.ID_COL]\n","        series_path = os.path.join(self.series_dir, series_id)\n","        \n","        # Load volume\n","        volume = self.processor.load_dicom_series(series_path)\n","\n","        # Get aneurysm presence label\n","        has_aneurysm = int(row[Config.TARGET_COL])\n","        \n","        # Load segmentation mask from cache (builds once if missing)\n","        mask = self.processor.load_and_cache_mask(series_id, bool(has_aneurysm))\n","        \n","        # Transform (CPU augmentations kept lightweight)\n","        data_dict = {'volume': volume}\n","        if self.transform:\n","            data_dict = self.transform(data_dict)\n","        vol_np = data_dict['volume'].numpy() if isinstance(data_dict['volume'], torch.Tensor) else data_dict['volume']\n","        # Ensure numpy array, contiguous, and writable (decouple from read-only storage)\n","        if isinstance(vol_np, torch.Tensor):\n","            vol_np = vol_np.cpu().numpy()\n","        vol_np = np.ascontiguousarray(vol_np).copy()\n","        volume_tensor = torch.tensor(vol_np, dtype=torch.float32).unsqueeze(0).contiguous()  # [1, D, H, W]\n","        # mask already at target size/dtype via cache\n","        mask_np = np.ascontiguousarray(mask).copy()\n","        mask_tensor = torch.tensor(mask_np, dtype=torch.float32).unsqueeze(0).contiguous()\n","        \n","        return {\n","            'volume': volume_tensor,\n","            'mask': mask_tensor,\n","            'has_aneurysm': torch.tensor(has_aneurysm, dtype=torch.float32),\n","            'series_id': series_id\n","        }\n","\n","print(\"✅ Dataset class loaded\")\n","\n","# ====================================================\n","# CELL 5: 3D U-NET MODEL\n","# ====================================================\n","\n","class Simple3DSegmentationNet(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=1):\n","        super().__init__()\n","        \n","        # Use our Custom3DUNet - pure PyTorch implementation!\n","        self.backbone = Custom3DUNet(spatial_dims=3, in_channels=in_channels, dropout=0.1)\n","        \n","        # Segmentation head\n","        self.seg_head = nn.Conv3d(Config.UNET_OUT_CHANNELS, out_channels, kernel_size=1)\n","\n","        # Classification head (aneurysm presence)\n","        self.global_pool = nn.AdaptiveAvgPool3d(1)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(Config.UNET_OUT_CHANNELS, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, 1)\n","        )\n","\n","        \n","    def forward(self, x):\n","        # Extract features\n","        features = self.backbone(x)\n","        \n","        # Segmentation output\n","        seg_logits = self.seg_head(features)\n","        \n","        # Classification output\n","        pooled_features = self.global_pool(features).flatten(1)\n","        cls_logits = self.classifier(pooled_features)\n","        \n","        return seg_logits, cls_logits\n","\n","print(\"✅ Model architecture loaded\")\n","\n","# ====================================================\n","# CELL 6: ENHANCED LOSS FUNCTIONS\n","# ====================================================\n","\n","class DiceLoss(nn.Module):\n","    \"\"\"Dice Loss for better segmentation of small objects\"\"\"\n","    def __init__(self, smooth=1e-6):\n","        super().__init__()\n","        self.smooth = smooth\n","        \n","    def forward(self, predictions, targets):\n","        # Apply sigmoid to logits and clamp to avoid log(0) / NaN in grads\n","        predictions = torch.sigmoid(predictions).clamp(min=1e-6, max=1-1e-6)\n","        \n","        # Flatten tensors\n","        predictions = predictions.view(-1)\n","        targets = targets.view(-1)\n","        \n","        # Calculate intersection and union\n","        intersection = (predictions * targets).sum()\n","        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n","        \n","        return 1 - dice\n","\n","class FocalLoss(nn.Module):\n","    \"\"\"Focal Loss for handling class imbalance\"\"\"\n","    def __init__(self, alpha=0.25, gamma=2.0, smooth=1e-6):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.smooth = smooth\n","        \n","    def forward(self, predictions, targets):\n","        # Apply sigmoid to get probabilities\n","        probs = torch.sigmoid(predictions)\n","        \n","        # Calculate focal loss components with clamped probs for stability\n","        probs = probs.clamp(min=1e-6, max=1-1e-6)\n","        pt = torch.where(targets == 1, probs, 1 - probs)\n","        ce_loss = nn.functional.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n","        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n","        \n","        return focal_loss.mean()\n","        \n","class EnhancedCombinedLoss(nn.Module):\n","    \"\"\"Enhanced loss combining Dice + BCE + Focal (seg) + BCE (cls) with weights\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        self.dice_loss = DiceLoss()\n","        self.bce_loss = nn.BCEWithLogitsLoss()\n","        self.focal_loss = FocalLoss(alpha=0.25, gamma=2)\n","        \n","    def forward(self, seg_logits, cls_logits, seg_targets, cls_targets, is_synthetic_mask: bool):\n","        # Multi-component segmentation loss\n","        dice_loss = self.dice_loss(seg_logits, seg_targets)\n","        bce_seg_loss = self.bce_loss(seg_logits, seg_targets)\n","        focal_seg_loss = self.focal_loss(seg_logits, seg_targets)\n","        seg_loss = 0.5 * dice_loss + 0.3 * bce_seg_loss + Config.FOCAL_LOSS_WEIGHT * focal_seg_loss\n","        \n","        # Down-weight seg loss if targets are synthetic\n","        seg_weight = Config.SEG_LOSS_WEIGHT if is_synthetic_mask else 1.0\n","        seg_loss = seg_weight * seg_loss\n","        \n","        # Classification loss (preserve batch dim)\n","        # Clamp logits for stability\n","        cls_loss = self.bce_loss(cls_logits.view(-1), cls_targets)\n","        \n","        # Total loss: prioritize classification guidance\n","        total_loss = seg_loss + 1.0 * cls_loss\n","        return total_loss, seg_loss, cls_loss\n","\n","print(\"✅ Enhanced loss functions loaded (Dice + BCE + Focal)\")\n","\n","# ====================================================\n","# CELL 7: TRAINING FUNCTIONS\n","# ====================================================\n","\n","def train_epoch(model, loader, optimizer, criterion, device, scaler=None):\n","    model.train()\n","    total_loss = 0\n","    total_seg_loss = 0\n","    total_cls_loss = 0\n","    num_batches = 0\n","    \n","    # Initialize grads for accumulation\n","    optimizer.zero_grad(set_to_none=True)\n","    for step, batch in enumerate(tqdm(loader, desc=\"Training\")):\n","        volume = batch['volume'].to(device, non_blocking=True)\n","        mask = batch['mask'].to(device, non_blocking=True)\n","        has_aneurysm = batch['has_aneurysm'].to(device, non_blocking=True)    \n","        \n","        # Forward pass\n","        with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION, dtype=torch.float16):\n","            # Volumes are pre-normalized and resized in cache; skip per-step norm/resize\n","            vol = volume\n","            if mask.shape[2:] != Config.STAGE1_TARGET_SIZE:\n","                with torch.cuda.amp.autocast(enabled=False):\n","                    mask = torch.nn.functional.interpolate(\n","                        mask.float(), size=Config.STAGE1_TARGET_SIZE, mode='nearest'\n","                    )\n","\n","            # Lightweight GPU augmentations (training only)\n","            if Config.AUG_ENABLE_GPU:\n","                # Brightness (clamped)\n","                if Config.AUG_BRIGHTNESS > 0:\n","                    b = (1.0 + (torch.rand(vol.size(0), 1, 1, 1, 1, device=vol.device) * 2 - 1) * Config.AUG_BRIGHTNESS)\n","                    vol = torch.clamp(vol * b, 0, 1)\n","                # Contrast\n","                if Config.AUG_CONTRAST > 0:\n","                    mean = vol.mean(dim=[2,3,4], keepdim=True)\n","                    c = (1.0 + (torch.rand(vol.size(0), 1, 1, 1, 1, device=vol.device) * 2 - 1) * Config.AUG_CONTRAST)\n","                    vol = torch.clamp((vol - mean) * c + mean, 0, 1)\n","                # Gamma\n","                gmin, gmax = Config.AUG_GAMMA_MINMAX\n","                if gmin != 1.0 or gmax != 1.0:\n","                    gamma = torch.rand(vol.size(0), 1, 1, 1, 1, device=vol.device) * (gmax - gmin) + gmin\n","                    vol = torch.clamp(vol, 0, 1) ** gamma\n","                # Noise\n","                if Config.AUG_NOISE_STD > 0:\n","                    std = torch.rand(vol.size(0), 1, 1, 1, 1, device=vol.device) * Config.AUG_NOISE_STD\n","                    noise = torch.randn_like(vol) * std\n","                    vol = torch.clamp(vol + noise, 0, 1)\n","\n","            seg_logits, cls_logits = model(vol)\n","            # Calculate loss\n","            is_synthetic = bool((mask.max() <= 0).item())\n","            # Ensure target dtype matches logits dtype to avoid mixed-type kernels\n","            mask = mask.to(dtype=seg_logits.dtype)\n","            loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm, is_synthetic)\n","        \n","        # Backward pass with gradient clipping (AMP-aware)\n","        if scaler is not None and Config.MIXED_PRECISION:\n","            scaler.scale(loss / Config.GRAD_ACCUM_STEPS).backward()\n","            if (step + 1) % Config.GRAD_ACCUM_STEPS == 0:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad(set_to_none=True)\n","        else:\n","            (loss / Config.GRAD_ACCUM_STEPS).backward()\n","            if (step + 1) % Config.GRAD_ACCUM_STEPS == 0:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                optimizer.step()\n","                optimizer.zero_grad(set_to_none=True)\n","            \n","        total_loss += loss.item()\n","        total_seg_loss += seg_loss.item()\n","        total_cls_loss += cls_loss.item()\n","        num_batches += 1\n","\n","        # Release per-batch tensors to help GPU memory\n","        del volume, mask, has_aneurysm, seg_logits, cls_logits, loss, seg_loss, cls_loss\n","    \n","    return (total_loss / num_batches, \n","            total_seg_loss / num_batches,\n","            total_cls_loss / num_batches)\n","            \n","\n","def validate_epoch(model, loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    total_seg_loss = 0\n","    total_cls_loss = 0\n","    num_batches = 0\n","    \n","    with torch.no_grad():\n","        for batch in tqdm(loader, desc=\"Validating\"):\n","            volume = batch['volume'].to(device, non_blocking=True)\n","            mask = batch['mask'].to(device, non_blocking=True)\n","            has_aneurysm = batch['has_aneurysm'].to(device, non_blocking=True)\n","            \n","            # Forward pass\n","            with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION, dtype=torch.float16):\n","                vol = volume\n","                if mask.shape[2:] != Config.STAGE1_TARGET_SIZE:\n","                    with torch.cuda.amp.autocast(enabled=False):\n","                        mask = torch.nn.functional.interpolate(\n","                            mask.float(), size=Config.STAGE1_TARGET_SIZE, mode='nearest'\n","                        )\n","\n","                # No GPU augs in validation\n","                seg_logits, cls_logits = model(vol)\n","                # Calculate loss\n","                is_synthetic = bool((mask.max() <= 0).item())\n","                loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm, is_synthetic)\n","            \n","            total_loss += loss.item()\n","            total_seg_loss += seg_loss.item()\n","            total_cls_loss += cls_loss.item()\n","            num_batches += 1\n","\n","            # Release per-batch tensors to help GPU memory\n","            del volume, mask, has_aneurysm, seg_logits, cls_logits, loss, seg_loss, cls_loss\n","    \n","    return (total_loss / num_batches, \n","            total_seg_loss / num_batches,\n","            total_cls_loss / num_batches)\n","\n","print(\"✅ Training functions loaded\")\n","\n","# ====================================================\n","# CELL 8: MAIN TRAINING LOOP\n","# ====================================================\n","\n","def main():\n","    print(f\"🚀 STAGE 1: 3D SEGMENTATION FOR REGION LOCALIZATION\")\n","    print(f\"Using device: {Config.DEVICE}\")\n","    print(f\"Target size: {Config.STAGE1_TARGET_SIZE}\")\n","    \n","    # Load data\n","    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n","    \n","    # Load localizer data (for future use)\n","    try:\n","        localizer_df = pd.read_csv(Config.LOCALIZER_CSV_PATH)\n","        print(f\"Loaded localizer data: {len(localizer_df)} entries\")\n","    except:\n","        localizer_df = None\n","        print(\"No localizer data found - continuing without it\")\n","    \n","    # Debug mode - small subset\n","    if Config.DEBUG_MODE:\n","        train_df = train_df.head(Config.DEBUG_SAMPLES)\n","    print(f\"Training samples (pre-filter): {len(train_df)}\")\n","    print(f\"Aneurysm cases (pre-filter): {train_df[Config.TARGET_COL].sum()}\")\n","\n","    # Optionally filter to series with real, non-empty masks\n","    if Config.FILTER_TO_MASKED_SERIES:\n","        def has_valid_mask(series_id: str) -> bool:\n","            seg_path = os.path.join(Config.SEGMENTATION_DIR, f\"{series_id}.nii\")\n","            if not os.path.exists(seg_path):\n","                return False\n","            try:\n","                nii = nib.load(seg_path)\n","                mask = nii.get_fdata()\n","                return np.any(mask > 0)\n","            except Exception:\n","                return False\n","\n","        filtered_df = train_df[train_df[Config.ID_COL].apply(has_valid_mask)].reset_index(drop=True)\n","        if len(filtered_df) == 0:\n","            print(\"⚠️ No series with ground-truth masks found. Proceeding without filtering.\")\n","        else:\n","            train_df = filtered_df\n","        print(f\"Training samples (post-filter): {len(train_df)}\")\n","        print(f\"Aneurysm cases (post-filter): {train_df[Config.TARGET_COL].sum()}\")\n","    \n","    # Simple train/val split\n","    val_size = len(train_df) // 5\n","    val_df = train_df[:val_size].reset_index(drop=True)\n","    train_df = train_df[val_size:].reset_index(drop=True)\n","    \n","    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n","    \n","    # Create datasets\n","    processor = SimpleDICOMProcessor()\n","    train_dataset = SimpleSegmentationDataset(train_df, Config.SERIES_DIR, processor, 'train')\n","    val_dataset = SimpleSegmentationDataset(val_df, Config.SERIES_DIR, processor, 'val')\n","\n","    # Optional pre-build caches to eliminate stalls\n","    if Config.PRE_BUILD_CACHE:\n","        print(\"\\n🚀 Pre-building caches (volumes + masks) ...\")\n","        combined_df = pd.concat([train_df, val_df], ignore_index=True)\n","        for _, row in tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Building caches\"):\n","            sid = row[Config.ID_COL]\n","            spath = os.path.join(Config.SERIES_DIR, sid)\n","            if not os.path.exists(spath):\n","                continue\n","            # Build volume cache\n","            _ = processor.load_dicom_series(spath)\n","            # Build mask cache\n","            has_an = bool(int(row[Config.TARGET_COL]))\n","            _ = processor.load_and_cache_mask(sid, has_an)\n","        gc.collect()\n","        print(\"✅ Cache building complete. Training will have minimal stalls.\")\n","    \n","    # Create loaders (tuned for throughput)\n","    cpu_count = os.cpu_count() or 2\n","    # num_workers = min(8, max(2, cpu_count - 1))\n","    num_workers = 8\n","    loader_kwargs = dict(\n","        batch_size=Config.STAGE1_BATCH_SIZE,\n","        pin_memory=True,\n","        num_workers=num_workers,\n","        persistent_workers=True,\n","        prefetch_factor=8,\n","    )\n","\n","    # Custom collate to avoid non-resizable storage issues during default_collate\n","    def collate_segmentation_batch(batch_list):\n","        volumes = torch.stack([sample['volume'].contiguous() for sample in batch_list], dim=0)\n","        masks = torch.stack([sample['mask'].contiguous() for sample in batch_list], dim=0)\n","        has = torch.stack([\n","            sample['has_aneurysm'] if isinstance(sample['has_aneurysm'], torch.Tensor)\n","            else torch.tensor(sample['has_aneurysm'], dtype=torch.float32)\n","            for sample in batch_list\n","        ], dim=0)\n","        series_ids = [sample['series_id'] for sample in batch_list]\n","        return {\n","            'volume': volumes,\n","            'mask': masks,\n","            'has_aneurysm': has,\n","            'series_id': series_ids,\n","        }\n","\n","    train_loader = DataLoader(train_dataset, shuffle=True, drop_last=False, collate_fn=collate_segmentation_batch, **loader_kwargs)\n","\n","    # # Validation subsampling: use fraction each epoch except last\n","    # if Config.VAL_SUBSAMPLE_FRACTION < 1.0 and len(val_dataset) > 0:\n","    #     val_indices = np.random.RandomState(Config.SEED).choice(\n","    #         len(val_dataset),\n","    #         size=max(1, int(len(val_dataset) * Config.VAL_SUBSAMPLE_FRACTION)),\n","    #         replace=False\n","    #     )\n","    #     val_subset = torch.utils.data.Subset(val_dataset, val_indices.tolist())\n","    #     val_loader = DataLoader(val_subset, shuffle=False, drop_last=False, collate_fn=collate_segmentation_batch, **loader_kwargs)\n","    #     print(f\"Validation subsample size: {len(val_subset)} / {len(val_dataset)}\")\n","    # else:\n","    #     val_loader = DataLoader(val_dataset, shuffle=False, drop_last=False, collate_fn=collate_segmentation_batch, **loader_kwargs)\n","\n","    # Full validation for final run\n","    val_loader = DataLoader(val_dataset, shuffle=False, drop_last=False, collate_fn=collate_segmentation_batch, **loader_kwargs)\n","    \n","    # Create model\n","    model = Simple3DSegmentationNet().to(Config.DEVICE)\n","\n","    # Enable TF32 for speed on Ampere (safe for training)\n","    try:\n","        torch.backends.cuda.matmul.allow_tf32 = True\n","        torch.backends.cudnn.allow_tf32 = True\n","    except Exception:\n","        pass\n","    \n","    # Multi-GPU if available\n","    if torch.cuda.device_count() > 1:\n","        print(f\"Using {torch.cuda.device_count()} GPUs\")\n","        model = nn.DataParallel(model)\n","    \n","    # Enhanced optimizer and loss - proven optimization from winning solutions\n","    optimizer = optim.AdamW(model.parameters(), lr=Config.STAGE1_LR, weight_decay=1e-4)\n","    criterion = EnhancedCombinedLoss()  # Use enhanced loss function\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.STAGE1_EPOCHS, eta_min=1e-6)\n","    scaler = torch.cuda.amp.GradScaler(enabled=Config.MIXED_PRECISION)\n","    \n","    # Training loop\n","    best_loss = float('inf')\n","    no_improve_epochs = 0\n","    \n","    for epoch in range(Config.STAGE1_EPOCHS):\n","        print(f\"\\nEpoch {epoch+1}/{Config.STAGE1_EPOCHS}\")\n","        \n","        # Train\n","        train_loss, train_seg_loss, train_cls_loss = train_epoch(\n","            model, train_loader, optimizer, criterion, Config.DEVICE, scaler\n","        )\n","        \n","        # Validate\n","        val_loss, val_seg_loss, val_cls_loss = validate_epoch(\n","            model, val_loader, criterion, Config.DEVICE\n","        )\n","        \n","        # Step scheduler\n","        scheduler.step()\n","        \n","        print(f\"Train - Total: {train_loss:.4f}, Seg: {train_seg_loss:.4f}, Cls: {train_cls_loss:.4f}\")\n","        print(f\"Val   - Total: {val_loss:.4f}, Seg: {val_seg_loss:.4f}, Cls: {val_cls_loss:.4f}\")\n","        \n","        # Save best model & early stopping\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            no_improve_epochs = 0\n","            torch.save({\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'epoch': epoch,\n","                'val_loss': val_loss\n","            }, 'stage1_segmentation_best.pth')\n","            print(f\"💾 Saved best model (val_loss: {val_loss:.4f})\")\n","        else:\n","            no_improve_epochs += 1\n","            if no_improve_epochs >= Config.EARLY_STOPPING_PATIENCE:\n","                print(f\"⏹️ Early stopping at epoch {epoch+1} (no improvement for {Config.EARLY_STOPPING_PATIENCE} epochs)\")\n","                break\n","\n","        # Proactive memory cleanup after each epoch\n","        try:\n","            if torch.cuda.is_available():\n","                torch.cuda.synchronize()\n","                torch.cuda.empty_cache()\n","        except Exception:\n","            pass\n","        gc.collect()\n","    \n","    print(f\"\\n✅ Stage 1 complete! Best val loss: {best_loss:.4f}\")\n","    print(\"📁 Model saved as 'stage1_segmentation_best.pth'\")\n","    \n","    return model\n","\n","# ====================================================\n","# CELL 9: ROI EXTRACTOR FOR STAGE 2 (FUTURE USE)\n","# ====================================================\n","\n","class ROIExtractor:\n","    def __init__(self, roi_size=(224, 224), confidence_threshold=0.5):\n","        self.roi_size = roi_size\n","        self.confidence_threshold = confidence_threshold\n","    \n","    def extract_rois(self, volume, segmentation_mask):\n","        \"\"\"Extract 2D ROI slices from 3D volume using segmentation mask\"\"\"\n","        rois = []\n","        \n","        # Find slices with high confidence regions\n","        for slice_idx in range(volume.shape[0]):\n","            slice_volume = volume[slice_idx]\n","            slice_mask = segmentation_mask[slice_idx]\n","            \n","            # Check if this slice has potential aneurysm regions\n","            if np.max(slice_mask) > self.confidence_threshold:\n","                # Find connected components\n","                binary_mask = (slice_mask > self.confidence_threshold).astype(np.uint8)\n","                \n","                # Find contours\n","                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","                \n","                for contour in contours:\n","                    # Get bounding box\n","                    x, y, w, h = cv2.boundingRect(contour)\n","                    \n","                    # Expand bounding box\n","                    margin = max(w, h) // 4\n","                    x = max(0, x - margin)\n","                    y = max(0, y - margin)\n","                    w = min(slice_volume.shape[1] - x, w + 2*margin)\n","                    h = min(slice_volume.shape[0] - y, h + 2*margin)\n","                    \n","                    # Extract ROI\n","                    roi = slice_volume[y:y+h, x:x+w]\n","                    \n","                    # Resize to standard size\n","                    roi_resized = cv2.resize(roi, self.roi_size)\n","                    \n","                    rois.append({\n","                        'roi': roi_resized,\n","                        'slice_idx': slice_idx,\n","                        'bbox': (x, y, w, h),\n","                        'confidence': np.max(slice_mask[y:y+h, x:x+w])\n","                    })\n","        \n","        return rois\n","\n","print(\"✅ ROI Extractor loaded (for Stage 2)\")"]},{"cell_type":"code","execution_count":3,"id":"b5c82d18","metadata":{"execution":{"iopub.execute_input":"2025-08-16T08:55:55.126267Z","iopub.status.busy":"2025-08-16T08:55:55.125894Z","iopub.status.idle":"2025-08-16T17:08:30.563116Z","shell.execute_reply":"2025-08-16T17:08:30.561891Z"},"papermill":{"duration":29555.442901,"end_time":"2025-08-16T17:08:30.565933","exception":false,"start_time":"2025-08-16T08:55:55.123032","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["🚀 STAGE 1: 3D SEGMENTATION FOR REGION LOCALIZATION\n","Using device: cuda\n","Target size: (48, 112, 112)\n","Loaded localizer data: 2286 entries\n","Training samples (pre-filter): 4405\n","Aneurysm cases (pre-filter): 1893\n","Train: 3524, Val: 881\n","\n","🚀 Pre-building caches (volumes + masks) ...\n"]},{"name":"stderr","output_type":"stream","text":["Building caches: 100%|██████████| 4405/4405 [1:17:49<00:00,  1.06s/it]\n"]},{"name":"stdout","output_type":"stream","text":["✅ Cache building complete. Training will have minimal stalls.\n","Using 2 GPUs\n","\n","Epoch 1/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:48<00:00, 13.35s/it]\n","Validating: 100%|██████████| 25/25 [05:34<00:00, 13.39s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.3888, Seg: 0.7018, Cls: 0.6870\n","Val   - Total: 1.3639, Seg: 0.6763, Cls: 0.6876\n","💾 Saved best model (val_loss: 1.3639)\n","\n","Epoch 2/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:33<00:00, 13.81s/it]\n","Validating: 100%|██████████| 25/25 [05:21<00:00, 12.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.3411, Seg: 0.6585, Cls: 0.6825\n","Val   - Total: 1.3257, Seg: 0.6395, Cls: 0.6862\n","💾 Saved best model (val_loss: 1.3257)\n","\n","Epoch 3/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:12<00:00, 13.60s/it]\n","Validating: 100%|██████████| 25/25 [05:24<00:00, 12.97s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2999, Seg: 0.6217, Cls: 0.6781\n","Val   - Total: 1.2924, Seg: 0.6071, Cls: 0.6853\n","💾 Saved best model (val_loss: 1.2924)\n","\n","Epoch 4/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:32<00:00, 13.80s/it]\n","Validating: 100%|██████████| 25/25 [05:23<00:00, 12.93s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2710, Seg: 0.5916, Cls: 0.6794\n","Val   - Total: 1.2658, Seg: 0.5798, Cls: 0.6859\n","💾 Saved best model (val_loss: 1.2658)\n","\n","Epoch 5/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:07<00:00, 13.54s/it]\n","Validating: 100%|██████████| 25/25 [05:16<00:00, 12.67s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2452, Seg: 0.5686, Cls: 0.6765\n","Val   - Total: 1.2441, Seg: 0.5599, Cls: 0.6842\n","💾 Saved best model (val_loss: 1.2441)\n","\n","Epoch 6/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:54<00:00, 13.42s/it]\n","Validating: 100%|██████████| 25/25 [05:18<00:00, 12.76s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2295, Seg: 0.5525, Cls: 0.6770\n","Val   - Total: 1.2298, Seg: 0.5456, Cls: 0.6842\n","💾 Saved best model (val_loss: 1.2298)\n","\n","Epoch 7/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:59<00:00, 13.46s/it]\n","Validating: 100%|██████████| 25/25 [05:12<00:00, 12.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2175, Seg: 0.5418, Cls: 0.6756\n","Val   - Total: 1.2203, Seg: 0.5375, Cls: 0.6828\n","💾 Saved best model (val_loss: 1.2203)\n","\n","Epoch 8/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:58<00:00, 13.45s/it]\n","Validating: 100%|██████████| 25/25 [05:21<00:00, 12.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2096, Seg: 0.5348, Cls: 0.6748\n","Val   - Total: 1.2132, Seg: 0.5312, Cls: 0.6820\n","💾 Saved best model (val_loss: 1.2132)\n","\n","Epoch 9/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:58<00:00, 13.45s/it]\n","Validating: 100%|██████████| 25/25 [05:20<00:00, 12.83s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2046, Seg: 0.5301, Cls: 0.6746\n","Val   - Total: 1.2088, Seg: 0.5276, Cls: 0.6812\n","💾 Saved best model (val_loss: 1.2088)\n","\n","Epoch 10/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:26<00:00, 13.74s/it]\n","Validating: 100%|██████████| 25/25 [05:28<00:00, 13.14s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2010, Seg: 0.5271, Cls: 0.6738\n","Val   - Total: 1.2047, Seg: 0.5251, Cls: 0.6796\n","💾 Saved best model (val_loss: 1.2047)\n","\n","Epoch 11/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:40<00:00, 13.88s/it]\n","Validating: 100%|██████████| 25/25 [05:28<00:00, 13.15s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.2001, Seg: 0.5252, Cls: 0.6749\n","Val   - Total: 1.2031, Seg: 0.5233, Cls: 0.6798\n","💾 Saved best model (val_loss: 1.2031)\n","\n","Epoch 12/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [23:03<00:00, 14.12s/it]\n","Validating: 100%|██████████| 25/25 [05:31<00:00, 13.24s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.1978, Seg: 0.5233, Cls: 0.6746\n","Val   - Total: 1.2013, Seg: 0.5224, Cls: 0.6789\n","💾 Saved best model (val_loss: 1.2013)\n","\n","Epoch 13/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [22:32<00:00, 13.80s/it]\n","Validating: 100%|██████████| 25/25 [05:19<00:00, 12.77s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.1950, Seg: 0.5226, Cls: 0.6724\n","Val   - Total: 1.2002, Seg: 0.5217, Cls: 0.6785\n","💾 Saved best model (val_loss: 1.2002)\n","\n","Epoch 14/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:59<00:00, 13.46s/it]\n","Validating: 100%|██████████| 25/25 [05:20<00:00, 12.82s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.1950, Seg: 0.5224, Cls: 0.6726\n","Val   - Total: 1.1998, Seg: 0.5214, Cls: 0.6785\n","💾 Saved best model (val_loss: 1.1998)\n","\n","Epoch 15/15\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 98/98 [21:54<00:00, 13.41s/it]\n","Validating: 100%|██████████| 25/25 [05:23<00:00, 12.94s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 1.1946, Seg: 0.5219, Cls: 0.6726\n","Val   - Total: 1.1993, Seg: 0.5213, Cls: 0.6780\n","💾 Saved best model (val_loss: 1.1993)\n","\n","✅ Stage 1 complete! Best val loss: 1.1993\n","📁 Model saved as 'stage1_segmentation_best.pth'\n","Expected training time: Approx 5 hours\n","Output: stage1_segmentation_best.pth\n"]}],"source":["# ====================================================\n","# CELL 10: RUN TRAINING\n","# ====================================================\n","\n","# Start Training\n","model = main()\n","\n","print(\"Expected training time: Approx 5 hours\")\n","print(\"Output: stage1_segmentation_best.pth\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":13190393,"sourceId":99552,"sourceType":"competition"}],"dockerImageVersionId":31089,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":29570.938167,"end_time":"2025-08-16T17:08:35.141134","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-16T08:55:44.202967","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}