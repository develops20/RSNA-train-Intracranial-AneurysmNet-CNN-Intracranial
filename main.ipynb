{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":99552,"databundleVersionId":13190393,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/02-aneurysmnet-cnn-intracranial-training-nb153?scriptVersionId=254354668\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install monai\n\n# ====================================================\n# RSNA INTRACRANIAL ANEURYSM DETECTION - TRAINING PIPELINE\n# ====================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pydicom\nimport nibabel as nib\nimport cv2\nfrom scipy import ndimage\nfrom monai.networks.nets import BasicUNet\nfrom monai.transforms import Compose, ToTensord\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================================\n# CELL 2: CONFIGURATION\n# ====================================================\n\nclass Config:\n    # Paths\n    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n    LOCALIZER_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\n    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n    \n    # Stage 1: 3D Segmentation\n    STAGE1_TARGET_SIZE = (64, 128, 128)  # Smaller for speed\n    STAGE1_BATCH_SIZE = 4\n    STAGE1_EPOCHS = 5\n    STAGE1_LR = 1e-3\n    \n    # General\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    MIXED_PRECISION = True\n    N_FOLDS = 3\n    \n    # Competition constants\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n    TARGET_COL = 'Aneurysm Present'\n    \n    # Debug settings\n    DEBUG_MODE = True\n    DEBUG_SAMPLES = 50  # Use small subset for testing\n\nprint(f\"âœ… Configuration loaded - Device: {Config.DEVICE}\")\n\n\n# ====================================================\n# CELL 3: SIMPLE DICOM PROCESSOR\n# ====================================================\n\nclass SimpleDICOMProcessor:\n    def __init__(self, target_size=None):\n        self.target_size = target_size or Config.STAGE1_TARGET_SIZE\n        \n    def load_dicom_series(self, series_path):\n        \"\"\"Simple DICOM loading - no complex error handling\"\"\"\n        try:\n            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n            if not dicom_files:\n                return np.zeros(self.target_size, dtype=np.float32)\n            \n            # Load all DICOMs\n            pixel_arrays = []\n            for f in dicom_files[:50]:  # Limit to 50 files max for speed\n                try:\n                    ds = pydicom.dcmread(os.path.join(series_path, f), force=True)\n                    if hasattr(ds, 'pixel_array'):\n                        arr = ds.pixel_array\n                        if arr.ndim == 2:  # Standard 2D slice\n                            pixel_arrays.append(arr)\n                        elif arr.ndim == 3:  # 3D volume - take middle slices\n                            mid_start = arr.shape[0] // 4\n                            mid_end = 3 * arr.shape[0] // 4\n                            for slice_idx in range(mid_start, mid_end, 2):  # Every 2nd slice\n                                pixel_arrays.append(arr[slice_idx])\n                except:\n                    continue\n            \n            if not pixel_arrays:\n                return np.zeros(self.target_size, dtype=np.float32)\n            \n            # Stack into volume\n            volume = np.stack(pixel_arrays, axis=0).astype(np.float32)\n            \n            # Simple preprocessing\n            volume = self.preprocess_volume(volume)\n            return volume\n            \n        except Exception as e:\n            print(f\"Failed to load {series_path}: {e}\")\n            return np.zeros(self.target_size, dtype=np.float32)\n    \n    def preprocess_volume(self, volume):\n        \"\"\"Simple preprocessing\"\"\"\n        # Normalize\n        p1, p99 = np.percentile(volume, [1, 99])\n        volume = np.clip(volume, p1, p99)\n        volume = (volume - p1) / (p99 - p1 + 1e-8)\n        \n        # Resize to target\n        if volume.shape != self.target_size:\n            zoom_factors = [self.target_size[i] / volume.shape[i] for i in range(3)]\n            volume = ndimage.zoom(volume, zoom_factors, order=1)\n        \n        return volume.astype(np.float32)\n\nprint(\"âœ… DICOM Processor loaded\")\n\n# ====================================================\n# CELL 4: DATASET CLASS\n# ====================================================\n\nclass SimpleSegmentationDataset(Dataset):\n    def __init__(self, df, series_dir, processor, mode='train'):\n        self.df = df\n        self.series_dir = series_dir\n        self.processor = processor\n        self.mode = mode\n        \n        # Simple transform\n        self.transform = Compose([ToTensord(keys=['volume'])])\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def load_segmentation_mask(self, series_id, volume_shape):\n        \"\"\"Load real segmentation mask from competition data\"\"\"\n        seg_path = os.path.join(Config.SEGMENTATION_DIR, f\"{series_id}.nii\")\n        \n        try:\n            if os.path.exists(seg_path):\n                # Load NIfTI segmentation mask\n                import nibabel as nib\n                nii_img = nib.load(seg_path)\n                mask = nii_img.get_fdata().astype(np.float32)\n                \n                # Resize mask to match volume shape\n                if mask.shape != volume_shape:\n                    zoom_factors = [volume_shape[i] / mask.shape[i] for i in range(3)]\n                    mask = ndimage.zoom(mask, zoom_factors, order=0)  # Nearest neighbor for masks\n                \n                # Normalize mask values to 0-1\n                mask = (mask > 0).astype(np.float32)\n                return mask\n            else:\n                # No segmentation available - create empty mask\n                return np.zeros(volume_shape, dtype=np.float32)\n                \n        except Exception as e:\n            print(f\"Error loading segmentation for {series_id}: {e}\")\n            # Fallback: create simple mask if aneurysm present\n            has_aneurysm = int(self.df[self.df[Config.ID_COL] == series_id][Config.TARGET_COL].iloc[0])\n            if has_aneurysm:\n                # Create a rough central region mask as fallback\n                mask = np.zeros(volume_shape, dtype=np.float32)\n                h, w, d = volume_shape\n                mask[h//4:3*h//4, w//4:3*w//4, d//4:3*d//4] = 1.0\n                return mask\n            else:\n                return np.zeros(volume_shape, dtype=np.float32)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        series_id = row[Config.ID_COL]\n        series_path = os.path.join(self.series_dir, series_id)\n        \n        # Load volume\n        volume = self.processor.load_dicom_series(series_path)\n        \n        # Load REAL segmentation mask from competition data\n        mask = self.load_segmentation_mask(series_id, volume.shape)\n        \n        # Get aneurysm presence label\n        has_aneurysm = int(row[Config.TARGET_COL])\n        \n        # Transform\n        data_dict = {'volume': volume}\n        if self.transform:\n            data_dict = self.transform(data_dict)\n        \n        volume_tensor = data_dict['volume'].unsqueeze(0)  # Add channel dim\n        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n        \n        return {\n            'volume': volume_tensor,\n            'mask': mask_tensor,\n            'has_aneurysm': torch.tensor(has_aneurysm, dtype=torch.float32),\n            'series_id': series_id\n        }\n\nprint(\"âœ… Dataset class loaded\")\n\n# ====================================================\n# CELL 5: 3D U-NET MODEL\n# ====================================================\n\nclass Simple3DSegmentationNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super().__init__()\n        \n        # Use MONAI's BasicUNet - simple and proven\n        self.backbone = BasicUNet(\n            spatial_dims=3,\n            in_channels=in_channels,\n            out_channels=32,\n            features=(32, 64, 128, 256, 32),\n            dropout=0.1\n        )\n        \n        # Segmentation head\n        self.seg_head = nn.Conv3d(32, out_channels, kernel_size=1)\n        \n        # Classification head (aneurysm presence)\n        self.global_pool = nn.AdaptiveAvgPool3d(1)\n        self.classifier = nn.Sequential(\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, x):\n        # Extract features\n        features = self.backbone(x)\n        \n        # Segmentation output\n        seg_logits = self.seg_head(features)\n        \n        # Classification output\n        pooled_features = self.global_pool(features).flatten(1)\n        cls_logits = self.classifier(pooled_features)\n        \n        return seg_logits, cls_logits\n\nprint(\"âœ… Model architecture loaded\")\n\n# ====================================================\n# CELL 6: LOSS FUNCTIONS\n# ====================================================\n\nclass CombinedLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bce_loss = nn.BCEWithLogitsLoss()\n        self.seg_loss = nn.BCEWithLogitsLoss()\n        \n    def forward(self, seg_logits, cls_logits, seg_targets, cls_targets):\n        # Segmentation loss\n        seg_loss = self.seg_loss(seg_logits, seg_targets)\n        \n        # Classification loss\n        cls_loss = self.bce_loss(cls_logits.squeeze(), cls_targets)\n        \n        # Combined loss\n        total_loss = seg_loss + 0.5 * cls_loss\n        \n        return total_loss, seg_loss, cls_loss\n\nprint(\"âœ… Loss functions loaded\")\n\n# ====================================================\n# CELL 7: TRAINING FUNCTIONS\n# ====================================================\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    total_seg_loss = 0\n    total_cls_loss = 0\n    num_batches = 0\n    \n    for batch in tqdm(loader, desc=\"Training\"):\n        volume = batch['volume'].to(device)\n        mask = batch['mask'].to(device)\n        has_aneurysm = batch['has_aneurysm'].to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        seg_logits, cls_logits = model(volume)\n        \n        # Calculate loss\n        loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_seg_loss += seg_loss.item()\n        total_cls_loss += cls_loss.item()\n        num_batches += 1\n    \n    return (total_loss / num_batches, \n            total_seg_loss / num_batches, \n            total_cls_loss / num_batches)\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_seg_loss = 0\n    total_cls_loss = 0\n    num_batches = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Validating\"):\n            volume = batch['volume'].to(device)\n            mask = batch['mask'].to(device)\n            has_aneurysm = batch['has_aneurysm'].to(device)\n            \n            # Forward pass\n            seg_logits, cls_logits = model(volume)\n            \n            # Calculate loss\n            loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm)\n            \n            total_loss += loss.item()\n            total_seg_loss += seg_loss.item()\n            total_cls_loss += cls_loss.item()\n            num_batches += 1\n    \n    return (total_loss / num_batches, \n            total_seg_loss / num_batches, \n            total_cls_loss / num_batches)\n\nprint(\"âœ… Training functions loaded\")\n\n\n# ====================================================\n# CELL 8: MAIN TRAINING LOOP\n# ====================================================\n\ndef main():\n    print(f\"ðŸš€ STAGE 1: 3D SEGMENTATION FOR REGION LOCALIZATION\")\n    print(f\"Using device: {Config.DEVICE}\")\n    print(f\"Target size: {Config.STAGE1_TARGET_SIZE}\")\n    \n    # Load data\n    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n    \n    # Load localizer data (for future use)\n    try:\n        localizer_df = pd.read_csv(Config.LOCALIZER_CSV_PATH)\n        print(f\"Loaded localizer data: {len(localizer_df)} entries\")\n    except:\n        localizer_df = None\n        print(\"No localizer data found - continuing without it\")\n    \n    # Debug mode - small subset\n    if Config.DEBUG_MODE:\n        train_df = train_df.head(Config.DEBUG_SAMPLES)\n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Aneurysm cases: {train_df[Config.TARGET_COL].sum()}\")\n    \n    # Simple train/val split\n    val_size = len(train_df) // 5\n    val_df = train_df[:val_size].reset_index(drop=True)\n    train_df = train_df[val_size:].reset_index(drop=True)\n    \n    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n    \n    # Create datasets\n    processor = SimpleDICOMProcessor()\n    train_dataset = SimpleSegmentationDataset(train_df, Config.SERIES_DIR, processor, 'train')\n    val_dataset = SimpleSegmentationDataset(val_df, Config.SERIES_DIR, processor, 'val')\n    \n    # Create loaders\n    train_loader = DataLoader(train_dataset, batch_size=Config.STAGE1_BATCH_SIZE, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=Config.STAGE1_BATCH_SIZE, shuffle=False, num_workers=2)\n    \n    # Create model\n    model = Simple3DSegmentationNet().to(Config.DEVICE)\n    \n    # Multi-GPU if available\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs\")\n        model = nn.DataParallel(model)\n    \n    # Optimizer and loss\n    optimizer = optim.AdamW(model.parameters(), lr=Config.STAGE1_LR)\n    criterion = CombinedLoss()\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.STAGE1_EPOCHS)\n    \n    # Training loop\n    best_loss = float('inf')\n    \n    for epoch in range(Config.STAGE1_EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{Config.STAGE1_EPOCHS}\")\n        \n        # Train\n        train_loss, train_seg_loss, train_cls_loss = train_epoch(\n            model, train_loader, optimizer, criterion, Config.DEVICE\n        )\n        \n        # Validate\n        val_loss, val_seg_loss, val_cls_loss = validate_epoch(\n            model, val_loader, criterion, Config.DEVICE\n        )\n        \n        # Step scheduler\n        scheduler.step()\n        \n        print(f\"Train - Total: {train_loss:.4f}, Seg: {train_seg_loss:.4f}, Cls: {train_cls_loss:.4f}\")\n        print(f\"Val   - Total: {val_loss:.4f}, Seg: {val_seg_loss:.4f}, Cls: {val_cls_loss:.4f}\")\n        \n        # Save best model\n        if val_loss < best_loss:\n            best_loss = val_loss\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'epoch': epoch,\n                'val_loss': val_loss\n            }, 'stage1_segmentation_best.pth')\n            print(f\"ðŸ’¾ Saved best model (val_loss: {val_loss:.4f})\")\n    \n    print(f\"\\nâœ… Stage 1 complete! Best val loss: {best_loss:.4f}\")\n    print(\"ðŸ“ Model saved as 'stage1_segmentation_best.pth'\")\n    \n    return model\n\n# ====================================================\n# CELL 9: ROI EXTRACTOR FOR STAGE 2 (FUTURE USE)\n# ====================================================\n\nclass ROIExtractor:\n    def __init__(self, roi_size=(224, 224), confidence_threshold=0.5):\n        self.roi_size = roi_size\n        self.confidence_threshold = confidence_threshold\n    \n    def extract_rois(self, volume, segmentation_mask):\n        \"\"\"Extract 2D ROI slices from 3D volume using segmentation mask\"\"\"\n        rois = []\n        \n        # Find slices with high confidence regions\n        for slice_idx in range(volume.shape[0]):\n            slice_volume = volume[slice_idx]\n            slice_mask = segmentation_mask[slice_idx]\n            \n            # Check if this slice has potential aneurysm regions\n            if np.max(slice_mask) > self.confidence_threshold:\n                # Find connected components\n                binary_mask = (slice_mask > self.confidence_threshold).astype(np.uint8)\n                \n                # Find contours\n                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n                \n                for contour in contours:\n                    # Get bounding box\n                    x, y, w, h = cv2.boundingRect(contour)\n                    \n                    # Expand bounding box\n                    margin = max(w, h) // 4\n                    x = max(0, x - margin)\n                    y = max(0, y - margin)\n                    w = min(slice_volume.shape[1] - x, w + 2*margin)\n                    h = min(slice_volume.shape[0] - y, h + 2*margin)\n                    \n                    # Extract ROI\n                    roi = slice_volume[y:y+h, x:x+w]\n                    \n                    # Resize to standard size\n                    roi_resized = cv2.resize(roi, self.roi_size)\n                    \n                    rois.append({\n                        'roi': roi_resized,\n                        'slice_idx': slice_idx,\n                        'bbox': (x, y, w, h),\n                        'confidence': np.max(slice_mask[y:y+h, x:x+w])\n                    })\n        \n        return rois\n\nprint(\"âœ… ROI Extractor loaded (for Stage 2)\")\n\n# ====================================================\n# CELL 10: RUN TRAINING\n# ====================================================\n\n# Uncomment the line below to start training\n# model = main()\n\nprint(\"ðŸŽ¯ Ready to train! Uncomment 'model = main()' in the last cell to start training.\")\nprint(\"ðŸ“Š Expected training time: 1-2 hours\")\nprint(\"ðŸ’¾ Output: stage1_segmentation_best.pth\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}