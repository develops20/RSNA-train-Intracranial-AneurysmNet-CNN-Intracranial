{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/02-aneurysmnet-cnn-intracranial-training-nb153?scriptVersionId=254365611\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"9089a656","metadata":{"execution":{"iopub.execute_input":"2025-08-05T14:32:51.668205Z","iopub.status.busy":"2025-08-05T14:32:51.667926Z","iopub.status.idle":"2025-08-05T14:35:05.27572Z","shell.execute_reply":"2025-08-05T14:35:05.274984Z"},"papermill":{"duration":133.612691,"end_time":"2025-08-05T14:35:05.277327","exception":false,"start_time":"2025-08-05T14:32:51.664636","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting monai\r\n","  Downloading monai-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\r\n","Requirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.18.0)\r\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.14.0)\r\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.5)\r\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\r\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.5.1)\r\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (0.6.2)\r\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2.21.5)\r\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\r\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\r\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.2.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (1.13.1)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\r\n","Downloading monai-1.5.0-py3-none-any.whl (2.7 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\r\n","  Attempting uninstall: nvidia-nvjitlink-cu12\r\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-curand-cu12\r\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n","  Attempting uninstall: nvidia-cufft-cu12\r\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cublas-cu12\r\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n","  Attempting uninstall: nvidia-cusparse-cu12\r\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n","  Attempting uninstall: nvidia-cudnn-cu12\r\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n","  Attempting uninstall: nvidia-cusolver-cu12\r\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n","Successfully installed monai-1.5.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"]},{"name":"stderr","output_type":"stream","text":["<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n","2025-08-05 14:34:49.563355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1754404489.897028      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1754404489.992472      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["!pip install monai\n","\n","# ====================================================\n","# RSNA INTRACRANIAL ANEURYSM DETECTION - TRAINING PIPELINE\n","# ====================================================\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pydicom\n","import nibabel as nib\n","import cv2\n","from scipy import ndimage\n","from monai.networks.nets import BasicUNet\n","from monai.transforms import Compose, ToTensord\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"id":"9d32fb05","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-08-05T14:35:05.327304Z","iopub.status.busy":"2025-08-05T14:35:05.326601Z","iopub.status.idle":"2025-08-05T14:35:05.365082Z","shell.execute_reply":"2025-08-05T14:35:05.364318Z"},"papermill":{"duration":0.063531,"end_time":"2025-08-05T14:35:05.366141","exception":false,"start_time":"2025-08-05T14:35:05.30261","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Configuration loaded - Device: cuda\n","âœ… DICOM Processor loaded\n","âœ… Dataset class loaded\n","âœ… Model architecture loaded\n","âœ… Loss functions loaded\n","âœ… Training functions loaded\n","âœ… ROI Extractor loaded (for Stage 2)\n"]}],"source":["# ====================================================\n","# CELL 2: CONFIGURATION\n","# ====================================================\n","\n","class Config:\n","    # Paths\n","    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n","    LOCALIZER_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\n","    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n","    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n","    \n","    # Stage 1: 3D Segmentation\n","    STAGE1_TARGET_SIZE = (64, 128, 128)  # Smaller for speed\n","    STAGE1_BATCH_SIZE = 4\n","    STAGE1_EPOCHS = 5\n","    STAGE1_LR = 1e-3\n","    \n","    # General\n","    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    MIXED_PRECISION = True\n","    N_FOLDS = 3\n","    \n","    # Competition constants\n","    ID_COL = 'SeriesInstanceUID'\n","    LABEL_COLS = [\n","        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n","        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n","        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n","        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n","        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n","        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n","    ]\n","    TARGET_COL = 'Aneurysm Present'\n","    \n","    # Debug settings\n","    DEBUG_MODE = True\n","    DEBUG_SAMPLES = 50  # Use small subset for testing\n","\n","print(f\"âœ… Configuration loaded - Device: {Config.DEVICE}\")\n","\n","\n","# ====================================================\n","# CELL 3: SIMPLE DICOM PROCESSOR\n","# ====================================================\n","\n","class SimpleDICOMProcessor:\n","    def __init__(self, target_size=None):\n","        self.target_size = target_size or Config.STAGE1_TARGET_SIZE\n","        \n","    def load_dicom_series(self, series_path):\n","        \"\"\"Simple DICOM loading - no complex error handling\"\"\"\n","        try:\n","            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n","            if not dicom_files:\n","                return np.zeros(self.target_size, dtype=np.float32)\n","            \n","            # Load all DICOMs\n","            pixel_arrays = []\n","            for f in dicom_files[:50]:  # Limit to 50 files max for speed\n","                try:\n","                    ds = pydicom.dcmread(os.path.join(series_path, f), force=True)\n","                    if hasattr(ds, 'pixel_array'):\n","                        arr = ds.pixel_array\n","                        if arr.ndim == 2:  # Standard 2D slice\n","                            pixel_arrays.append(arr)\n","                        elif arr.ndim == 3:  # 3D volume - take middle slices\n","                            mid_start = arr.shape[0] // 4\n","                            mid_end = 3 * arr.shape[0] // 4\n","                            for slice_idx in range(mid_start, mid_end, 2):  # Every 2nd slice\n","                                pixel_arrays.append(arr[slice_idx])\n","                except:\n","                    continue\n","            \n","            if not pixel_arrays:\n","                return np.zeros(self.target_size, dtype=np.float32)\n","            \n","            # Stack into volume\n","            #volume = np.stack(pixel_arrays, axis=0).astype(np.float32)\n","            \n","            # Resize all slices to same shape before stacking\n","            if len(pixel_arrays) > 0:\n","                # Use first slice shape as reference, or use a standard size\n","                target_slice_shape = (256, 256)  # Standard size for all slices\n","                \n","                resized_arrays = []\n","                for arr in pixel_arrays:\n","                    if arr.shape != target_slice_shape:\n","                        # Resize slice to target shape\n","                        resized_arr = ndimage.zoom(arr, \n","                                                 (target_slice_shape[0] / arr.shape[0], \n","                                                  target_slice_shape[1] / arr.shape[1]), \n","                                                 order=1)\n","                        resized_arrays.append(resized_arr)\n","                    else:\n","                        resized_arrays.append(arr)\n","                \n","                # Now stack - all arrays have same shape\n","                volume = np.stack(resized_arrays, axis=0).astype(np.float32)\n","            else:\n","                return np.zeros(self.target_size, dtype=np.float32)\n","\n","            \n","            # Simple preprocessing\n","            volume = self.preprocess_volume(volume)\n","            return volume\n","            \n","        except Exception as e:\n","            print(f\"Failed to load {series_path}: {e}\")\n","            return np.zeros(self.target_size, dtype=np.float32)\n","    \n","    def preprocess_volume(self, volume):\n","        \"\"\"Simple preprocessing\"\"\"\n","        # Normalize\n","        p1, p99 = np.percentile(volume, [1, 99])\n","        volume = np.clip(volume, p1, p99)\n","        volume = (volume - p1) / (p99 - p1 + 1e-8)\n","        \n","        # Resize to target\n","        if volume.shape != self.target_size:\n","            zoom_factors = [self.target_size[i] / volume.shape[i] for i in range(3)]\n","            volume = ndimage.zoom(volume, zoom_factors, order=1)\n","        \n","        return volume.astype(np.float32)\n","\n","print(\"âœ… DICOM Processor loaded\")\n","\n","# ====================================================\n","# CELL 4: DATASET CLASS\n","# ====================================================\n","\n","class SimpleSegmentationDataset(Dataset):\n","    def __init__(self, df, series_dir, processor, mode='train'):\n","        self.df = df\n","        self.series_dir = series_dir\n","        self.processor = processor\n","        self.mode = mode\n","        \n","        # Simple transform\n","        self.transform = Compose([ToTensord(keys=['volume'])])\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def load_segmentation_mask(self, series_id, volume_shape):\n","        \"\"\"Load real segmentation mask from competition data\"\"\"\n","        seg_path = os.path.join(Config.SEGMENTATION_DIR, f\"{series_id}.nii\")\n","        \n","        try:\n","            if os.path.exists(seg_path):\n","                # Load NIfTI segmentation mask\n","                import nibabel as nib\n","                nii_img = nib.load(seg_path)\n","                mask = nii_img.get_fdata().astype(np.float32)\n","                \n","                # Resize mask to match volume shape\n","                if mask.shape != volume_shape:\n","                    zoom_factors = [volume_shape[i] / mask.shape[i] for i in range(3)]\n","                    mask = ndimage.zoom(mask, zoom_factors, order=0)  # Nearest neighbor for masks\n","                \n","                # Normalize mask values to 0-1\n","                mask = (mask > 0).astype(np.float32)\n","                return mask\n","            else:\n","                # No segmentation available - create empty mask\n","                return np.zeros(volume_shape, dtype=np.float32)\n","                \n","        except Exception as e:\n","            print(f\"Error loading segmentation for {series_id}: {e}\")\n","            # Fallback: create simple mask if aneurysm present\n","            has_aneurysm = int(self.df[self.df[Config.ID_COL] == series_id][Config.TARGET_COL].iloc[0])\n","            if has_aneurysm:\n","                # Create a rough central region mask as fallback\n","                mask = np.zeros(volume_shape, dtype=np.float32)\n","                h, w, d = volume_shape\n","                mask[h//4:3*h//4, w//4:3*w//4, d//4:3*d//4] = 1.0\n","                return mask\n","            else:\n","                return np.zeros(volume_shape, dtype=np.float32)\n","    \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        series_id = row[Config.ID_COL]\n","        series_path = os.path.join(self.series_dir, series_id)\n","        \n","        # Load volume\n","        volume = self.processor.load_dicom_series(series_path)\n","        \n","        # Load REAL segmentation mask from competition data\n","        mask = self.load_segmentation_mask(series_id, volume.shape)\n","        \n","        # Get aneurysm presence label\n","        has_aneurysm = int(row[Config.TARGET_COL])\n","        \n","        # Transform\n","        data_dict = {'volume': volume}\n","        if self.transform:\n","            data_dict = self.transform(data_dict)\n","        \n","        volume_tensor = data_dict['volume'].unsqueeze(0)  # Add channel dim\n","        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n","        \n","        return {\n","            'volume': volume_tensor,\n","            'mask': mask_tensor,\n","            'has_aneurysm': torch.tensor(has_aneurysm, dtype=torch.float32),\n","            'series_id': series_id\n","        }\n","\n","print(\"âœ… Dataset class loaded\")\n","\n","# ====================================================\n","# CELL 5: 3D U-NET MODEL\n","# ====================================================\n","\n","class Simple3DSegmentationNet(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=1):\n","        super().__init__()\n","        \n","        # Use MONAI's BasicUNet - simple and proven\n","        self.backbone = BasicUNet(\n","            spatial_dims=3,\n","            in_channels=in_channels,\n","            out_channels=32,\n","            features=(32, 64, 128, 256, 512, 32),\n","            dropout=0.1\n","        )\n","        \n","        # Segmentation head\n","        self.seg_head = nn.Conv3d(32, out_channels, kernel_size=1)\n","        \n","        # Classification head (aneurysm presence)\n","        self.global_pool = nn.AdaptiveAvgPool3d(1)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(32, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, 1)\n","        )\n","        \n","    def forward(self, x):\n","        # Extract features\n","        features = self.backbone(x)\n","        \n","        # Segmentation output\n","        seg_logits = self.seg_head(features)\n","        \n","        # Classification output\n","        pooled_features = self.global_pool(features).flatten(1)\n","        cls_logits = self.classifier(pooled_features)\n","        \n","        return seg_logits, cls_logits\n","\n","print(\"âœ… Model architecture loaded\")\n","\n","# ====================================================\n","# CELL 6: LOSS FUNCTIONS\n","# ====================================================\n","\n","class CombinedLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bce_loss = nn.BCEWithLogitsLoss()\n","        self.seg_loss = nn.BCEWithLogitsLoss()\n","        \n","    def forward(self, seg_logits, cls_logits, seg_targets, cls_targets):\n","        # Segmentation loss\n","        seg_loss = self.seg_loss(seg_logits, seg_targets)\n","        \n","        # Classification loss\n","        cls_loss = self.bce_loss(cls_logits.squeeze(), cls_targets)\n","        \n","        # Combined loss\n","        total_loss = seg_loss + 0.5 * cls_loss\n","        \n","        return total_loss, seg_loss, cls_loss\n","\n","print(\"âœ… Loss functions loaded\")\n","\n","# ====================================================\n","# CELL 7: TRAINING FUNCTIONS\n","# ====================================================\n","\n","def train_epoch(model, loader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    total_seg_loss = 0\n","    total_cls_loss = 0\n","    num_batches = 0\n","    \n","    for batch in tqdm(loader, desc=\"Training\"):\n","        volume = batch['volume'].to(device)\n","        mask = batch['mask'].to(device)\n","        has_aneurysm = batch['has_aneurysm'].to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        # Forward pass\n","        seg_logits, cls_logits = model(volume)\n","        \n","        # Calculate loss\n","        loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm)\n","        \n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        total_seg_loss += seg_loss.item()\n","        total_cls_loss += cls_loss.item()\n","        num_batches += 1\n","    \n","    return (total_loss / num_batches, \n","            total_seg_loss / num_batches, \n","            total_cls_loss / num_batches)\n","\n","def validate_epoch(model, loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    total_seg_loss = 0\n","    total_cls_loss = 0\n","    num_batches = 0\n","    \n","    with torch.no_grad():\n","        for batch in tqdm(loader, desc=\"Validating\"):\n","            volume = batch['volume'].to(device)\n","            mask = batch['mask'].to(device)\n","            has_aneurysm = batch['has_aneurysm'].to(device)\n","            \n","            # Forward pass\n","            seg_logits, cls_logits = model(volume)\n","            \n","            # Calculate loss\n","            loss, seg_loss, cls_loss = criterion(seg_logits, cls_logits, mask, has_aneurysm)\n","            \n","            total_loss += loss.item()\n","            total_seg_loss += seg_loss.item()\n","            total_cls_loss += cls_loss.item()\n","            num_batches += 1\n","    \n","    return (total_loss / num_batches, \n","            total_seg_loss / num_batches, \n","            total_cls_loss / num_batches)\n","\n","print(\"âœ… Training functions loaded\")\n","\n","\n","# ====================================================\n","# CELL 8: MAIN TRAINING LOOP\n","# ====================================================\n","\n","def main():\n","    print(f\"ğŸš€ STAGE 1: 3D SEGMENTATION FOR REGION LOCALIZATION\")\n","    print(f\"Using device: {Config.DEVICE}\")\n","    print(f\"Target size: {Config.STAGE1_TARGET_SIZE}\")\n","    \n","    # Load data\n","    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n","    \n","    # Load localizer data (for future use)\n","    try:\n","        localizer_df = pd.read_csv(Config.LOCALIZER_CSV_PATH)\n","        print(f\"Loaded localizer data: {len(localizer_df)} entries\")\n","    except:\n","        localizer_df = None\n","        print(\"No localizer data found - continuing without it\")\n","    \n","    # Debug mode - small subset\n","    if Config.DEBUG_MODE:\n","        train_df = train_df.head(Config.DEBUG_SAMPLES)\n","    print(f\"Training samples: {len(train_df)}\")\n","    print(f\"Aneurysm cases: {train_df[Config.TARGET_COL].sum()}\")\n","    \n","    # Simple train/val split\n","    val_size = len(train_df) // 5\n","    val_df = train_df[:val_size].reset_index(drop=True)\n","    train_df = train_df[val_size:].reset_index(drop=True)\n","    \n","    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n","    \n","    # Create datasets\n","    processor = SimpleDICOMProcessor()\n","    train_dataset = SimpleSegmentationDataset(train_df, Config.SERIES_DIR, processor, 'train')\n","    val_dataset = SimpleSegmentationDataset(val_df, Config.SERIES_DIR, processor, 'val')\n","    \n","    # Create loaders\n","    train_loader = DataLoader(train_dataset, batch_size=Config.STAGE1_BATCH_SIZE, shuffle=True, num_workers=2)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.STAGE1_BATCH_SIZE, shuffle=False, num_workers=2)\n","    \n","    # Create model\n","    model = Simple3DSegmentationNet().to(Config.DEVICE)\n","    \n","    # Multi-GPU if available\n","    if torch.cuda.device_count() > 1:\n","        print(f\"Using {torch.cuda.device_count()} GPUs\")\n","        model = nn.DataParallel(model)\n","    \n","    # Optimizer and loss\n","    optimizer = optim.AdamW(model.parameters(), lr=Config.STAGE1_LR)\n","    criterion = CombinedLoss()\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.STAGE1_EPOCHS)\n","    \n","    # Training loop\n","    best_loss = float('inf')\n","    \n","    for epoch in range(Config.STAGE1_EPOCHS):\n","        print(f\"\\nEpoch {epoch+1}/{Config.STAGE1_EPOCHS}\")\n","        \n","        # Train\n","        train_loss, train_seg_loss, train_cls_loss = train_epoch(\n","            model, train_loader, optimizer, criterion, Config.DEVICE\n","        )\n","        \n","        # Validate\n","        val_loss, val_seg_loss, val_cls_loss = validate_epoch(\n","            model, val_loader, criterion, Config.DEVICE\n","        )\n","        \n","        # Step scheduler\n","        scheduler.step()\n","        \n","        print(f\"Train - Total: {train_loss:.4f}, Seg: {train_seg_loss:.4f}, Cls: {train_cls_loss:.4f}\")\n","        print(f\"Val   - Total: {val_loss:.4f}, Seg: {val_seg_loss:.4f}, Cls: {val_cls_loss:.4f}\")\n","        \n","        # Save best model\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            torch.save({\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'epoch': epoch,\n","                'val_loss': val_loss\n","            }, 'stage1_segmentation_best.pth')\n","            print(f\"ğŸ’¾ Saved best model (val_loss: {val_loss:.4f})\")\n","    \n","    print(f\"\\nâœ… Stage 1 complete! Best val loss: {best_loss:.4f}\")\n","    print(\"ğŸ“ Model saved as 'stage1_segmentation_best.pth'\")\n","    \n","    return model\n","\n","# ====================================================\n","# CELL 9: ROI EXTRACTOR FOR STAGE 2 (FUTURE USE)\n","# ====================================================\n","\n","class ROIExtractor:\n","    def __init__(self, roi_size=(224, 224), confidence_threshold=0.5):\n","        self.roi_size = roi_size\n","        self.confidence_threshold = confidence_threshold\n","    \n","    def extract_rois(self, volume, segmentation_mask):\n","        \"\"\"Extract 2D ROI slices from 3D volume using segmentation mask\"\"\"\n","        rois = []\n","        \n","        # Find slices with high confidence regions\n","        for slice_idx in range(volume.shape[0]):\n","            slice_volume = volume[slice_idx]\n","            slice_mask = segmentation_mask[slice_idx]\n","            \n","            # Check if this slice has potential aneurysm regions\n","            if np.max(slice_mask) > self.confidence_threshold:\n","                # Find connected components\n","                binary_mask = (slice_mask > self.confidence_threshold).astype(np.uint8)\n","                \n","                # Find contours\n","                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","                \n","                for contour in contours:\n","                    # Get bounding box\n","                    x, y, w, h = cv2.boundingRect(contour)\n","                    \n","                    # Expand bounding box\n","                    margin = max(w, h) // 4\n","                    x = max(0, x - margin)\n","                    y = max(0, y - margin)\n","                    w = min(slice_volume.shape[1] - x, w + 2*margin)\n","                    h = min(slice_volume.shape[0] - y, h + 2*margin)\n","                    \n","                    # Extract ROI\n","                    roi = slice_volume[y:y+h, x:x+w]\n","                    \n","                    # Resize to standard size\n","                    roi_resized = cv2.resize(roi, self.roi_size)\n","                    \n","                    rois.append({\n","                        'roi': roi_resized,\n","                        'slice_idx': slice_idx,\n","                        'bbox': (x, y, w, h),\n","                        'confidence': np.max(slice_mask[y:y+h, x:x+w])\n","                    })\n","        \n","        return rois\n","\n","print(\"âœ… ROI Extractor loaded (for Stage 2)\")\n"]},{"cell_type":"code","execution_count":3,"id":"b8f02a54","metadata":{"execution":{"iopub.execute_input":"2025-08-05T14:35:05.412319Z","iopub.status.busy":"2025-08-05T14:35:05.412059Z","iopub.status.idle":"2025-08-05T14:37:52.093063Z","shell.execute_reply":"2025-08-05T14:37:52.092031Z"},"papermill":{"duration":166.706111,"end_time":"2025-08-05T14:37:52.095021","exception":false,"start_time":"2025-08-05T14:35:05.38891","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["ğŸš€ STAGE 1: 3D SEGMENTATION FOR REGION LOCALIZATION\n","Using device: cuda\n","Target size: (64, 128, 128)\n","Loaded localizer data: 2286 entries\n","Training samples: 50\n","Aneurysm cases: 22\n","Train: 40, Val: 10\n","BasicUNet features: (32, 64, 128, 256, 512, 32).\n","Using 2 GPUs\n","\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.01s/it]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.84s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 0.8289, Seg: 0.4778, Cls: 0.7022\n","Val   - Total: 0.7155, Seg: 0.3653, Cls: 0.7003\n","ğŸ’¾ Saved best model (val_loss: 0.7155)\n","\n","Epoch 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.45s/it]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.24s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 0.6598, Seg: 0.3098, Cls: 0.7001\n","Val   - Total: 0.5912, Seg: 0.2444, Cls: 0.6936\n","ğŸ’¾ Saved best model (val_loss: 0.5912)\n","\n","Epoch 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.31s/it]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.23s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 0.5611, Seg: 0.2140, Cls: 0.6940\n","Val   - Total: 0.5219, Seg: 0.1759, Cls: 0.6918\n","ğŸ’¾ Saved best model (val_loss: 0.5219)\n","\n","Epoch 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.53s/it]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.47s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 0.5142, Seg: 0.1646, Cls: 0.6992\n","Val   - Total: 0.4920, Seg: 0.1468, Cls: 0.6904\n","ğŸ’¾ Saved best model (val_loss: 0.4920)\n","\n","Epoch 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.41s/it]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train - Total: 0.4932, Seg: 0.1458, Cls: 0.6949\n","Val   - Total: 0.4845, Seg: 0.1396, Cls: 0.6900\n","ğŸ’¾ Saved best model (val_loss: 0.4845)\n","\n","âœ… Stage 1 complete! Best val loss: 0.4845\n","ğŸ“ Model saved as 'stage1_segmentation_best.pth'\n","ğŸ¯ Ready to train! Uncomment 'model = main()' in the last cell to start training.\n","ğŸ“Š Expected training time: 1-2 hours\n","ğŸ’¾ Output: stage1_segmentation_best.pth\n"]}],"source":["# ====================================================\n","# CELL 10: RUN TRAINING\n","# ====================================================\n","\n","# Uncomment the line below to start training\n","model = main()\n","\n","print(\"ğŸ¯ Ready to train! Uncomment 'model = main()' in the last cell to start training.\")\n","print(\"ğŸ“Š Expected training time: 1-2 hours\")\n","print(\"ğŸ’¾ Output: stage1_segmentation_best.pth\")"]},{"cell_type":"code","execution_count":null,"id":"22938c16","metadata":{"papermill":{"duration":0.026079,"end_time":"2025-08-05T14:37:52.155695","exception":false,"start_time":"2025-08-05T14:37:52.129616","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":13190393,"sourceId":99552,"sourceType":"competition"}],"dockerImageVersionId":31089,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":309.131078,"end_time":"2025-08-05T14:37:55.199949","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-05T14:32:46.068871","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}